{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23dbf1cd",
   "metadata": {},
   "source": [
    "# RENT AUTOMATION BOT (PROOF OF CONCEPT, PROTOTYPE, DEPLOYMENT)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96bfed",
   "metadata": {},
   "source": [
    "<img src= 'images\\rent bot.jpg' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578216d3",
   "metadata": {},
   "source": [
    "\n",
    "# Problem Statement and Project Objectives\n",
    "\n",
    "***\n",
    "\n",
    "## Problem Statement\n",
    "The primary challenge addressed in this notebook is the automation of rent payment tracking for Lemaiyan Heights. Traditional rent collection and record-keeping can be error-prone and time-consuming, especially when dealing with multiple payment sources and tenants. Key challenges include:\n",
    "- Manual reconciliation of payments.\n",
    "- Risk of duplicate entries due to repetitive processing of the same payment notifications.\n",
    "- Difficulty in maintaining up-to-date financial records and tenant-specific payment histories.\n",
    "\n",
    "## Project Objectives\n",
    "The notebook aims to achieve the following objectives:\n",
    "- **Automate Payment Parsing:** Use regular expressions to extract payment details from email notifications reliably.\n",
    "- **Ensure Data Integrity:** Avoid double-processing of payments by tracking unique payment references.\n",
    "- **Dynamic Sheet Management:** Automatically update or create individual tenant sheets based on the received payment details.\n",
    "- **Seamless Integration:** Connect with the Google platform (Gmail and Google Sheets) to streamline data extraction and real-time updates.\n",
    "- **User-Friendly Dashboard:** Provide a streamlined overview through a Streamlit app, allowing users to initiate the payment bot and view processing logs and summaries.\n",
    "\n",
    "This solution demonstrates a proof of concept that leverages Python, Pandas, openpyxl, gspread, and Google APIs to enhance the rent collection process, optimize administrative workflows, and reduce the possibility of human error.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d849538",
   "metadata": {},
   "source": [
    "## PROOF OF CONCEPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c84fb8",
   "metadata": {},
   "source": [
    "* Random generated dataset to simulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c261b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 200 dummy emails in data\\dummy_emails_200.txt\n",
      "Sample email:\n",
      " Dear Customer, your payment of KES 19000.00 for account: PAYLEMAIYAN #A3 has been received from Kathleen Jones 759****602 on 04/02/2025 09:06 AM. M-Pesa Ref: R80VIOA2YW\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define possible account codes (A1-A6, B1-B6, ..., G1-G6)\n",
    "accounts = [f\"{l}{n}\" for l in \"ABCDEFG\" for n in range(1, 7)]\n",
    "\n",
    "email_template = (\"Dear Customer, your payment of KES {amount} for account: PAYLEMAIYAN #{code} \"\n",
    "                  \"has been received from {name} {phone} on {date_time}. \"\n",
    "                  \"M-Pesa Ref: {mpesa_ref}\")\n",
    "def random_ref_code(length=10):\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=length))\n",
    "dummy_emails = []\n",
    "for _ in range(200):\n",
    "    amount = f\"{random.randint(5, 20) * 1000}.00\"\n",
    "    code = random.choice(accounts)\n",
    "    name = fake.name()\n",
    "    phone = f\"{random.randint(700, 799)}****{random.randint(100,999)}\"\n",
    "    date_time = fake.date_time_this_year().strftime('%d/%m/%Y %I:%M %p')\n",
    "    mpesa_ref = random_ref_code(10)\n",
    "    email_text = email_template.format(\n",
    "        amount=amount,\n",
    "        code=code,\n",
    "        name=name,\n",
    "        phone=phone,\n",
    "        date_time=date_time,\n",
    "        mpesa_ref=mpesa_ref\n",
    "    )\n",
    "    dummy_emails.append(email_text)\n",
    "\n",
    "# Save to data/dummy_emails_200.txt\n",
    "out_path = Path(\"data/dummy_emails_200.txt\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_path.write_text(\"\\n\\n\".join(dummy_emails))\n",
    "\n",
    "print(f\"Created {len(dummy_emails)} dummy emails in {out_path}\")\n",
    "print(\"Sample email:\\n\", dummy_emails[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b474a9c",
   "metadata": {},
   "source": [
    "* Logic engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa9290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 emails.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Reads MPESA email notifications from dummy_emails.txt,\n",
    "# Parses payment info, updates dummy_rent_tracker.xlsx,\n",
    "# Avoids double-logging by checking ProcessedRefs sheet.\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_DIR = Path('data')\n",
    "EMAIL_FILE = DATA_DIR / 'dummy_emails_200.txt'\n",
    "SPREADSHEET_FILE = DATA_DIR / 'dummy_rent_tracker.xlsx'\n",
    "\n",
    "# --- 1. Load Dummy Emails ---\n",
    "with open(EMAIL_FILE, 'r') as f:\n",
    "    email_texts = f.read().split('\\n\\n')\n",
    "\n",
    "print(f\"Loaded {len(email_texts)} emails.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532bc6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Customer, your payment of KES 20000.00 for account: PAYLEMAIYAN #G4 has been received from Blake Lee 719****900 on 08/05/2025 08:08 AM. M-Pesa Ref: 1NRVADULXZ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_texts[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2107ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1250 previously processed refs.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Workbook and All Sheet Names ---\n",
    "wb = load_workbook(SPREADSHEET_FILE)\n",
    "sheet_names = wb.sheetnames\n",
    "\n",
    "# --- 3. Load ProcessedRefs (deduplication) ---\n",
    "try:\n",
    "    processed_refs_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='ProcessedRefs')\n",
    "    processed_refs = set(str(ref).strip().upper() for ref in processed_refs_df['Ref'] if pd.notna(ref))\n",
    "except Exception:\n",
    "    processed_refs = set()\n",
    "    print(\"ProcessedRefs sheet is empty or missing. Will create it.\")\n",
    "\n",
    "print(f\"Found {len(processed_refs)} previously processed refs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46ab175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Regex Parser Function ---\n",
    "def extract_payment_info(email_body):\n",
    "    pattern = (\n",
    "        r'payment of KES ([\\d,]+\\.\\d{2}) '\n",
    "        r'for account: PAYLEMAIYAN\\s*#?\\s*([A-Za-z]\\d{1,2})'\n",
    "        r' has been received from (.+?) '\n",
    "        r'(.{1,13}) '\n",
    "        r'on (\\d{2}/\\d{2}/\\d{4} \\d{1,2}:\\d{2} [APM]{2})\\. '\n",
    "        r'M-Pesa Ref: ([\\w\\d]+)'\n",
    "    )\n",
    "    match = re.search(pattern, email_body, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        return {\n",
    "            'Amount': float(match.group(1).replace(',', '').strip()),\n",
    "            'AccountCode': match.group(2).strip().upper(),\n",
    "            'Payer': match.group(3).strip(),\n",
    "            'Phone': match.group(4).strip(),\n",
    "            'Date': match.group(5).strip(),\n",
    "            'Ref': match.group(6).strip().upper(),\n",
    "        }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07c2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Process Emails, Update or Create Sheets ---\n",
    "\n",
    "\n",
    "updates_log = []\n",
    "new_refs = []\n",
    "updates_per_sheet = {}\n",
    "\n",
    "# We'll use openpyxl to add new sheets if needed\n",
    "wb = load_workbook(SPREADSHEET_FILE)\n",
    "writer = pd.ExcelWriter(SPREADSHEET_FILE, engine='openpyxl', mode='a', if_sheet_exists='overlay')\n",
    "\n",
    "# Loading a Master payments file\n",
    "try:\n",
    "    payment_history_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='PaymentHistory')\n",
    "except Exception:\n",
    "    payment_history_df = pd.DataFrame(columns=[\n",
    "        'Date', 'Amount', 'Ref', 'Payer', 'Phone', 'Payment Mode', 'AccountCode', 'TenantSheet'\n",
    "    ])\n",
    "\n",
    "\n",
    "for email in email_texts:\n",
    "    payment_data = extract_payment_info(email)\n",
    "    if not payment_data:\n",
    "        updates_log.append(\"Skipped email: Could not parse payment info.\")\n",
    "        continue\n",
    "\n",
    "    ref = payment_data['Ref'].upper().strip()\n",
    "    if ref in processed_refs:\n",
    "        updates_log.append(f\"Duplicate ignored (Ref {ref})\")\n",
    "        continue\n",
    "\n",
    "    account_code = payment_data['AccountCode']\n",
    "    payer_name = payment_data['Payer'].replace(\" \", \"_\")[:15]\n",
    "    # Try to match an existing tenant sheet\n",
    "    target_sheet = None\n",
    "    for s in sheet_names:\n",
    "        # Take just the code part from the sheet name\n",
    "        sheet_token = s.split()[0].replace('-', '').upper().strip()\n",
    "        if account_code == sheet_token and 'PROCESSEDREFS' not in s.upper() and 'PAYMENTHISTORY' not in s.upper():\n",
    "            target_sheet = s\n",
    "            break\n",
    "\n",
    "    # --- 7. If no sheet found, CREATE it ---\n",
    "    if target_sheet is None:\n",
    "        target_sheet = f\"{account_code} - {payer_name if payer_name else 'AutoAdded'}\"\n",
    "        print(f\"Creating new sheet: {target_sheet} for new tenant {account_code}\")\n",
    "        new_tenant_df = pd.DataFrame(columns=[\n",
    "            'Date', 'Amount', 'Ref', 'Payer', 'Phone', 'Payment Mode'\n",
    "        ])\n",
    "        new_tenant_df.to_excel(writer, sheet_name=target_sheet, index=False)\n",
    "        updates_log.append(f\"Created new sheet: {target_sheet}\")\n",
    "        sheet_names.append(target_sheet)  # So we don't create it twice\n",
    "\n",
    "    # --- 8. Append payment to tenant sheet ---\n",
    "    try:\n",
    "        df = pd.read_excel(SPREADSHEET_FILE, sheet_name=target_sheet)\n",
    "    except Exception:\n",
    "        df = pd.DataFrame(columns=['Date', 'Amount', 'Ref', 'Payer', 'Phone', 'Payment Mode'])\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'Date': [payment_data['Date']],\n",
    "        'Amount': [payment_data['Amount']],\n",
    "        'Ref': [payment_data['Ref']],\n",
    "        'Payer': [payment_data['Payer']],\n",
    "        'Phone': [payment_data['Phone']],\n",
    "        'Payment Mode': ['MPESA Payment'],\n",
    "    })\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_excel(writer, sheet_name=target_sheet, index=False)\n",
    "    updates_log.append(f\"Logged payment for {account_code} - Ref {ref}\")\n",
    "    new_refs.append(ref)\n",
    "    updates_per_sheet.setdefault(target_sheet, 0)\n",
    "    updates_per_sheet[target_sheet] += 1\n",
    "\n",
    "     # --- 9. Add to PaymentHistory sheet ---\n",
    "    new_hist_row = new_row.copy()\n",
    "    new_hist_row['AccountCode'] = account_code\n",
    "    new_hist_row['TenantSheet'] = target_sheet\n",
    "    payment_history_df = pd.concat([payment_history_df, new_hist_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ccb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Logged payment for A3 - Ref R80VIOA2YW\n",
      "Logged payment for C4 - Ref WURDRH7ZBU\n",
      "Logged payment for D2 - Ref LTW0VCTS5S\n",
      "Logged payment for A6 - Ref WP2X99YUDD\n",
      "Logged payment for G4 - Ref MUH400LVXG\n",
      "Logged payment for A3 - Ref 3RB37S9E7O\n",
      "Logged payment for A3 - Ref LRVN72GBQD\n",
      "Logged payment for F6 - Ref FRGEE8A03G\n",
      "Logged payment for F1 - Ref SXFW54V1I9\n",
      "Logged payment for G3 - Ref IY79MGDB1U\n",
      "Logged payment for F2 - Ref 8AEOYFJRQ8\n",
      "Logged payment for C3 - Ref 2CT6AX00NG\n",
      "Logged payment for E1 - Ref JEFNXKQ14B\n",
      "Logged payment for D4 - Ref 1OKUUKCM8U\n",
      "Logged payment for C2 - Ref 6KZBWB5WB5\n",
      "Logged payment for G2 - Ref RRYATOC3YD\n",
      "Logged payment for G2 - Ref CBIHOA0YP1\n",
      "Logged payment for A1 - Ref V5W74BU5YC\n",
      "Logged payment for B2 - Ref L2YI1I2XWG\n",
      "Logged payment for E5 - Ref AKPXDAOR4G\n",
      "Logged payment for G6 - Ref X1W9MGLQ64\n",
      "Logged payment for B2 - Ref 5V2F3WF2HQ\n",
      "Logged payment for G4 - Ref 1NRVADULXZ\n",
      "Logged payment for A3 - Ref X5DK2WVQC2\n",
      "Logged payment for F1 - Ref 9EW3MP7T41\n",
      "Logged payment for F3 - Ref U6Y1HU29I6\n",
      "Logged payment for F3 - Ref EOIQWK0IDF\n",
      "Logged payment for B5 - Ref D8PCEFGFEF\n",
      "Logged payment for D4 - Ref BO0A6VW8TV\n",
      "Logged payment for B3 - Ref OTCAPO3TPN\n",
      "Logged payment for E4 - Ref BC6LU4OR26\n",
      "Logged payment for E5 - Ref 50MFFFDZ6F\n",
      "Logged payment for F6 - Ref Z6RRM5W9RH\n",
      "Logged payment for C5 - Ref JA4F23YYAW\n",
      "Logged payment for B1 - Ref W4GUZ6SNCT\n",
      "Logged payment for G3 - Ref SKNISAXO11\n",
      "Logged payment for G6 - Ref 7BXPVYN2TP\n",
      "Logged payment for E3 - Ref LZKKVBE8WI\n",
      "Logged payment for D3 - Ref 6FY5YMUUWU\n",
      "Logged payment for G4 - Ref XAZ6PW4DOC\n",
      "Logged payment for G1 - Ref 9MS7N9CVYW\n",
      "Logged payment for G3 - Ref G61M9QCEU8\n",
      "Logged payment for G2 - Ref MILL26SY02\n",
      "Logged payment for D5 - Ref M8F7VG3QEX\n",
      "Logged payment for A2 - Ref ADB90A79W9\n",
      "Logged payment for B4 - Ref O2NFGL8QR3\n",
      "Logged payment for D4 - Ref MBJ4MGGGIW\n",
      "Logged payment for C5 - Ref 2C6TDK273Y\n",
      "Logged payment for A4 - Ref LLU12WOSIH\n",
      "Logged payment for F6 - Ref EIWZLFFUZR\n",
      "Logged payment for B6 - Ref NIXA902R9Y\n",
      "Logged payment for A5 - Ref TCVXSRE1IM\n",
      "Logged payment for G1 - Ref TJC5CRFZ2M\n",
      "Logged payment for E3 - Ref UJN6I2E4F0\n",
      "Logged payment for G3 - Ref 3E0GE8KWKS\n",
      "Logged payment for F4 - Ref O24IXPQIWH\n",
      "Logged payment for C5 - Ref U0W7XXJMSW\n",
      "Logged payment for A2 - Ref GMJ2MBPVUO\n",
      "Logged payment for B1 - Ref J1455MYQKK\n",
      "Logged payment for D2 - Ref ILHTH6FW5U\n",
      "Logged payment for B1 - Ref 8L5Q5YHFH3\n",
      "Logged payment for F4 - Ref 88F23893AG\n",
      "Logged payment for D2 - Ref E8JUMDNDZU\n",
      "Logged payment for E5 - Ref NETO1VDBL2\n",
      "Logged payment for G1 - Ref E51UEHDPAY\n",
      "Logged payment for F3 - Ref V0Y8PZEQJT\n",
      "Logged payment for C1 - Ref DODA3U606Y\n",
      "Logged payment for C1 - Ref QEEPZOA346\n",
      "Logged payment for C2 - Ref TXATD1JTU8\n",
      "Logged payment for C2 - Ref 6JM8PR5IKJ\n",
      "Logged payment for D1 - Ref 6AG66Z923J\n",
      "Logged payment for B5 - Ref KI3EIYZVPA\n",
      "Logged payment for F3 - Ref 6R6XPCD8K6\n",
      "Logged payment for E4 - Ref RPVGM119T2\n",
      "Logged payment for B4 - Ref 0V05QHUDY5\n",
      "Logged payment for B1 - Ref 6XPFJSE84B\n",
      "Logged payment for A1 - Ref HYBZFXJSJ2\n",
      "Logged payment for D4 - Ref CMBBVPW8QM\n",
      "Logged payment for E5 - Ref PQDRUG7E8S\n",
      "Logged payment for G5 - Ref R4QPRUOXNC\n",
      "Logged payment for C1 - Ref TH0XKTQ64V\n",
      "Logged payment for B3 - Ref U9E0EN566G\n",
      "Logged payment for E2 - Ref Z8WLE5YSUS\n",
      "Logged payment for C5 - Ref MA9RJF77E4\n",
      "Logged payment for D6 - Ref 7SROZK4ETH\n",
      "Logged payment for D1 - Ref 399DRWMNOH\n",
      "Logged payment for F5 - Ref FM6T9JIIYX\n",
      "Logged payment for A1 - Ref 9Z559VB5AM\n",
      "Logged payment for A4 - Ref 9QKNXT7YSG\n",
      "Logged payment for F1 - Ref 55DVR91BXK\n",
      "Logged payment for E5 - Ref Z64LZ2NYS4\n",
      "Logged payment for G2 - Ref 91LIMU7EFW\n",
      "Logged payment for A4 - Ref V7YK603CRB\n",
      "Logged payment for D6 - Ref 0LX3DTX908\n",
      "Logged payment for E4 - Ref OCV44ZI91L\n",
      "Logged payment for A1 - Ref IWLQ0OMUBP\n",
      "Logged payment for A1 - Ref XDP3C0Z3OZ\n",
      "Logged payment for G1 - Ref MG8J6L0VHQ\n",
      "Logged payment for G2 - Ref NFNR8TTZDO\n",
      "Logged payment for E4 - Ref LTNZOT403X\n",
      "Logged payment for D3 - Ref 9QVIUXS7K9\n",
      "Logged payment for E6 - Ref Y7SRWCR8MB\n",
      "Logged payment for B4 - Ref FO7SSVLQYH\n",
      "Logged payment for G4 - Ref HXROI4YN80\n",
      "Logged payment for D6 - Ref 4UZAHI0RPP\n",
      "Logged payment for A2 - Ref SXKRQ4JG81\n",
      "Logged payment for D3 - Ref V26KBACQTB\n",
      "Logged payment for F5 - Ref 88RNU45QMV\n",
      "Logged payment for E4 - Ref QNU6KBDPYW\n",
      "Logged payment for G4 - Ref 6Q1CSKDAOH\n",
      "Logged payment for F4 - Ref ADZ76PIN0H\n",
      "Logged payment for E2 - Ref O8YRYVQW2W\n",
      "Logged payment for B1 - Ref EWE3S9R9T5\n",
      "Logged payment for A6 - Ref C2ME2KE0YY\n",
      "Logged payment for G1 - Ref 035BF3PQ45\n",
      "Logged payment for E5 - Ref IZ0R4E0E5D\n",
      "Logged payment for B3 - Ref 2C1MM86HRY\n",
      "Logged payment for A1 - Ref HPV4F6JZ80\n",
      "Logged payment for G1 - Ref G4989910W9\n",
      "Logged payment for E4 - Ref BEVRXPEC4C\n",
      "Logged payment for A3 - Ref 1KZMSC7GSG\n",
      "Logged payment for A5 - Ref J5K9L7OIEJ\n",
      "Logged payment for F2 - Ref OHOX78BMFN\n",
      "Logged payment for F3 - Ref E902IA06KX\n",
      "Logged payment for F4 - Ref JSYVVCX02O\n",
      "Logged payment for C2 - Ref STTYEVZR1V\n",
      "Logged payment for E2 - Ref SD9ZCFJMWK\n",
      "Logged payment for F3 - Ref HH1LH1T7PN\n",
      "Logged payment for A4 - Ref PG07QVSNS4\n",
      "Logged payment for F4 - Ref JA75S3VHG8\n",
      "Logged payment for E4 - Ref FIMVDWZ8OJ\n",
      "Logged payment for C6 - Ref OGWBLL5GUZ\n",
      "Logged payment for G5 - Ref CRKC9M9X9A\n",
      "Logged payment for F6 - Ref EMJMOV1TEL\n",
      "Logged payment for B4 - Ref G4HSP3KSIJ\n",
      "Logged payment for D1 - Ref 1H3BDLYTD1\n",
      "Logged payment for E5 - Ref IA05ES95RT\n",
      "Logged payment for B3 - Ref ADTJ8NK2NG\n",
      "Logged payment for D5 - Ref OYNRASA21M\n",
      "Logged payment for B2 - Ref 62J3UCGRWV\n",
      "Logged payment for F6 - Ref 3U4I6KN5XZ\n",
      "Logged payment for E2 - Ref KA0YXO42E2\n",
      "Logged payment for G3 - Ref GB0BSN2HH5\n",
      "Logged payment for G3 - Ref KK7PE340WZ\n",
      "Logged payment for C2 - Ref 1GTIT9XJY2\n",
      "Logged payment for B3 - Ref KQEOJYVBMQ\n",
      "Logged payment for B5 - Ref KB94IJBXZK\n",
      "Logged payment for A5 - Ref 5JK60K55HS\n",
      "Logged payment for B6 - Ref DG918O7407\n",
      "Logged payment for C1 - Ref AHQNKG9AD8\n",
      "Logged payment for G1 - Ref SDGU9GFT0R\n",
      "Logged payment for E2 - Ref OG6FMPROPV\n",
      "Logged payment for C5 - Ref Q3PB3PDPFC\n",
      "Logged payment for A1 - Ref GK4K8G08RN\n",
      "Logged payment for A5 - Ref HWX40ML0K7\n",
      "Logged payment for E1 - Ref R37VV0G7O9\n",
      "Logged payment for E5 - Ref 2JY9AO1GLB\n",
      "Logged payment for B3 - Ref KXK6NEAA6M\n",
      "Logged payment for F2 - Ref 3MDDPKFT53\n",
      "Logged payment for D2 - Ref G9RPDCD3N1\n",
      "Logged payment for A2 - Ref BPUFHZA5HO\n",
      "Logged payment for F2 - Ref 2OPZUBUX2E\n",
      "Logged payment for B1 - Ref V2GIYL65GK\n",
      "Logged payment for E6 - Ref KLX88O9S62\n",
      "Logged payment for F4 - Ref S66R8EGDRA\n",
      "Logged payment for F1 - Ref OJ2Z132NL3\n",
      "Logged payment for G3 - Ref ZF6MZRW314\n",
      "Logged payment for C2 - Ref HMEHQFOOVG\n",
      "Logged payment for D3 - Ref RQF5XJ2LOB\n",
      "Logged payment for C4 - Ref 6VYNLIK1HX\n",
      "Logged payment for B1 - Ref UILNUFXUEI\n",
      "Logged payment for A2 - Ref BOTTO7RSOV\n",
      "Logged payment for D3 - Ref CZZVT0V7EZ\n",
      "Logged payment for G2 - Ref TOQ82H9JR7\n",
      "Logged payment for B1 - Ref RJQIVJD4H4\n",
      "Logged payment for F5 - Ref EK03OR0JLQ\n",
      "Logged payment for D5 - Ref 8M9FQHDIU3\n",
      "Logged payment for G2 - Ref A1C0ABYU9J\n",
      "Logged payment for F3 - Ref BU7ECPCAUN\n",
      "Logged payment for E6 - Ref F24450UED8\n",
      "Logged payment for A2 - Ref OXM24L831N\n",
      "Logged payment for A5 - Ref 8OEPM2TG9N\n",
      "Logged payment for F3 - Ref 2QQMQOKFYJ\n",
      "Logged payment for B3 - Ref G5YDX6EH62\n",
      "Logged payment for B1 - Ref IQB86IM1HU\n",
      "Logged payment for D3 - Ref XOINEXDG1V\n",
      "Logged payment for D1 - Ref K5YALC8IW3\n",
      "Logged payment for A4 - Ref 9MB4QK3GEF\n",
      "Logged payment for E1 - Ref ML06IIE20U\n",
      "Logged payment for G3 - Ref BARWRWRENU\n",
      "Logged payment for B6 - Ref URI0WN9C84\n",
      "Logged payment for B3 - Ref FYHA8MEW2T\n",
      "Logged payment for G5 - Ref LINBDBMKBZ\n",
      "Logged payment for E1 - Ref 3RUJ6PXXQ4\n",
      "Logged payment for E1 - Ref 32YCAK78H3\n",
      "Logged payment for C2 - Ref KKPK8RA85P\n",
      "Logged payment for A3 - Ref GPB448BPQW\n",
      "Logged payment for F5 - Ref KTKJIBKXG6\n",
      "Logged payment for C6 - Ref 91KZ5E53AY\n",
      "Logged payment for E4 - Ref T0GFRWFQR6\n",
      "ProcessedRefs updated with 200 new refs.\n",
      "\n",
      "Updates per tenant sheet:\n",
      "A3 - Bradley_Turner: 6 payments appended\n",
      "C4 - Bobby_Alvarez: 2 payments appended\n",
      "D2 - Robert_Brown: 4 payments appended\n",
      "A6 - Paul_Moreno: 2 payments appended\n",
      "G4 - Jason_Reyes: 5 payments appended\n",
      "F6 - AutoAdded: 5 payments appended\n",
      "F1 - Deanna_Perkins: 4 payments appended\n",
      "G3 - Caleb_Casey: 8 payments appended\n",
      "F2 - Jonathan: 4 payments appended\n",
      "C3 - AutoAdded: 1 payments appended\n",
      "E1 - Jason: 5 payments appended\n",
      "D4 - AutoAdded: 4 payments appended\n",
      "C2 - Valerie_Frost: 7 payments appended\n",
      "G2 - Jessica_Tran: 7 payments appended\n",
      "A1 - AutoAdded: 7 payments appended\n",
      "B2 - AutoAdded: 3 payments appended\n",
      "E5 - AutoAdded: 8 payments appended\n",
      "G6 - Nicholas: 2 payments appended\n",
      "F3 - Sophia_Garcia: 8 payments appended\n",
      "B5 - Andrew_Johnson: 3 payments appended\n",
      "B3 - William: 8 payments appended\n",
      "E4 - John_Shannon: 8 payments appended\n",
      "C5 - Susan_Cook: 5 payments appended\n",
      "B1 - Jackie_Miller: 9 payments appended\n",
      "E3 - Todd_Harris: 2 payments appended\n",
      "D3 - Andrew_Hubbard: 6 payments appended\n",
      "G1 - AutoAdded: 7 payments appended\n",
      "D5 - Adam: 3 payments appended\n",
      "A2 - Lisa_Andrews: 6 payments appended\n",
      "B4 - Lauren_Lee: 4 payments appended\n",
      "A4 - Dawn_Mason: 5 payments appended\n",
      "B6 - Eric_Pruitt: 3 payments appended\n",
      "A5 - Misty_Kim: 5 payments appended\n",
      "F4 - Michael: 6 payments appended\n",
      "C1 - Grace_Huffman: 4 payments appended\n",
      "D1 - Michael_Thomas: 4 payments appended\n",
      "G5 - Roger_Mejia: 3 payments appended\n",
      "E2 - Jeremiah_Smith: 5 payments appended\n",
      "D6 - Mr._Robert_Elli: 3 payments appended\n",
      "F5 - Heidi_Rivera: 4 payments appended\n",
      "E6 - Karla_Myers: 3 payments appended\n",
      "C6 - Ryan_White: 2 payments appended\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Save PaymentHistory sheet\n",
    "payment_history_df.to_excel(writer, sheet_name='PaymentHistory', index=False)\n",
    "\n",
    "# --- 11. Update ProcessedRefs sheet\n",
    "try:\n",
    "    refs_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='ProcessedRefs')\n",
    "except Exception:\n",
    "    refs_df = pd.DataFrame({'Ref': []})\n",
    "if new_refs:\n",
    "    new_refs_df = pd.DataFrame({'Ref': new_refs})\n",
    "    updated_refs = pd.concat([refs_df, new_refs_df], ignore_index=True)\n",
    "    updated_refs.to_excel(writer, sheet_name='ProcessedRefs', index=False)\n",
    "    updates_log.append(f\"ProcessedRefs updated with {len(new_refs)} new refs.\")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"\\n--- Processing Summary ---\")\n",
    "for log in updates_log:\n",
    "    print(log)\n",
    "print(\"\\nUpdates per tenant sheet:\")\n",
    "for k, v in updates_per_sheet.items():\n",
    "    print(f\"{k}: {v} payments appended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecf57d",
   "metadata": {},
   "source": [
    "## PROTOTYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f050d",
   "metadata": {},
   "source": [
    "* Intergrating the proof of concept to the Google Platform\n",
    "* First is to create a dummy account on gmail and populate it with dummy emails as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458db27",
   "metadata": {},
   "source": [
    "### DUMMY EMAIL GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eda4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependencies for sending email notifications\n",
    "import base64, random, string, time, datetime\n",
    "from faker import Faker\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from email.mime.text import MIMEText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359afaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899105285450-50tdk35cnnrrich3nlr0d80kdp2qeovr.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A64255%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify&state=TYzmv311ajdCSUiS6AZT5qGNJ4rnHR&access_type=offline\n",
      "âœ…Â 200 dummy messages delivered to dmmccntdev@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# ---------- SEND 200 TEST EMAILS INTO SANDBOX GMAIL ----------\n",
    "\n",
    "fake = Faker()\n",
    "SCOPES = SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.send',     # to inject test mail\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/gmail.modify' # to call getProfile\n",
    "]\n",
    "flow   = InstalledAppFlow.from_client_secrets_file('bot_secret.json', SCOPES)\n",
    "creds  = flow.run_local_server(port=0)\n",
    "gmail  = build('gmail', 'v1', credentials=creds)\n",
    "user_email = gmail.users().getProfile(userId='me').execute()['emailAddress']\n",
    "\n",
    "accounts = [f\"{l}{n}\" for l in \"ABCDEFG\" for n in range(1,7)]\n",
    "def rand_ref(): return ''.join(random.choices(string.ascii_uppercase+string.digits, k=10))\n",
    "\n",
    "def make_msg(text):\n",
    "    m = MIMEText(text)\n",
    "    m['From'] = 'NCB <ncbcustomer@ncbgroup.com>'\n",
    "    m['To']   = user_email\n",
    "    m['Subject'] = 'NCBA TRANSACTIONS STATUS UPDATE'\n",
    "    return {'raw': base64.urlsafe_b64encode(m.as_bytes()).decode()}\n",
    "\n",
    "for _ in range(40):\n",
    "    code  = random.choice(accounts)\n",
    "    code_fragment = f\"#{code}\" if random.random()>.4 else code   # hash optional\n",
    "    amt   = f\"{random.randint(5,20)*1000:,}.00\"\n",
    "    name  = fake.name().upper()\n",
    "    phone = f\"0{random.randint(100,999)}***{random.randint(100,999)}\"\n",
    "    dt    = fake.date_time_this_year().strftime('%d/%m/%Y %I:%M %p')\n",
    "    ref   = rand_ref()\n",
    "    body  = (f\"Your M-Pesa payment of KES {amt} for account: PAYLEMAIYAN {code_fragment} \"\n",
    "             f\"has been received from {name} {phone} on {dt}. M-Pesa Ref: {ref}. NCBA, Go for it.\")\n",
    "    gmail.users().messages().send(userId='me', body=make_msg(body)).execute()\n",
    "    time.sleep(0.3) # Adjusted sleep time to avoid rate limits\n",
    "\n",
    "print(\"âœ…Â 40 dummy messages delivered to\", user_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243da59",
   "metadata": {},
   "source": [
    "### GOOGLE SHEET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc98e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD GSPREAD LIBRARIES FOR GOOGLE SHEETS ----------\n",
    "import pandas as pd, gspread, openpyxl\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efa219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap complete â€“ Google Sheet mirrors the Excel file.\n"
     ]
    }
   ],
   "source": [
    "# ---------- ONEâ€‘TIME MIGRATION EXCEL â†’ GOOGLE SHEETS ----------\n",
    "\n",
    "\n",
    "SRC_EXCEL = 'data/2025 RENT TRACKING - Lemaiyan Heights.xlsx'  # original data file\n",
    "DEST_SHEET = 'RENT TRACKING-Lemaiyan Heights' # New file in google sheets\n",
    "\n",
    "creds = Credentials.from_service_account_file('bot_service.json',\n",
    "    scopes=['https://www.googleapis.com/auth/spreadsheets',\n",
    "            'https://www.googleapis.com/auth/drive'])\n",
    "gc = gspread.authorize(creds)\n",
    "sh = gc.open(DEST_SHEET)\n",
    "\n",
    "wb = openpyxl.load_workbook(SRC_EXCEL, data_only=True)\n",
    "for ws in wb.worksheets:\n",
    "    title = ws.title[:99]  # Sheets title limit\n",
    "    if title in [s.title for s in sh.worksheets()]:\n",
    "        sheet = sh.worksheet(title)\n",
    "    else:\n",
    "        sheet = sh.add_worksheet(title, rows=2000, cols=10)\n",
    "\n",
    "    data = [[str(cell) if cell is not None else '' for cell in row] for row in ws.iter_rows(values_only=True)]\n",
    "    \n",
    "#   Update the sheets to populate\n",
    "    sheet.update(values=data, range_name='A1', value_input_option='USER_ENTERED')\n",
    "    time.sleep(2)  # Wait 2 seconds per write\n",
    "\n",
    "    # freeze first 7 rows and bold headers\n",
    "    sheet.format('1:7', {'textFormat': {'bold': True}})\n",
    "    sheet.freeze(rows=1)\n",
    "\n",
    "print(\"Bootstrap complete â€“ Google Sheet mirrors the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec35b08",
   "metadata": {},
   "source": [
    "### BOT-SERVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9ece92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899105285450-50tdk35cnnrrich3nlr0d80kdp2qeovr.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A64549%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send&state=RLSPJlljDsFVNMjhzgOmSIa4rLFqNV&access_type=offline\n",
      "ðŸ”Ž Searching Gmailâ€¦\n",
      "Found 200 candidate emails.\n",
      "âœ… Parsed 0 new payments.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Payments",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TotalAmount",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2d878edb-0973-4f76-ab37-627d588ff524",
       "rows": [
        [
         "0",
         "2025-01",
         "51",
         "682000"
        ],
        [
         "1",
         "2025-02",
         "42",
         "559000"
        ],
        [
         "2",
         "2025-03",
         "71",
         "853000"
        ],
        [
         "3",
         "2025-04",
         "68",
         "845000"
        ],
        [
         "4",
         "2025-05",
         "45",
         "545000"
        ],
        [
         "5",
         "2025-06",
         "54",
         "712000"
        ],
        [
         "6",
         "2025-07",
         "56",
         "690000"
        ],
        [
         "7",
         "2025-08",
         "28",
         "318000"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Payments</th>\n",
       "      <th>TotalAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01</td>\n",
       "      <td>51</td>\n",
       "      <td>682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02</td>\n",
       "      <td>42</td>\n",
       "      <td>559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>71</td>\n",
       "      <td>853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>68</td>\n",
       "      <td>845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>45</td>\n",
       "      <td>545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>54</td>\n",
       "      <td>712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>56</td>\n",
       "      <td>690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-08</td>\n",
       "      <td>28</td>\n",
       "      <td>318000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  Payments  TotalAmount\n",
       "0  2025-01        51       682000\n",
       "1  2025-02        42       559000\n",
       "2  2025-03        71       853000\n",
       "3  2025-04        68       845000\n",
       "4  2025-05        45       545000\n",
       "5  2025-06        54       712000\n",
       "6  2025-07        56       690000\n",
       "7  2025-08        28       318000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ BOT LOG ------\n",
      "\n",
      "Payments per tenant sheet:\n",
      "\n",
      "âœ… Prototype run complete.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "#  RENT RPA â€” PROTOTYPE\n",
    "#  Gmail -> Google Sheets\n",
    "# ================================\n",
    "\n",
    "import re, base64, time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.text import MIMEText\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Google APIs ---\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.oauth2.service_account import Credentials\n",
    "import gspread\n",
    "from gspread.utils import rowcol_to_a1\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CLIENT_SECRET = 'bot_secret.json'        # Gmail OAuth Desktop credentials\n",
    "SERVICE_KEY   = 'bot_service.json'      # Sheets service account (shared on the target Sheet)\n",
    "SHEET_NAME    = 'RENT TRACKING-Lemaiyan Heights'  # exact Google Sheet NAME\n",
    "GMAIL_QUERY   = 'subject:\"NCBA TRANSACTIONS STATUS UPDATE\" newer_than:365d'  # tweak as needed\n",
    "\n",
    "# This prototype uses a unified event schema for consistency:\n",
    "PAYMENT_COLS  = ['Date Paid','Amount Paid','REF Number','Payer','Phone','Payment Mode']\n",
    "MAX_PHONE_LEN = 13\n",
    "REF_LEN       = 10\n",
    "\n",
    "\n",
    "# ----- AUTH -----\n",
    "gmail_flow = InstalledAppFlow.from_client_secrets_file(\n",
    "    CLIENT_SECRET,\n",
    "    scopes=[\n",
    "        'https://www.googleapis.com/auth/gmail.modify',  # read + mark read\n",
    "        'https://www.googleapis.com/auth/gmail.readonly',\n",
    "        'https://www.googleapis.com/auth/gmail.send'\n",
    "    ]\n",
    ")\n",
    "gmail_creds = gmail_flow.run_local_server(port=0)\n",
    "gmail = build('gmail', 'v1', credentials=gmail_creds)\n",
    "\n",
    "sheets_creds = Credentials.from_service_account_file(\n",
    "    SERVICE_KEY,\n",
    "    scopes=['https://www.googleapis.com/auth/spreadsheets',\n",
    "            'https://www.googleapis.com/auth/drive'])\n",
    "gc = gspread.authorize(sheets_creds)\n",
    "sh = gc.open(SHEET_NAME)\n",
    "\n",
    "# ----- PARSER (flexible account code; 10-char ref) -----\n",
    "PATTERN = re.compile(\n",
    "    rf'payment of KES ([\\d,]+\\.\\d{{2}}) '\n",
    "    rf'for account: PAYLEMAIYAN\\s*#?\\s*([A-Za-z]\\d{{1,2}})'\n",
    "    rf' has been received from (.+?) '\n",
    "    rf'(.{{1,{MAX_PHONE_LEN}}}) '\n",
    "    rf'on (\\d{{2}}/\\d{{2}}/\\d{{4}} \\d{{1,2}}:\\d{{2}} [APM]{{2}})\\. '\n",
    "    rf'M-Pesa Ref: ([A-Z0-9]{{{REF_LEN}}})',\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_email(text: str):\n",
    "    m = PATTERN.search(text or \"\")\n",
    "    if not m:\n",
    "        return None\n",
    "    amt, code, payer, phone, dt, ref = m.groups()\n",
    "    return {\n",
    "        'Date Paid':   dt.strip(),                      # dd/mm/YYYY hh:mm AM/PM\n",
    "        'Amount Paid': float(amt.replace(',', '')),\n",
    "        'REF Number':  ref.upper(),\n",
    "        'Payer':       payer.strip(),\n",
    "        'Phone':       phone.strip(),\n",
    "        'Payment Mode':'MPESA Payment',\n",
    "        'AccountCode': code.upper(),                    # used for routing to the tenant sheet\n",
    "    }\n",
    "\n",
    "# ----- GMAIL: get message text (best-effort) -----\n",
    "def get_message_text(service, msg_id):\n",
    "    msg = service.users().messages().get(userId=\"me\", id=msg_id, format=\"full\").execute()\n",
    "    payload = msg.get(\"payload\", {})\n",
    "    body_texts = []\n",
    "\n",
    "    def walk(part):\n",
    "        mime = part.get(\"mimeType\", \"\")\n",
    "        data = part.get(\"body\", {}).get(\"data\")\n",
    "        parts = part.get(\"parts\", [])\n",
    "        if mime == \"text/plain\" and data:\n",
    "            body_texts.append(base64.urlsafe_b64decode(data).decode(\"utf-8\", errors=\"ignore\"))\n",
    "        for p in parts:\n",
    "            walk(p)\n",
    "\n",
    "    walk(payload)\n",
    "    if body_texts:\n",
    "        return \"\\n\".join(body_texts)\n",
    "    return msg.get(\"snippet\", \"\")\n",
    "\n",
    "# Normalizer: lower, trim, collapse spaces, strip punctuation/currency/nbsp\n",
    "_PUNCT = re.compile(r\"[^\\w\\s/]+\", re.UNICODE)\n",
    "def _norm(s):\n",
    "    if s is None: return \"\"\n",
    "    s = str(s).replace(\"\\xa0\", \" \")  # nbsp -> space\n",
    "    s = s.strip().lower()\n",
    "    s = _PUNCT.sub(\"\", s)            # remove punctuation like ( ), :, KES, etc.\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "# Broad alias sets (normalized)\n",
    "ALIASES = {\n",
    "    \"month\": {\n",
    "        \"month\",\"month/period\",\"period\",\"rent month\",\"billing month\"\n",
    "    },\n",
    "    \"amount_due\": {\n",
    "        \"amount due\",\"rent due\",\"due\",\"amountdue\",\"monthly rent\",\"rent\",\"amount due kes\",\"rent (kes)\"\n",
    "    },\n",
    "    \"amount_paid\": {\n",
    "        \"amount paid\",\"paid\",\"amt paid\",\"paid (kes)\",\"amountpaid\"\n",
    "    },\n",
    "    \"date_paid\": {\n",
    "        \"date paid\",\"paid date\",\"payment date\",\"datepaid\"\n",
    "    },\n",
    "    \"ref\": {\n",
    "        \"ref number\",\"ref\",\"reference\",\"ref no\",\"reference no\",\"mpesa ref\",\"mpesa reference\",\"receipt\",\"receipt no\"\n",
    "    },\n",
    "    \"date_due\": {\n",
    "        \"date due\",\"due date\",\"rent due date\",\"datedue\"\n",
    "    },\n",
    "    \"prepay_arrears\": {\n",
    "        \"prepayment/arrears\",\"prepayment\",\"arrears\",\"balance\",\"bal\",\"prepayment arrears\",\"carry forward\",\"cf\"\n",
    "    },\n",
    "    \"penalties\": {\n",
    "        \"penalties\",\"penalty\",\"late fee\",\"late fees\",\"fine\",\"fines\"\n",
    "    },\n",
    "}\n",
    "\n",
    "REQUIRED_KEYS = [\"month\",\"amount_due\",\"amount_paid\",\"date_paid\",\"ref\",\"date_due\",\"prepay_arrears\",\"penalties\"]\n",
    "\n",
    "# --- Helper to score header row ---\n",
    "def _score_header(row_norm):\n",
    "    \"\"\"How many required columns does this row satisfy?\"\"\"\n",
    "    hits = 0\n",
    "    for key in REQUIRED_KEYS:\n",
    "        if any(a in row_norm for a in ALIASES[key]):\n",
    "            hits += 1\n",
    "    return hits\n",
    "\n",
    "# --- Helper to map row tokens to column keys ---\n",
    "def _header_map_from_row(row):\n",
    "    \"\"\"Return (colmap) by matching normalized row tokens against aliases.\"\"\"\n",
    "    row_norm = [_norm(c) for c in row]\n",
    "    colmap = {}\n",
    "    for key, aliases in ALIASES.items():\n",
    "        for i, token in enumerate(row_norm):\n",
    "            if token in aliases:\n",
    "                colmap[key] = i\n",
    "                break\n",
    "    return colmap\n",
    "\n",
    "\n",
    "# --- Helper to detect or create a header row ---\n",
    "def _detect_or_create_header(ws):\n",
    "    \"\"\"\n",
    "    Find a header row in the first 10 rows.\n",
    "    If none reaches a threshold (>=4 matches), insert a standard header at row 1.\n",
    "    Returns (header_row_idx_0based, header_list, colmap).\n",
    "    \"\"\"\n",
    "    all_data = ws.get_all_values()\n",
    "    max_rows = len(all_data) if all_data else 1\n",
    "    probe_rows = min(max_rows, 10)\n",
    "    last_col = ws.col_count or 12\n",
    "    rn = f\"A1:{rowcol_to_a1(probe_rows, last_col)}\"\n",
    "    values = ws.get_values(rn)  # rectangular cut\n",
    "\n",
    "    best_idx, best_hits, best_map = None, -1, None\n",
    "    for idx, row in enumerate(values):\n",
    "        colmap = _header_map_from_row(row)\n",
    "        hits = len(colmap)\n",
    "        if hits > best_hits:\n",
    "            best_idx, best_hits, best_map = idx, hits, colmap\n",
    "\n",
    "    if best_hits >= 4:\n",
    "        header = ws.row_values(best_idx+1)\n",
    "        missing_keys = [k for k in REQUIRED_KEYS if k not in best_map]\n",
    "        if missing_keys:\n",
    "            standard_columns = {\n",
    "                \"month\": \"Month\",\n",
    "                \"amount_due\": \"Amount Due\",\n",
    "                \"amount_paid\": \"Amount paid\",\n",
    "                \"date_paid\": \"Date paid\",\n",
    "                \"ref\": \"REF Number\",\n",
    "                \"date_due\": \"Date due\",\n",
    "                \"prepay_arrears\": \"Prepayment/Arrears\",\n",
    "                \"penalties\": \"Penalties\"\n",
    "            }\n",
    "            for key in missing_keys:\n",
    "                header.append(standard_columns[key])\n",
    "            ws.update(values=[header], range_name=f\"{best_idx+1}:{best_idx+1}\", value_input_option=\"USER_ENTERED\")\n",
    "            best_map = _header_map_from_row(header)\n",
    "        return best_idx, header, best_map\n",
    "    # No good header found: create standard header on row 1\n",
    "    header = ['Month','Amount Due','Amount paid','Date paid','REF Number','Date due','Prepayment/Arrears','Penalties']\n",
    "    if max_rows == 0:\n",
    "        ws.update(values=[header], range_name=\"1:1\", value_input_option=\"USER_ENTERED\")\n",
    "    else:\n",
    "        ws.insert_row(header, index=1, value_input_option=\"USER_ENTERED\")\n",
    "    return 0, header, _header_map_from_row(header)\n",
    "\n",
    "\n",
    "# --- Helper to convert date string to month key ---\n",
    "def _month_key_from_date_str(date_str):\n",
    "    dt = datetime.strptime(date_str, '%d/%m/%Y %I:%M %p')\n",
    "    return dt.strftime('%B-%Y'), dt   # e.g., January-2025\n",
    "\n",
    "# --- Helper to find the month row in values ---\n",
    "def _find_month_row(values, month_col_idx, month_key):\n",
    "    for r in range(1, len(values)):  # skip header at 0\n",
    "        cell = str(values[r][month_col_idx]).strip()\n",
    "        if not cell:\n",
    "            continue\n",
    "        # accept \"Jan-2025\"/\"JAN 2025\"/\"January 2025\"\n",
    "        if cell.lower().startswith(month_key.lower()[:3]) and month_key[-4:] in cell:\n",
    "            return r\n",
    "    return None\n",
    "\n",
    "# --- Helper to convert row/col to letter(s) ---\n",
    "def _col_letter(row, col):\n",
    "    \"\"\"Return column letter(s) for a given 1-based row/col using A1 conversion.\"\"\"\n",
    "    return re.sub(r'\\d+', '', rowcol_to_a1(row, col))\n",
    "\n",
    "\n",
    "# --- Main function to update tenant month row ---\n",
    "def update_tenant_month_row(tenant_ws, payment):\n",
    "    \"\"\"\n",
    "    Realtime version:\n",
    "      - Writes ONLY: Amount paid, Date paid, REF Number\n",
    "      - Sets once-per-row formulas for:\n",
    "          Prepayment/Arrears = N(Amount paid) - N(Amount Due)\n",
    "          Penalties          = IF(DATEVALUE(LEFT(DatePaid,10)) > DATEVALUE(DateDue)+2, 3000, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- detect/insert header (uses your robust detector from the previous block) ---\n",
    "    header_row0, header, colmap = _detect_or_create_header(tenant_ws)\n",
    "    missing = [k for k in REQUIRED_KEYS if k not in colmap]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Sheet '{tenant_ws.title}' missing required columns after normalization: {missing}\")\n",
    "\n",
    "    # Reload values from header row downward\n",
    "    all_vals = tenant_ws.get_all_values()\n",
    "    vals = all_vals[header_row0:]\n",
    "    base_row_1based = header_row0 + 1\n",
    "\n",
    "    # --- find or create the month row ---\n",
    "    month_key, pay_dt = _month_key_from_date_str(payment['Date Paid'])\n",
    "    row_rel = _find_month_row(vals, colmap['month'], month_key)\n",
    "    if row_rel is None:\n",
    "        new_row = [''] * len(header)\n",
    "        new_row[colmap['month']] = month_key\n",
    "        new_row[colmap['amount_due']] = '0'\n",
    "        new_row[colmap['amount_paid']] = '0'\n",
    "        new_row[colmap['date_paid']] = ''\n",
    "        new_row[colmap['ref']] = ''\n",
    "        # Set Date due as the previous row's date due plus one month.\n",
    "        # Try to get last row's Date due (skip header row)\n",
    "        if len(vals) > 1 and vals[-1][colmap['date_due']]:\n",
    "            try:\n",
    "                last_date_due = datetime.strptime(vals[-1][colmap['date_due']], \"%d/%m/%Y\").replace(day=5)\n",
    "                new_date_due = last_date_due + relativedelta(months=1)\n",
    "            except Exception:\n",
    "            # Fallback to payment date plus one month if parsing fails\n",
    "                new_date_due = datetime.strptime(payment['Date Paid'], '%d/%m/%Y %I:%M %p') + relativedelta(months=1)\n",
    "        else:\n",
    "            new_date_due = datetime.strptime(payment['Date Paid'], '%d/%m/%Y %I:%M %p') + relativedelta(months=1)\n",
    "            new_row[colmap['date_due']] = new_date_due.strftime(\"%d/%m/%Y\")\n",
    "            \n",
    "        # prepay/arrears and penalties will be set as FORMULAS after append\n",
    "        tenant_ws.append_row(new_row, value_input_option='USER_ENTERED')\n",
    "        all_vals = tenant_ws.get_all_values()\n",
    "        vals = all_vals[header_row0:]\n",
    "        row_rel = len(vals) - 1\n",
    "\n",
    "    row_abs_1based = base_row_1based + row_rel\n",
    "    row = vals[row_rel]\n",
    "\n",
    "    # --- helpers to coerce numbers/strings ---\n",
    "    def _num(v):\n",
    "        try:\n",
    "            s = str(v).replace(',','').strip()\n",
    "            return float(s) if s else 0.0\n",
    "        except:\n",
    "            return 0.0\n",
    "    def _str(v):\n",
    "        return '' if v is None else str(v)\n",
    "\n",
    "    # current row values\n",
    "    due0   = _num(row[colmap['amount_due']])\n",
    "    paid0  = _num(row[colmap['amount_paid']])\n",
    "    ref0   = _str(row[colmap['ref']])\n",
    "\n",
    "    pay_amt = float(payment['Amount Paid'])\n",
    "\n",
    "    # (if you previously tracked arrears carryover in this cell, you can ignore that here\n",
    "    #  because the balance is now a live formula: Paid - Due)\n",
    "    paid1 = paid0 + pay_amt\n",
    "\n",
    "    # --- 1) write the three direct fields ---\n",
    "    updates = {\n",
    "        colmap['amount_paid']:  paid1,\n",
    "        colmap['date_paid']:    payment['Date Paid'],\n",
    "        colmap['ref']:          (payment['REF Number'] if not ref0 else f\"{ref0}, {payment['REF Number']}\")\n",
    "    }\n",
    "\n",
    "    # compact range write\n",
    "    touched = sorted(updates.keys())\n",
    "    c1 = touched[0] + 1\n",
    "    c2 = touched[-1] + 1\n",
    "    rng = f\"{rowcol_to_a1(row_abs_1based, c1)}:{rowcol_to_a1(row_abs_1based, c2)}\"\n",
    "    payload = [''] * (c2 - c1 + 1)\n",
    "    for cidx, val in updates.items():\n",
    "        payload[(cidx + 1 - c1)] = val\n",
    "    payload = [str(x) if x is not None else '' for x in payload]\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            tenant_ws.update(values=[payload], range_name=rng, value_input_option='USER_ENTERED')\n",
    "            break\n",
    "        except HttpError as e:\n",
    "            if getattr(e, \"resp\", None) and e.resp.status == 429:\n",
    "                time.sleep(5 * (attempt+1))\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "    # --- 2) ensure the formula cells are present (set once; theyâ€™ll recalc automatically) ---\n",
    "    col_letters = {k: _col_letter(row_abs_1based, colmap[k] + 1) for k in colmap}\n",
    "    # addresses for this row:\n",
    "    amt_paid_addr = f\"{col_letters['amount_paid']}{row_abs_1based}\"\n",
    "    amt_due_addr  = f\"{col_letters['amount_due']}{row_abs_1based}\"\n",
    "    date_paid_addr= f\"{col_letters['date_paid']}{row_abs_1based}\"\n",
    "    date_due_addr = f\"{col_letters['date_due']}{row_abs_1based}\"\n",
    "    bal_addr      = f\"{col_letters['prepay_arrears']}{row_abs_1based}\"\n",
    "    pen_addr      = f\"{col_letters['penalties']}{row_abs_1based}\"\n",
    "\n",
    "\n",
    "    # Penalties formula: if DatePaid > DateDue + 2 days, penalty = 3000\n",
    "    pen_formula = f\"=IF(DATEVALUE(LEFT({date_paid_addr},10))>DATEVALUE({date_due_addr})+2, 3000, 0)\"\n",
    "\n",
    "    # Balance formula: if first data row, =N(amt_paid)-N(amt_due); else, =N(prev_bal)+N(amt_paid)-N(amt_due)\n",
    "    if row_abs_1based == base_row_1based:\n",
    "        bal_formula = f\"=N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "    else:\n",
    "        prev_bal_addr = f\"{col_letters['prepay_arrears']}{row_abs_1based-1}\"\n",
    "        bal_formula = f\"=N({prev_bal_addr})+N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "    \n",
    "\n",
    "    # Only set if not already a formula (so we don't overwrite intentional manual values)\n",
    "    current_bal = tenant_ws.acell(bal_addr).value or \"\"\n",
    "    current_pen = tenant_ws.acell(pen_addr).value or \"\"\n",
    "    needs_bal = not str(current_bal).startswith(\"=\")\n",
    "    needs_pen = not str(current_pen).startswith(\"=\")\n",
    "\n",
    "    # Set any missing formulas in a single batch\n",
    "    body = []\n",
    "    if needs_bal:\n",
    "        body.append({'range': bal_addr, 'values': [[bal_formula]]})\n",
    "    if needs_pen:\n",
    "        body.append({'range': pen_addr, 'values': [[pen_formula]]})\n",
    "    if body:\n",
    "        tenant_ws.batch_update(body, value_input_option='USER_ENTERED')\n",
    "\n",
    "    # Return info (no computed numbers nowâ€”Sheet will reflect in realtime)\n",
    "    return {\n",
    "        'sheet': tenant_ws.title,\n",
    "        'month_row': row_abs_1based,\n",
    "        'paid_before': paid0,\n",
    "        'paid_after': paid1,\n",
    "        'ref_added': payment['REF Number'],\n",
    "        'formulas_set': {'balance': needs_bal, 'penalties': needs_pen},\n",
    "        'balance_addr': bal_addr,    \n",
    "        'penalties_addr': pen_addr       \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# ----- META SHEETS (ProcessedRefs, PaymentHistory) -----\n",
    "def ensure_meta(ws_name, header):\n",
    "    try:\n",
    "        ws = sh.worksheet(ws_name)\n",
    "    except gspread.WorksheetNotFound:\n",
    "        ws = sh.add_worksheet(ws_name, rows=2000, cols=max(10, len(header)))\n",
    "        ws.append_row(header)\n",
    "    return ws\n",
    "\n",
    "refs_ws = ensure_meta(\"ProcessedRefs\", [\"Ref\"])\n",
    "hist_ws = ensure_meta(\"PaymentHistory\", PAYMENT_COLS + ['AccountCode','TenantSheet','Month'])\n",
    "\n",
    "# Load processed refs into a set\n",
    "ref_vals = refs_ws.get_all_values()\n",
    "processed_refs = set((r[0] or '').upper() for r in ref_vals[1:]) if len(ref_vals) > 1 else set()\n",
    "\n",
    "# ----- GMAIL FETCH + PARSE -----\n",
    "print(\"ðŸ”Ž Searching Gmailâ€¦\")\n",
    "result = gmail.users().messages().list(userId=\"me\", q=GMAIL_QUERY, maxResults=200).execute()\n",
    "msg_list = result.get(\"messages\", [])\n",
    "print(f\"Found {len(msg_list)} candidate emails.\")\n",
    "\n",
    "parsed, errors = [], []\n",
    "for m in msg_list:\n",
    "    try:\n",
    "        text = get_message_text(gmail, m[\"id\"])\n",
    "        pay = parse_email(text)\n",
    "        if not pay:\n",
    "            errors.append(f\"Could not parse message id {m['id']}\")\n",
    "            continue\n",
    "        if pay['REF Number'] in processed_refs:\n",
    "            continue\n",
    "        parsed.append((m[\"id\"], pay))\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error reading message {m['id']}: {e}\")\n",
    "\n",
    "print(f\"âœ… Parsed {len(parsed)} new payments.\")\n",
    "\n",
    "# ----- APPLY: to tenant sheets + PaymentHistory + ProcessedRefs -----\n",
    "logs = []\n",
    "tenant_tally = {}\n",
    "\n",
    "# Cache worksheets to reduce calls\n",
    "worksheets = {ws.title: ws for ws in sh.worksheets()}\n",
    "\n",
    "def find_or_create_tenant_sheet(account_code: str):\n",
    "    for title, ws in worksheets.items():\n",
    "        t = title.upper()\n",
    "        if t.startswith(account_code) and 'PROCESSEDREFS' not in t and 'PAYMENTHISTORY' not in t:\n",
    "            return ws\n",
    "    title = f\"{account_code} - AutoAdded\"\n",
    "    ws = sh.add_worksheet(title, rows=1000, cols=12)\n",
    "    ws.update(values=[['Month','Amount Due','Amount paid','Date paid','REF Number','Date due','Prepayment/Arrears','Penalties']],\n",
    "              range_name='A1', value_input_option='USER_ENTERED')\n",
    "    ws.format('1:1', {'textFormat': {'bold': True}})\n",
    "    ws.freeze(rows=1)\n",
    "    worksheets[title] = ws\n",
    "    logs.append(f\"âž• Created tenant sheet: {title}\")\n",
    "    return ws\n",
    "\n",
    "for msg_id, p in parsed:\n",
    "    tenant_ws = find_or_create_tenant_sheet(p['AccountCode'])\n",
    "    info = update_tenant_month_row(tenant_ws, p)\n",
    "    # Read the live, recalculated values\n",
    "    logs.append(\n",
    "    f\"ðŸ§¾ {info['sheet']} R{info['month_row']} | \"\n",
    "    f\"Paid {info['paid_before']}â†’{info['paid_after']} | \"\n",
    "    f\"Ref {info['ref_added']} | Bal/penalties will auto-update in sheet\"\n",
    "    )\n",
    "    \n",
    "    tenant_tally[info['sheet']] = tenant_tally.get(info['sheet'], 0) + 1\n",
    "\n",
    "    # PaymentHistory\n",
    "    dt = datetime.strptime(p['Date Paid'], '%d/%m/%Y %I:%M %p')\n",
    "    mon = dt.strftime('%Y-%m')\n",
    "    hist_ws.append_row(\n",
    "        [p[k] for k in PAYMENT_COLS] + [p['AccountCode'], tenant_ws.title, mon],\n",
    "        value_input_option='USER_ENTERED'\n",
    "    )\n",
    "\n",
    "    # ProcessedRefs\n",
    "    refs_ws.append_row([p['REF Number']], value_input_option='RAW')\n",
    "    processed_refs.add(p['REF Number'])\n",
    "\n",
    "    # Mark Gmail read (optional)\n",
    "    try:\n",
    "        gmail.users().messages().modify(userId='me', id=msg_id, body={'removeLabelIds': ['UNREAD']}).execute()\n",
    "    except HttpError:\n",
    "        pass\n",
    "\n",
    "    time.sleep(2)  # throttle writes\n",
    "\n",
    "# ----- GROUPED MONTHLY SUMMARY (display) -----\n",
    "hist_vals = hist_ws.get_all_values()\n",
    "if len(hist_vals) > 1:\n",
    "    df = pd.DataFrame(hist_vals[1:], columns=hist_vals[0])\n",
    "    with pd.option_context('display.float_format', '{:,.2f}'.format):\n",
    "        df['Amount Paid'] = pd.to_numeric(df['Amount Paid'], errors='coerce').fillna(0.0)\n",
    "        grouped = df.groupby('Month', dropna=False).agg(\n",
    "            Payments=('REF Number','count'),\n",
    "            TotalAmount=('Amount Paid','sum')\n",
    "        ).reset_index().sort_values('Month')\n",
    "        display(grouped)\n",
    "else:\n",
    "    print(\"No payment history yet.\")\n",
    "\n",
    "# ----- LOGS -----\n",
    "print(\"\\n------ BOT LOG ------\")\n",
    "for line in logs:\n",
    "    print(line)\n",
    "print(\"\\nPayments per tenant sheet:\")\n",
    "for t, c in tenant_tally.items():\n",
    "    print(f\"  {t}: {c} payment(s)\")\n",
    "if errors:\n",
    "    print(\"\\nNon-fatal parse/read issues:\")\n",
    "    for e in errors:\n",
    "        print(\"  -\", e)\n",
    "print(\"\\nâœ… Prototype run complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067a70e",
   "metadata": {},
   "source": [
    "## DEPLOYMENT CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb35c02",
   "metadata": {},
   "source": [
    "* In this integration, we extend the proofâ€ofâ€concept prototype into a Streamlit app. The app retains the core functionality: â€¢ OAuth-based Google authentication to securely access Gmail, Google Sheets, and Drive. â€¢ Parsing payment notification emails with regular expressions. â€¢ Updating the relevant tenant sheets and maintaining meta data like ProcessedRefs and PaymentHistory.\n",
    "\n",
    "* Streamlit provides a user-friendly dashboard where users can trigger the payment bot and view real-time summaries and logs. This separation of the UI from the backend logic enables rapid deployment and easier scalability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "#  RENT RPA â€” Prototype (Patched to match deployment)\n",
    "#  Gmail -> Google Sheets (Realtime formulas, Quota-safe, Header robust)\n",
    "# ================================\n",
    "import re, base64, time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "import gspread\n",
    "\n",
    "from bot_logic import parse_email, update_tenant_month_row, PAYMENT_COLS\n",
    "\n",
    "CLIENT_SECRET = 'client_secret.json'   # OAuth desktop credentials (same project as Streamlit)\n",
    "SHEET_URL     = input(\"Paste your Google Sheet URL: \").strip()\n",
    "GMAIL_QUERY   = 'subject:\"NCBA TRANSACTIONS STATUS UPDATE\" newer_than:365d'\n",
    "THROTTLE_MS   = 250\n",
    "\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/gmail.modify\",\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "]\n",
    "\n",
    "def extract_sheet_id(url: str) -> str:\n",
    "    return url.split(\"/d/\")[1].split(\"/\")[0]\n",
    "\n",
    "def get_message_text(service, msg_id):\n",
    "    msg = service.users().messages().get(userId=\"me\", id=msg_id, format=\"full\").execute()\n",
    "    payload = msg.get(\"payload\", {})\n",
    "    body_texts = []\n",
    "    def walk(part):\n",
    "        mime = part.get(\"mimeType\", \"\")\n",
    "        data = part.get(\"body\", {}).get(\"data\")\n",
    "        parts = part.get(\"parts\", [])\n",
    "        if mime == \"text/plain\" and data:\n",
    "            body_texts.append(base64.urlsafe_b64decode(data).decode(\"utf-8\", errors=\"ignore\"))\n",
    "        for p in parts or []:\n",
    "            walk(p)\n",
    "    walk(payload)\n",
    "    if body_texts:\n",
    "        return \"\\n\".join(body_texts)\n",
    "    return msg.get(\"snippet\", \"\")\n",
    "\n",
    "# OAuth user login\n",
    "flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET, SCOPES)\n",
    "creds = flow.run_local_server(port=0)\n",
    "\n",
    "gmail = build(\"gmail\", \"v1\", credentials=creds)\n",
    "gc = gspread.authorize(creds)\n",
    "\n",
    "sheet_id = extract_sheet_id(SHEET_URL)\n",
    "sh = gc.open_by_key(sheet_id)\n",
    "\n",
    "# meta sheets\n",
    "def ensure_meta(ws_name, header):\n",
    "    try:\n",
    "        ws = sh.worksheet(ws_name)\n",
    "    except gspread.WorksheetNotFound:\n",
    "        ws = sh.add_worksheet(ws_name, rows=2000, cols=max(10, len(header)))\n",
    "        ws.append_row(header)\n",
    "    return ws\n",
    "\n",
    "refs_ws = ensure_meta(\"ProcessedRefs\", [\"Ref\"])\n",
    "hist_ws = ensure_meta(\"PaymentHistory\", PAYMENT_COLS + ['AccountCode','TenantSheet','Month'])\n",
    "\n",
    "# Load processed refs\n",
    "ref_vals = refs_ws.get_all_values()\n",
    "processed_refs = set((r[0] or '').upper() for r in ref_vals[1:]) if len(ref_vals) > 1 else set()\n",
    "\n",
    "print(\"ðŸ”Ž Searching Gmailâ€¦\")\n",
    "result = gmail.users().messages().list(userId=\"me\", q=GMAIL_QUERY, maxResults=200).execute()\n",
    "msg_list = result.get(\"messages\", [])\n",
    "print(f\"Found {len(msg_list)} candidate emails.\")\n",
    "\n",
    "parsed, errors = [], []\n",
    "for m in msg_list:\n",
    "    try:\n",
    "        text = get_message_text(gmail, m[\"id\"])\n",
    "        pay = parse_email(text)\n",
    "        if not pay:\n",
    "            errors.append(f\"Could not parse message id {m['id']}\")\n",
    "            continue\n",
    "        if pay['REF Number'] in processed_refs:\n",
    "            continue\n",
    "        parsed.append((m[\"id\"], pay))\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error reading message {m['id']}: {e}\")\n",
    "\n",
    "print(f\"âœ… Parsed {len(parsed)} new payments.\")\n",
    "\n",
    "logs = []\n",
    "worksheets = {ws.title: ws for ws in sh.worksheets()}\n",
    "\n",
    "def find_or_create_tenant_sheet(account_code: str):\n",
    "    for title, ws in worksheets.items():\n",
    "        t = title.upper()\n",
    "        if t.startswith(account_code) and 'PROCESSEDREFS' not in t and 'PAYMENTHISTORY' not in t:\n",
    "            return ws\n",
    "    title = f\"{account_code} - AutoAdded\"\n",
    "    ws = sh.add_worksheet(title, rows=1000, cols=12)\n",
    "    ws.update(values=[['Month','Amount Due','Amount paid','Date paid','REF Number','Date due','Prepayment/Arrears','Penalties']],\n",
    "              range_name='A1', value_input_option='USER_ENTERED')\n",
    "    ws.format('1:1', {'textFormat': {'bold': True}})\n",
    "    ws.freeze(rows=1)\n",
    "    worksheets[title] = ws\n",
    "    logs.append(f\"âž• Created tenant sheet: {title}\")\n",
    "    return ws\n",
    "\n",
    "for msg_id, p in parsed:\n",
    "    ws = find_or_create_tenant_sheet(p[\"AccountCode\"])\n",
    "    info = update_tenant_month_row(ws, p)\n",
    "\n",
    "    logs.append(\n",
    "        f\"ðŸ§¾ {info['sheet']} R{info['month_row']} | \"\n",
    "        f\"Paid {info['paid_before']}â†’{info['paid_after']} | \"\n",
    "        f\"Ref {info['ref_added']} | formulas set: {info['formulas_set']}\"\n",
    "    )\n",
    "\n",
    "    dt = datetime.strptime(p[\"Date Paid\"], \"%d/%m/%Y %I:%M %p\")\n",
    "    mon = dt.strftime(\"%Y-%m\")\n",
    "    hist_ws.append_row(\n",
    "        [p[k] for k in PAYMENT_COLS] + [p['AccountCode'], ws.title, mon],\n",
    "        value_input_option=\"USER_ENTERED\"\n",
    "    )\n",
    "    refs_ws.append_row([p[\"REF Number\"]], value_input_option=\"RAW\")\n",
    "    processed_refs.add(p[\"REF Number\"])\n",
    "\n",
    "    try:\n",
    "        gmail.users().messages().modify(userId='me', id=msg_id, body={'removeLabelIds': ['UNREAD']}).execute()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if THROTTLE_MS > 0:\n",
    "        time.sleep(THROTTLE_MS / 1000.0)\n",
    "\n",
    "hist_vals = hist_ws.get_all_values()\n",
    "if len(hist_vals) > 1:\n",
    "    df = pd.DataFrame(hist_vals[1:], columns=hist_vals[0])\n",
    "    with pd.option_context('display.float_format', '{:,.2f}'.format):\n",
    "        df[\"Amount Paid\"] = pd.to_numeric(df[\"Amount Paid\"], errors=\"coerce\").fillna(0.0)\n",
    "        grouped = df.groupby(\"Month\", dropna=False).agg(\n",
    "            Payments=(\"REF Number\",\"count\"),\n",
    "            TotalAmount=(\"Amount Paid\",\"sum\")\n",
    "        ).reset_index().sort_values(\"Month\")\n",
    "        display(grouped)\n",
    "else:\n",
    "    print(\"No PaymentHistory yet.\")\n",
    "\n",
    "print(\"\\n------ BOT LOG ------\")\n",
    "for line in logs:\n",
    "    print(line)\n",
    "if errors:\n",
    "    print(\"\\nNon-fatal parse/read issues:\")\n",
    "    for e in errors:\n",
    "        print(\"  -\", e)\n",
    "print(\"\\nâœ… Prototype (deployment-aligned) complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6711f",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Workflow Summary\n",
    "\n",
    "- **Project Overview:**  \n",
    "    Developed a rent automation bot for Lemaiyan Heights that processes payment notifications and tracks rent payment histories.\n",
    "\n",
    "- **Dummy Data Generation:**  \n",
    "    - Created a dummy dataset of email notifications to simulate incoming rent payment emails.  \n",
    "    - Utilized Faker for generating realistic customer names, phone numbers, dates, and payment amounts.\n",
    "\n",
    "- **Payment Parsing & Data Extraction:**  \n",
    "    - Developed regex-based functions to extract payment details (amount, account code, payer, phone, date, and reference) from email texts.\n",
    "    - Handled variable formatting and ensured proper deduplication using a set of processed payment references.\n",
    "\n",
    "- **Excel Workbook Management:**  \n",
    "    - Implemented logic to update an Excel workbook (`dummy_rent_tracker.xlsx`) with the parsed payment data.\n",
    "    - Managed multiple sheets: tenant-specific sheets, a master payment history, and a deduplication sheet (\"ProcessedRefs\").\n",
    "    - Used Pandas and openpyxl to read, update, and create sheets dynamically when a tenantâ€™s sheet was not found.\n",
    "\n",
    "- **Integration with Google Services:**  \n",
    "    - Extended the proof-of-concept to interact with Gmail and Google Sheets:\n",
    "        - Sent dummy emails into a Gmail sandbox for testing.\n",
    "        - Migrated data from Excel to Google Sheets.\n",
    "        - Automated the process to fetch emails, parse their content, and update the corresponding tenant sheets on Google Sheets in real time.\n",
    "    - Employed OAuth for secure access to Gmail and Google Sheets.\n",
    "\n",
    "- **Deployment and Prototyping:**  \n",
    "    - The final implementation was adapted for a deployment scenario, integrating with both Gmail and Google Sheets, and ensuring quota-safe operations.\n",
    "    - Streamlit was mentioned as a potential UI dashboard for triggering the payment bot and viewing realtime logs and summaries.\n",
    "\n",
    "This notebook documents the end-to-end automation of rent payment processing, from dummy email generation to real-time Google Sheets updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d42f76",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusions\n",
    "- The rent automation bot successfully simulates the processing of payment emails, extracting key information using regex.\n",
    "- Data is reliably logged into an Excel workbook with dedicated sheets for tenant details, payment history, and deduplication (ProcessedRefs).\n",
    "- Integration with Google services (Sheets and Gmail) demonstrates that the core functionality can be extended to a cloud-based, real-time workflow.\n",
    "- The use of Faker and dummy email generation confirms that the system can handle various data scenarios and potential edge cases.\n",
    "\n",
    "## Next Steps\n",
    "- Refine the data extraction process by enhancing regex patterns for even more robust parsing.\n",
    "- Develop a user-friendly dashboard (possibly with Streamlit) to monitor logs and trigger processes without directly modifying code.\n",
    "- Automate scheduling and deployment of the bot to run periodically (e.g., using cloud functions or cron jobs).\n",
    "- Implement detailed error handling and notifications for failed processing events.\n",
    "- Conduct thorough testing, including integration tests with real Gmail and Google Sheets accounts, before proceeding to production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cb1ce",
   "metadata": {},
   "source": [
    "## ðŸ‘¨â€ðŸ’» Author\n",
    "\n",
    "Eugene Maina\n",
    "Data Scientist | RPA Developer\n",
    "\n",
    "* [LinkedIn](https://www.linkedin.com/in/eugene-maina-4a8b9a128/) | [GitHub](https://github.com/eugene-maina72) | [Email](mailto:eugenemaina72@gmail.com)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartpath-streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
