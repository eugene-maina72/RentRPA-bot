{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23dbf1cd",
   "metadata": {},
   "source": [
    "# LEMAIYAN HEIGHTS RENT AUTOMATION BOT (PROOF OF CONCEPT, PROTOTYPE, DEPLOYMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96bfed",
   "metadata": {},
   "source": [
    "<img src= 'images\\rent bot.jpg' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d849538",
   "metadata": {},
   "source": [
    "## PROOF OF CONCEPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c84fb8",
   "metadata": {},
   "source": [
    "* Random generated dataset to simulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c261b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 200 dummy emails in data\\dummy_emails_200.txt\n",
      "Sample email:\n",
      " Dear Customer, your payment of KES 11000.00 for account: PAYLEMAIYAN #F2 has been received from Lindsey Mcdonald 750****163 on 18/05/2025 09:44 AM. M-Pesa Ref: 9AS60PSOXL\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define possible account codes (A1-A6, B1-B6, ..., G1-G6)\n",
    "accounts = [f\"{l}{n}\" for l in \"ABCDEFG\" for n in range(1, 7)]\n",
    "\n",
    "email_template = (\"Dear Customer, your payment of KES {amount} for account: PAYLEMAIYAN #{code} \"\n",
    "                  \"has been received from {name} {phone} on {date_time}. \"\n",
    "                  \"M-Pesa Ref: {mpesa_ref}\")\n",
    "def random_ref_code(length=10):\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=length))\n",
    "dummy_emails = []\n",
    "for _ in range(200):\n",
    "    amount = f\"{random.randint(5, 20) * 1000}.00\"\n",
    "    code = random.choice(accounts)\n",
    "    name = fake.name()\n",
    "    phone = f\"{random.randint(700, 799)}****{random.randint(100,999)}\"\n",
    "    date_time = fake.date_time_this_year().strftime('%d/%m/%Y %I:%M %p')\n",
    "    mpesa_ref = random_ref_code(10)\n",
    "    email_text = email_template.format(\n",
    "        amount=amount,\n",
    "        code=code,\n",
    "        name=name,\n",
    "        phone=phone,\n",
    "        date_time=date_time,\n",
    "        mpesa_ref=mpesa_ref\n",
    "    )\n",
    "    dummy_emails.append(email_text)\n",
    "\n",
    "# Save to data/dummy_emails_200.txt\n",
    "out_path = Path(\"data/dummy_emails_200.txt\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_path.write_text(\"\\n\\n\".join(dummy_emails))\n",
    "\n",
    "print(f\"Created {len(dummy_emails)} dummy emails in {out_path}\")\n",
    "print(\"Sample email:\\n\", dummy_emails[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b474a9c",
   "metadata": {},
   "source": [
    "* Logic engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa9290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 emails.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Reads MPESA email notifications from dummy_emails.txt,\n",
    "# Parses payment info, updates dummy_rent_tracker.xlsx,\n",
    "# Avoids double-logging by checking ProcessedRefs sheet.\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_DIR = Path('data')\n",
    "EMAIL_FILE = DATA_DIR / 'dummy_emails_200.txt'\n",
    "SPREADSHEET_FILE = DATA_DIR / 'dummy_rent_tracker.xlsx'\n",
    "\n",
    "# --- 1. Load Dummy Emails ---\n",
    "with open(EMAIL_FILE, 'r') as f:\n",
    "    email_texts = f.read().split('\\n\\n')\n",
    "\n",
    "print(f\"Loaded {len(email_texts)} emails.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532bc6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Customer, your payment of KES 5000.00 for account: PAYLEMAIYAN #F2 has been received from David Brown 722****274 on 13/03/2025 08:01 PM. M-Pesa Ref: OTRGYGKLJ4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_texts[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2107ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1250 previously processed refs.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Workbook and All Sheet Names ---\n",
    "wb = load_workbook(SPREADSHEET_FILE)\n",
    "sheet_names = wb.sheetnames\n",
    "\n",
    "# --- 3. Load ProcessedRefs (deduplication) ---\n",
    "try:\n",
    "    processed_refs_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='ProcessedRefs')\n",
    "    processed_refs = set(str(ref).strip().upper() for ref in processed_refs_df['Ref'] if pd.notna(ref))\n",
    "except Exception:\n",
    "    processed_refs = set()\n",
    "    print(\"ProcessedRefs sheet is empty or missing. Will create it.\")\n",
    "\n",
    "print(f\"Found {len(processed_refs)} previously processed refs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c46ab175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Regex Parser Function ---\n",
    "def extract_payment_info(email_body):\n",
    "    pattern = (\n",
    "        r'payment of KES ([\\d,]+\\.\\d{2}) '\n",
    "        r'for account: PAYLEMAIYAN\\s*#?\\s*([A-Za-z]\\d{1,2})'\n",
    "        r' has been received from (.+?) '\n",
    "        r'(.{1,13}) '\n",
    "        r'on (\\d{2}/\\d{2}/\\d{4} \\d{1,2}:\\d{2} [APM]{2})\\. '\n",
    "        r'M-Pesa Ref: ([\\w\\d]+)'\n",
    "    )\n",
    "    match = re.search(pattern, email_body, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        return {\n",
    "            'Amount': float(match.group(1).replace(',', '').strip()),\n",
    "            'AccountCode': match.group(2).strip().upper(),\n",
    "            'Payer': match.group(3).strip(),\n",
    "            'Phone': match.group(4).strip(),\n",
    "            'Date': match.group(5).strip(),\n",
    "            'Ref': match.group(6).strip().upper(),\n",
    "        }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f07c2627",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PhoneOrID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 65\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRef\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhoneOrID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayment Mode\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     60\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: [payment_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m'\u001b[39m: [payment_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRef\u001b[39m\u001b[38;5;124m'\u001b[39m: [payment_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRef\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayer\u001b[39m\u001b[38;5;124m'\u001b[39m: [payment_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayer\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhoneOrID\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[43mpayment_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhoneOrID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m],\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPayment Mode\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPESA Payment\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     67\u001b[0m })\n\u001b[0;32m     68\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, new_row], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     69\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39mtarget_sheet, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PhoneOrID'"
     ]
    }
   ],
   "source": [
    "# --- 5. Process Emails, Update or Create Sheets ---\n",
    "\n",
    "\n",
    "updates_log = []\n",
    "new_refs = []\n",
    "updates_per_sheet = {}\n",
    "\n",
    "# We'll use openpyxl to add new sheets if needed\n",
    "wb = load_workbook(SPREADSHEET_FILE)\n",
    "writer = pd.ExcelWriter(SPREADSHEET_FILE, engine='openpyxl', mode='a', if_sheet_exists='overlay')\n",
    "\n",
    "# Loading a Master payments file\n",
    "try:\n",
    "    payment_history_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='PaymentHistory')\n",
    "except Exception:\n",
    "    payment_history_df = pd.DataFrame(columns=[\n",
    "        'Date', 'Amount', 'Ref', 'Payer', 'Phone', 'Payment Mode', 'AccountCode', 'TenantSheet'\n",
    "    ])\n",
    "\n",
    "\n",
    "for email in email_texts:\n",
    "    payment_data = extract_payment_info(email)\n",
    "    if not payment_data:\n",
    "        updates_log.append(\"Skipped email: Could not parse payment info.\")\n",
    "        continue\n",
    "\n",
    "    ref = payment_data['Ref'].upper().strip()\n",
    "    if ref in processed_refs:\n",
    "        updates_log.append(f\"Duplicate ignored (Ref {ref})\")\n",
    "        continue\n",
    "\n",
    "    account_code = payment_data['AccountCode']\n",
    "    payer_name = payment_data['Payer'].replace(\" \", \"_\")[:15]\n",
    "    # Try to match an existing tenant sheet\n",
    "    target_sheet = None\n",
    "    for s in sheet_names:\n",
    "        # Take just the code part from the sheet name\n",
    "        sheet_token = s.split()[0].replace('-', '').upper().strip()\n",
    "        if account_code == sheet_token and 'PROCESSEDREFS' not in s.upper() and 'PAYMENTHISTORY' not in s.upper():\n",
    "            target_sheet = s\n",
    "            break\n",
    "\n",
    "    # --- 7. If no sheet found, CREATE it ---\n",
    "    if target_sheet is None:\n",
    "        target_sheet = f\"{account_code} - {payer_name if payer_name else 'AutoAdded'}\"\n",
    "        print(f\"Creating new sheet: {target_sheet} for new tenant {account_code}\")\n",
    "        new_tenant_df = pd.DataFrame(columns=[\n",
    "            'Date', 'Amount', 'Ref', 'Payer', 'PhoneOrID', 'Payment Mode'\n",
    "        ])\n",
    "        new_tenant_df.to_excel(writer, sheet_name=target_sheet, index=False)\n",
    "        updates_log.append(f\"Created new sheet: {target_sheet}\")\n",
    "        sheet_names.append(target_sheet)  # So we don't create it twice\n",
    "\n",
    "    # --- 8. Append payment to tenant sheet ---\n",
    "    try:\n",
    "        df = pd.read_excel(SPREADSHEET_FILE, sheet_name=target_sheet)\n",
    "    except Exception:\n",
    "        df = pd.DataFrame(columns=['Date', 'Amount', 'Ref', 'Payer', 'PhoneOrID', 'Payment Mode'])\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'Date': [payment_data['Date']],\n",
    "        'Amount': [payment_data['Amount']],\n",
    "        'Ref': [payment_data['Ref']],\n",
    "        'Payer': [payment_data['Payer']],\n",
    "        'PhoneOrID': [payment_data['PhoneOrID']],\n",
    "        'Payment Mode': ['MPESA Payment'],\n",
    "    })\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_excel(writer, sheet_name=target_sheet, index=False)\n",
    "    updates_log.append(f\"Logged payment for {account_code} - Ref {ref}\")\n",
    "    new_refs.append(ref)\n",
    "    updates_per_sheet.setdefault(target_sheet, 0)\n",
    "    updates_per_sheet[target_sheet] += 1\n",
    "\n",
    "     # --- 9. Add to PaymentHistory sheet ---\n",
    "    new_hist_row = new_row.copy()\n",
    "    new_hist_row['AccountCode'] = account_code\n",
    "    new_hist_row['TenantSheet'] = target_sheet\n",
    "    payment_history_df = pd.concat([payment_history_df, new_hist_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ccb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Logged payment for C3 - Ref EN2S5W1K15\n",
      "Logged payment for E3 - Ref TDPBK94WB3\n",
      "Logged payment for C3 - Ref 9R1ZXBXIEJ\n",
      "Logged payment for E1 - Ref 1A2SAZ6ZXY\n",
      "Logged payment for E4 - Ref MALRGW9Q2J\n",
      "Logged payment for E6 - Ref OUHOP1L40S\n",
      "Logged payment for C5 - Ref 6UC0B4NYFU\n",
      "Logged payment for D2 - Ref WNL2SRV9N6\n",
      "Logged payment for B1 - Ref 5TI40XT1D4\n",
      "Logged payment for E1 - Ref 2C3KQZ7RV0\n",
      "Logged payment for C6 - Ref Q58O0PQH3Y\n",
      "Logged payment for C1 - Ref V4NRV9PA11\n",
      "Logged payment for B5 - Ref JBWDP1V1PC\n",
      "Logged payment for B3 - Ref AT43F9BAA6\n",
      "Logged payment for A5 - Ref EHAUX3TWV0\n",
      "Logged payment for A3 - Ref FSYAFA45RE\n",
      "Logged payment for C2 - Ref X9NNQ4GARU\n",
      "Logged payment for F3 - Ref LDXV7I787L\n",
      "Logged payment for F4 - Ref VDYRMLQQZF\n",
      "Logged payment for A5 - Ref JJAUPU41ZN\n",
      "Logged payment for B1 - Ref L6IAV493B6\n",
      "Logged payment for B5 - Ref J7BQ1QBTCE\n",
      "Logged payment for D2 - Ref P3H9WOYU37\n",
      "Logged payment for G3 - Ref 09W6DXTO2R\n",
      "Logged payment for B5 - Ref WL1BPVYSDZ\n",
      "Logged payment for G4 - Ref KTQ9W73HM8\n",
      "Logged payment for E6 - Ref OMCZJEA9OG\n",
      "Logged payment for C3 - Ref CLD4STLL24\n",
      "Logged payment for C1 - Ref MO3KF72PQG\n",
      "Logged payment for G5 - Ref XX0NTHMLLL\n",
      "Logged payment for E1 - Ref 11QJ27AX8B\n",
      "Logged payment for D2 - Ref XYZQG30VYP\n",
      "Logged payment for F1 - Ref YZLP3WG5Y8\n",
      "Logged payment for B2 - Ref SXC355VY6V\n",
      "Logged payment for C4 - Ref 2IMOUW9MT3\n",
      "Logged payment for E3 - Ref N6V0JT7WAE\n",
      "Logged payment for A1 - Ref 6ZYLRMC6QY\n",
      "Logged payment for E2 - Ref 03R5G7DENZ\n",
      "Logged payment for F2 - Ref TBEJRO9M6H\n",
      "Logged payment for G6 - Ref 17SZ9RUTH5\n",
      "Logged payment for F6 - Ref IX7DOI3DH0\n",
      "Logged payment for G6 - Ref YI33S3UQZI\n",
      "Logged payment for A2 - Ref MN36ED0ROP\n",
      "Logged payment for D4 - Ref Y3U6EUDZMS\n",
      "Logged payment for E6 - Ref 2PFND9QVYA\n",
      "Logged payment for G5 - Ref O37DU01EJO\n",
      "Logged payment for D4 - Ref SYDN4DEPVA\n",
      "Logged payment for E4 - Ref Z7102CKSD0\n",
      "Logged payment for A6 - Ref MP9OYI9U00\n",
      "Logged payment for G6 - Ref Y5XNKJWWO9\n",
      "Logged payment for D3 - Ref CNXCGN7T0R\n",
      "Logged payment for C3 - Ref ZJYJ7IUJDN\n",
      "Logged payment for D6 - Ref 0J9FLJ0XLV\n",
      "Logged payment for G2 - Ref M118TKVXGC\n",
      "Logged payment for A3 - Ref KC7A90VSXX\n",
      "Logged payment for B5 - Ref 81Q87WY4GT\n",
      "Logged payment for E6 - Ref 674LNNZYBP\n",
      "Logged payment for G6 - Ref 9AEA1U6TGU\n",
      "Logged payment for D6 - Ref 0HHFJ1MGDM\n",
      "Logged payment for D3 - Ref QXYYBRSWGP\n",
      "Logged payment for B2 - Ref 8XQXUX16U6\n",
      "Logged payment for D2 - Ref 3CYM3F31AU\n",
      "Logged payment for A6 - Ref FQZWQCGI4Z\n",
      "Logged payment for E3 - Ref L0AWN972CC\n",
      "Logged payment for D6 - Ref P387MFMFEC\n",
      "Logged payment for D1 - Ref WXE4A0XY17\n",
      "Logged payment for D1 - Ref B6UHNQF6VV\n",
      "Logged payment for E3 - Ref MJYSGWWG5O\n",
      "Logged payment for G5 - Ref UV226YQ563\n",
      "Logged payment for A1 - Ref HWBDXDUY0V\n",
      "Logged payment for A3 - Ref IES1BNKSFR\n",
      "Logged payment for B3 - Ref 5IXPTFGV8Y\n",
      "Logged payment for B5 - Ref K13RKGA40Y\n",
      "Logged payment for B6 - Ref VAX9PPGXYJ\n",
      "Logged payment for G5 - Ref 5CXJTM6F9W\n",
      "Logged payment for B4 - Ref D8QP8E2BT6\n",
      "Logged payment for C1 - Ref 3RPDTZ6AZZ\n",
      "Logged payment for F3 - Ref GS4H3P0HKS\n",
      "Logged payment for A3 - Ref AS8JKG4045\n",
      "Logged payment for F4 - Ref 1E5ER8GKMG\n",
      "Logged payment for E4 - Ref GPI0447NKH\n",
      "Logged payment for D5 - Ref EJEEBTGWN5\n",
      "Logged payment for E6 - Ref 6K5642ZGHO\n",
      "Logged payment for C2 - Ref O4VAJWSHIY\n",
      "Logged payment for B2 - Ref ZG5HKZSKH7\n",
      "Logged payment for F6 - Ref IKSAUHU72C\n",
      "Logged payment for G6 - Ref NHG7YE071G\n",
      "Logged payment for C3 - Ref PZGGZ1DTG1\n",
      "Logged payment for A4 - Ref 3GGYAQWVG9\n",
      "Logged payment for A1 - Ref 5TG5KVDKC0\n",
      "Logged payment for B6 - Ref QOPQMXO0RS\n",
      "Logged payment for A2 - Ref EOHYBX2SMQ\n",
      "Logged payment for A6 - Ref 1SRE194UMA\n",
      "Logged payment for D4 - Ref 2B1Q60T4UU\n",
      "Logged payment for E5 - Ref BOSF7099J5\n",
      "Logged payment for A2 - Ref WIOHGWHQJR\n",
      "Logged payment for E2 - Ref 6NH4YH20TO\n",
      "Logged payment for G3 - Ref HRNU0FY9AQ\n",
      "Logged payment for D1 - Ref T8E2EZJ4EB\n",
      "Logged payment for C1 - Ref SWKRV4HJ5G\n",
      "Logged payment for D5 - Ref 8QKIG6M4WJ\n",
      "Logged payment for C3 - Ref RJTV3FHAQ9\n",
      "Logged payment for A5 - Ref GROOGP1GLG\n",
      "Logged payment for G4 - Ref 9935KSA0DO\n",
      "Logged payment for D6 - Ref 9HZTXH0S2Z\n",
      "Logged payment for A2 - Ref DOWBJUVYW1\n",
      "Logged payment for F4 - Ref I3E15UDDS1\n",
      "Logged payment for G2 - Ref D4Z64SURWL\n",
      "Logged payment for E2 - Ref 6OBF0T1VAU\n",
      "Logged payment for F1 - Ref ILB4R0RLRX\n",
      "Logged payment for E2 - Ref FDCT0QWNAG\n",
      "Logged payment for B5 - Ref B08QQTP7D9\n",
      "Logged payment for F6 - Ref CRSC3L8RE1\n",
      "Logged payment for B2 - Ref FBW86X5SBC\n",
      "Logged payment for C5 - Ref LFOGZK3ZWI\n",
      "Logged payment for D1 - Ref D3LECYEEFO\n",
      "Logged payment for G4 - Ref 7FVRPUWT9A\n",
      "Logged payment for F5 - Ref V0I9IOPHW0\n",
      "Logged payment for C2 - Ref HKT9XD74DM\n",
      "Logged payment for D2 - Ref J875CZFLHM\n",
      "Logged payment for F2 - Ref GONEXLA63X\n",
      "Logged payment for D1 - Ref UJ02KROGGO\n",
      "Logged payment for A3 - Ref O3FWCHOTVP\n",
      "Logged payment for B1 - Ref 8KR81S3TOB\n",
      "Logged payment for E5 - Ref 7IXFXJ2GZK\n",
      "Logged payment for A5 - Ref 69MBKSQYSO\n",
      "Logged payment for C4 - Ref IRADLNN7GD\n",
      "Logged payment for C4 - Ref DTV7MD467H\n",
      "Logged payment for B5 - Ref GXW4DCK8JB\n",
      "Logged payment for E5 - Ref FEUUOX3606\n",
      "Logged payment for E2 - Ref LD7EGK0UT0\n",
      "Logged payment for G1 - Ref JKREMEHUFX\n",
      "Logged payment for B2 - Ref H0IWIDDUWK\n",
      "Logged payment for A2 - Ref 2F7N9LNWG7\n",
      "Logged payment for G4 - Ref KHYN67CU5F\n",
      "Logged payment for A1 - Ref ZYBNMS68N4\n",
      "Logged payment for G1 - Ref 183A5T6ZM4\n",
      "Logged payment for F6 - Ref K7H7UMF9ZQ\n",
      "Logged payment for C5 - Ref P7CIK8218J\n",
      "Logged payment for E4 - Ref NXQ3Z6B7AH\n",
      "Logged payment for D5 - Ref S3PBF5RUHH\n",
      "Logged payment for D4 - Ref I0PJYZSOF0\n",
      "Logged payment for A4 - Ref F3J6TT1YQ3\n",
      "Logged payment for G5 - Ref N895LZ6QCS\n",
      "Logged payment for E2 - Ref STTIR9ZZXJ\n",
      "Logged payment for D5 - Ref S68Y7B2NVU\n",
      "Logged payment for B2 - Ref G3AD5E68GA\n",
      "Logged payment for G5 - Ref 9VARSBZBE1\n",
      "Logged payment for G6 - Ref JAEKBT06LA\n",
      "Logged payment for B2 - Ref 77JY75APLW\n",
      "Logged payment for C5 - Ref 244V5QO5SU\n",
      "Logged payment for F1 - Ref 55674ZQQJ0\n",
      "Logged payment for C4 - Ref Z49MBNUMKS\n",
      "Logged payment for A3 - Ref U1W7F0V3GN\n",
      "Logged payment for G3 - Ref 0BE47JCWHA\n",
      "Logged payment for B6 - Ref ED3ADFC8QY\n",
      "Logged payment for G5 - Ref SYX9V1DAQG\n",
      "Logged payment for E4 - Ref UQEPNUO8RC\n",
      "Logged payment for E6 - Ref T8BJA0DOTY\n",
      "Logged payment for A4 - Ref KJGFJS34G0\n",
      "Logged payment for D6 - Ref THSN8EL7BQ\n",
      "Logged payment for B1 - Ref 442LOLRX49\n",
      "Logged payment for C1 - Ref 98O7PS4DNG\n",
      "Logged payment for C1 - Ref 64X7WM72CP\n",
      "Logged payment for F2 - Ref UCFK53TQA5\n",
      "Logged payment for C1 - Ref FV8DKSBPSM\n",
      "Logged payment for G2 - Ref YRE9WQDYF7\n",
      "Logged payment for G1 - Ref 0QSNAX100U\n",
      "Logged payment for E5 - Ref 3JUVJBEFC7\n",
      "Logged payment for B2 - Ref 7V1057MR2N\n",
      "Logged payment for A4 - Ref 8KH6CMSO9J\n",
      "Logged payment for G4 - Ref S4D2EIPWCS\n",
      "Logged payment for G4 - Ref 7AF6BMDPQL\n",
      "Logged payment for C3 - Ref UXGQV66RFI\n",
      "Logged payment for B2 - Ref BAMD8291ZR\n",
      "Logged payment for C4 - Ref KSLR7HC28Z\n",
      "Logged payment for E5 - Ref Q2U44RPCK3\n",
      "Logged payment for E6 - Ref 718WOVGEQE\n",
      "Logged payment for D1 - Ref UDW3QWIBQG\n",
      "Logged payment for F3 - Ref QUTLZJN8JC\n",
      "Logged payment for E5 - Ref WOJV5L0YAX\n",
      "Logged payment for B1 - Ref FISKMI27RA\n",
      "Logged payment for E2 - Ref C9R6YC02I4\n",
      "Logged payment for D5 - Ref 3C8P6YYXB4\n",
      "Logged payment for C4 - Ref 8W9IPTZM8D\n",
      "Logged payment for D3 - Ref ALGJCHM0GA\n",
      "Logged payment for A1 - Ref WF8KKE2B6O\n",
      "Logged payment for E3 - Ref WSF60XDY4P\n",
      "Logged payment for F3 - Ref RO4B3GCRIN\n",
      "Logged payment for F5 - Ref XO8NJFOB3M\n",
      "Logged payment for E2 - Ref KSJOS87M64\n",
      "Logged payment for A5 - Ref R3LGGIFGRC\n",
      "Logged payment for C6 - Ref MX44C7MQYM\n",
      "Logged payment for G5 - Ref UFIIMB5TD8\n",
      "Logged payment for E1 - Ref O17MQ9ZDXV\n",
      "Logged payment for E4 - Ref XLEBTFF2ZG\n",
      "Logged payment for E2 - Ref CYXBSCGZLW\n",
      "Logged payment for A2 - Ref 7O1AKBXDTZ\n",
      "Logged payment for G2 - Ref DMHTSEV6JA\n",
      "Logged payment for C2 - Ref BSDNA17DDJ\n",
      "ProcessedRefs updated with 200 new refs.\n",
      "\n",
      "Updates per tenant sheet:\n",
      "C3 - AutoAdded: 7 payments appended\n",
      "E3 - Todd_Harris: 5 payments appended\n",
      "E1 - Jason: 4 payments appended\n",
      "E4 - John_Shannon: 6 payments appended\n",
      "E6 - Karla_Myers: 7 payments appended\n",
      "C5 - Susan_Cook: 4 payments appended\n",
      "D2 - Robert_Brown: 5 payments appended\n",
      "B1 - Jackie_Miller: 5 payments appended\n",
      "C6 - Ryan_White: 2 payments appended\n",
      "C1 - Grace_Huffman: 7 payments appended\n",
      "B5 - Andrew_Johnson: 7 payments appended\n",
      "B3 - William: 2 payments appended\n",
      "A5 - Misty_Kim: 5 payments appended\n",
      "A3 - Bradley_Turner: 6 payments appended\n",
      "C2 - Valerie_Frost: 4 payments appended\n",
      "F3 - Sophia_Garcia: 4 payments appended\n",
      "F4 - Michael: 3 payments appended\n",
      "G3 - Caleb_Casey: 3 payments appended\n",
      "G4 - Jason_Reyes: 6 payments appended\n",
      "G5 - Roger_Mejia: 8 payments appended\n",
      "F1 - Deanna_Perkins: 3 payments appended\n",
      "B2 - AutoAdded: 9 payments appended\n",
      "C4 - Bobby_Alvarez: 6 payments appended\n",
      "A1 - AutoAdded: 5 payments appended\n",
      "E2 - Jeremiah_Smith: 9 payments appended\n",
      "F2 - Jonathan: 3 payments appended\n",
      "G6 - Nicholas: 6 payments appended\n",
      "F6 - AutoAdded: 4 payments appended\n",
      "A2 - Lisa_Andrews: 6 payments appended\n",
      "D4 - AutoAdded: 4 payments appended\n",
      "A6 - Paul_Moreno: 3 payments appended\n",
      "D3 - Andrew_Hubbard: 3 payments appended\n",
      "D6 - Mr._Robert_Elli: 5 payments appended\n",
      "G2 - Jessica_Tran: 4 payments appended\n",
      "D1 - Michael_Thomas: 6 payments appended\n",
      "B6 - Eric_Pruitt: 3 payments appended\n",
      "B4 - Lauren_Lee: 1 payments appended\n",
      "D5 - Adam: 5 payments appended\n",
      "A4 - Dawn_Mason: 4 payments appended\n",
      "E5 - AutoAdded: 6 payments appended\n",
      "F5 - Heidi_Rivera: 2 payments appended\n",
      "G1 - AutoAdded: 3 payments appended\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Save PaymentHistory sheet\n",
    "payment_history_df.to_excel(writer, sheet_name='PaymentHistory', index=False)\n",
    "\n",
    "# --- 11. Update ProcessedRefs sheet\n",
    "try:\n",
    "    refs_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='ProcessedRefs')\n",
    "except Exception:\n",
    "    refs_df = pd.DataFrame({'Ref': []})\n",
    "if new_refs:\n",
    "    new_refs_df = pd.DataFrame({'Ref': new_refs})\n",
    "    updated_refs = pd.concat([refs_df, new_refs_df], ignore_index=True)\n",
    "    updated_refs.to_excel(writer, sheet_name='ProcessedRefs', index=False)\n",
    "    updates_log.append(f\"ProcessedRefs updated with {len(new_refs)} new refs.\")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"\\n--- Processing Summary ---\")\n",
    "for log in updates_log:\n",
    "    print(log)\n",
    "print(\"\\nUpdates per tenant sheet:\")\n",
    "for k, v in updates_per_sheet.items():\n",
    "    print(f\"{k}: {v} payments appended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecf57d",
   "metadata": {},
   "source": [
    "## PROTOTYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f050d",
   "metadata": {},
   "source": [
    "* Intergrating the proof of concept to the Google Platform\n",
    "* First is to create a dummy account on gmail and populate it with dummy emails as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458db27",
   "metadata": {},
   "source": [
    "### DUMMY EMAIL GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eda4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependencies for sending email notifications\n",
    "import base64, random, string, time, datetime\n",
    "from faker import Faker\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from email.mime.text import MIMEText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359afaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899105285450-50tdk35cnnrrich3nlr0d80kdp2qeovr.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A64255%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify&state=TYzmv311ajdCSUiS6AZT5qGNJ4rnHR&access_type=offline\n",
      "âœ…Â 200 dummy messages delivered to dmmccntdev@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# ---------- SEND 200 TEST EMAILS INTO SANDBOX GMAIL ----------\n",
    "\n",
    "fake = Faker()\n",
    "SCOPES = SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.send',     # to inject test mail\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/gmail.modify' # to call getProfile\n",
    "]\n",
    "flow   = InstalledAppFlow.from_client_secrets_file('bot_secret.json', SCOPES)\n",
    "creds  = flow.run_local_server(port=0)\n",
    "gmail  = build('gmail', 'v1', credentials=creds)\n",
    "user_email = gmail.users().getProfile(userId='me').execute()['emailAddress']\n",
    "\n",
    "accounts = [f\"{l}{n}\" for l in \"ABCDEFG\" for n in range(1,7)]\n",
    "def rand_ref(): return ''.join(random.choices(string.ascii_uppercase+string.digits, k=10))\n",
    "\n",
    "def make_msg(text):\n",
    "    m = MIMEText(text)\n",
    "    m['From'] = 'NCB <ncbcustomer@ncbgroup.com>'\n",
    "    m['To']   = user_email\n",
    "    m['Subject'] = 'NCBA TRANSACTIONS STATUS UPDATE'\n",
    "    return {'raw': base64.urlsafe_b64encode(m.as_bytes()).decode()}\n",
    "\n",
    "for _ in range(40):\n",
    "    code  = random.choice(accounts)\n",
    "    code_fragment = f\"#{code}\" if random.random()>.4 else code   # hash optional\n",
    "    amt   = f\"{random.randint(5,20)*1000:,}.00\"\n",
    "    name  = fake.name().upper()\n",
    "    phone = f\"0{random.randint(100,999)}***{random.randint(100,999)}\"\n",
    "    dt    = fake.date_time_this_year().strftime('%d/%m/%Y %I:%M %p')\n",
    "    ref   = rand_ref()\n",
    "    body  = (f\"Your M-Pesa payment of KES {amt} for account: PAYLEMAIYAN {code_fragment} \"\n",
    "             f\"has been received from {name} {phone} on {dt}. M-Pesa Ref: {ref}. NCBA, Go for it.\")\n",
    "    gmail.users().messages().send(userId='me', body=make_msg(body)).execute()\n",
    "    time.sleep(0.3) # Adjusted sleep time to avoid rate limits\n",
    "\n",
    "print(\"âœ…Â 40 dummy messages delivered to\", user_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243da59",
   "metadata": {},
   "source": [
    "### GOOGLE SHEET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc98e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD GSPREAD LIBRARIES FOR GOOGLE SHEETS ----------\n",
    "import pandas as pd, gspread, openpyxl\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efa219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap complete â€“ Google Sheet mirrors the Excel file.\n"
     ]
    }
   ],
   "source": [
    "# ---------- ONEâ€‘TIME MIGRATION EXCEL â†’ GOOGLE SHEETS ----------\n",
    "\n",
    "\n",
    "SRC_EXCEL = 'data/2025 RENT TRACKING - Lemaiyan Heights.xlsx'  # original data file\n",
    "DEST_SHEET = 'RENT TRACKING-Lemaiyan Heights' # New file in google sheets\n",
    "\n",
    "creds = Credentials.from_service_account_file('bot_service.json',\n",
    "    scopes=['https://www.googleapis.com/auth/spreadsheets',\n",
    "            'https://www.googleapis.com/auth/drive'])\n",
    "gc = gspread.authorize(creds)\n",
    "sh = gc.open(DEST_SHEET)\n",
    "\n",
    "wb = openpyxl.load_workbook(SRC_EXCEL, data_only=True)\n",
    "for ws in wb.worksheets:\n",
    "    title = ws.title[:99]  # Sheets title limit\n",
    "    if title in [s.title for s in sh.worksheets()]:\n",
    "        sheet = sh.worksheet(title)\n",
    "    else:\n",
    "        sheet = sh.add_worksheet(title, rows=2000, cols=10)\n",
    "\n",
    "    data = [[str(cell) if cell is not None else '' for cell in row] for row in ws.iter_rows(values_only=True)]\n",
    "    \n",
    "#   Update the sheets to populate\n",
    "    sheet.update(values=data, range_name='A1', value_input_option='USER_ENTERED')\n",
    "    time.sleep(2)  # Wait 2 seconds per write\n",
    "\n",
    "    # freeze first 7 rows and bold headers\n",
    "    sheet.format('1:7', {'textFormat': {'bold': True}})\n",
    "    sheet.freeze(rows=1)\n",
    "\n",
    "print(\"Bootstrap complete â€“ Google Sheet mirrors the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec35b08",
   "metadata": {},
   "source": [
    "### BOT-SERVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9ece92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899105285450-50tdk35cnnrrich3nlr0d80kdp2qeovr.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A64549%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send&state=RLSPJlljDsFVNMjhzgOmSIa4rLFqNV&access_type=offline\n",
      "ðŸ”Ž Searching Gmailâ€¦\n",
      "Found 200 candidate emails.\n",
      "âœ… Parsed 0 new payments.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Payments",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TotalAmount",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2d878edb-0973-4f76-ab37-627d588ff524",
       "rows": [
        [
         "0",
         "2025-01",
         "51",
         "682000"
        ],
        [
         "1",
         "2025-02",
         "42",
         "559000"
        ],
        [
         "2",
         "2025-03",
         "71",
         "853000"
        ],
        [
         "3",
         "2025-04",
         "68",
         "845000"
        ],
        [
         "4",
         "2025-05",
         "45",
         "545000"
        ],
        [
         "5",
         "2025-06",
         "54",
         "712000"
        ],
        [
         "6",
         "2025-07",
         "56",
         "690000"
        ],
        [
         "7",
         "2025-08",
         "28",
         "318000"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Payments</th>\n",
       "      <th>TotalAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01</td>\n",
       "      <td>51</td>\n",
       "      <td>682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02</td>\n",
       "      <td>42</td>\n",
       "      <td>559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>71</td>\n",
       "      <td>853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>68</td>\n",
       "      <td>845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>45</td>\n",
       "      <td>545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>54</td>\n",
       "      <td>712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>56</td>\n",
       "      <td>690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-08</td>\n",
       "      <td>28</td>\n",
       "      <td>318000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  Payments  TotalAmount\n",
       "0  2025-01        51       682000\n",
       "1  2025-02        42       559000\n",
       "2  2025-03        71       853000\n",
       "3  2025-04        68       845000\n",
       "4  2025-05        45       545000\n",
       "5  2025-06        54       712000\n",
       "6  2025-07        56       690000\n",
       "7  2025-08        28       318000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ BOT LOG ------\n",
      "\n",
      "Payments per tenant sheet:\n",
      "\n",
      "âœ… Prototype run complete.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "#  RENT RPA â€” PROTOTYPE\n",
    "#  Gmail -> Google Sheets\n",
    "# ================================\n",
    "\n",
    "import re, base64, time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.text import MIMEText\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Google APIs ---\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.oauth2.service_account import Credentials\n",
    "import gspread\n",
    "from gspread.utils import rowcol_to_a1\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CLIENT_SECRET = 'bot_secret.json'        # Gmail OAuth Desktop credentials\n",
    "SERVICE_KEY   = 'bot_service.json'      # Sheets service account (shared on the target Sheet)\n",
    "SHEET_NAME    = 'RENT TRACKING-Lemaiyan Heights'  # exact Google Sheet NAME\n",
    "GMAIL_QUERY   = 'subject:\"NCBA TRANSACTIONS STATUS UPDATE\" newer_than:365d'  # tweak as needed\n",
    "\n",
    "# This prototype uses a unified event schema for consistency:\n",
    "PAYMENT_COLS  = ['Date Paid','Amount Paid','REF Number','Payer','Phone','Payment Mode']\n",
    "MAX_PHONE_LEN = 13\n",
    "REF_LEN       = 10\n",
    "\n",
    "\n",
    "# ----- AUTH -----\n",
    "gmail_flow = InstalledAppFlow.from_client_secrets_file(\n",
    "    CLIENT_SECRET,\n",
    "    scopes=[\n",
    "        'https://www.googleapis.com/auth/gmail.modify',  # read + mark read\n",
    "        'https://www.googleapis.com/auth/gmail.readonly',\n",
    "        'https://www.googleapis.com/auth/gmail.send'\n",
    "    ]\n",
    ")\n",
    "gmail_creds = gmail_flow.run_local_server(port=0)\n",
    "gmail = build('gmail', 'v1', credentials=gmail_creds)\n",
    "\n",
    "sheets_creds = Credentials.from_service_account_file(\n",
    "    SERVICE_KEY,\n",
    "    scopes=['https://www.googleapis.com/auth/spreadsheets',\n",
    "            'https://www.googleapis.com/auth/drive'])\n",
    "gc = gspread.authorize(sheets_creds)\n",
    "sh = gc.open(SHEET_NAME)\n",
    "\n",
    "# ----- PARSER (flexible account code; 10-char ref) -----\n",
    "PATTERN = re.compile(\n",
    "    rf'payment of KES ([\\d,]+\\.\\d{{2}}) '\n",
    "    rf'for account: PAYLEMAIYAN\\s*#?\\s*([A-Za-z]\\d{{1,2}})'\n",
    "    rf' has been received from (.+?) '\n",
    "    rf'(.{{1,{MAX_PHONE_LEN}}}) '\n",
    "    rf'on (\\d{{2}}/\\d{{2}}/\\d{{4}} \\d{{1,2}}:\\d{{2}} [APM]{{2}})\\. '\n",
    "    rf'M-Pesa Ref: ([A-Z0-9]{{{REF_LEN}}})',\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_email(text: str):\n",
    "    m = PATTERN.search(text or \"\")\n",
    "    if not m:\n",
    "        return None\n",
    "    amt, code, payer, phone, dt, ref = m.groups()\n",
    "    return {\n",
    "        'Date Paid':   dt.strip(),                      # dd/mm/YYYY hh:mm AM/PM\n",
    "        'Amount Paid': float(amt.replace(',', '')),\n",
    "        'REF Number':  ref.upper(),\n",
    "        'Payer':       payer.strip(),\n",
    "        'Phone':       phone.strip(),\n",
    "        'Payment Mode':'MPESA Payment',\n",
    "        'AccountCode': code.upper(),                    # used for routing to the tenant sheet\n",
    "    }\n",
    "\n",
    "# ----- GMAIL: get message text (best-effort) -----\n",
    "def get_message_text(service, msg_id):\n",
    "    msg = service.users().messages().get(userId=\"me\", id=msg_id, format=\"full\").execute()\n",
    "    payload = msg.get(\"payload\", {})\n",
    "    body_texts = []\n",
    "\n",
    "    def walk(part):\n",
    "        mime = part.get(\"mimeType\", \"\")\n",
    "        data = part.get(\"body\", {}).get(\"data\")\n",
    "        parts = part.get(\"parts\", [])\n",
    "        if mime == \"text/plain\" and data:\n",
    "            body_texts.append(base64.urlsafe_b64decode(data).decode(\"utf-8\", errors=\"ignore\"))\n",
    "        for p in parts:\n",
    "            walk(p)\n",
    "\n",
    "    walk(payload)\n",
    "    if body_texts:\n",
    "        return \"\\n\".join(body_texts)\n",
    "    return msg.get(\"snippet\", \"\")\n",
    "\n",
    "# Normalizer: lower, trim, collapse spaces, strip punctuation/currency/nbsp\n",
    "_PUNCT = re.compile(r\"[^\\w\\s/]+\", re.UNICODE)\n",
    "def _norm(s):\n",
    "    if s is None: return \"\"\n",
    "    s = str(s).replace(\"\\xa0\", \" \")  # nbsp -> space\n",
    "    s = s.strip().lower()\n",
    "    s = _PUNCT.sub(\"\", s)            # remove punctuation like ( ), :, KES, etc.\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "# Broad alias sets (normalized)\n",
    "ALIASES = {\n",
    "    \"month\": {\n",
    "        \"month\",\"month/period\",\"period\",\"rent month\",\"billing month\"\n",
    "    },\n",
    "    \"amount_due\": {\n",
    "        \"amount due\",\"rent due\",\"due\",\"amountdue\",\"monthly rent\",\"rent\",\"amount due kes\",\"rent (kes)\"\n",
    "    },\n",
    "    \"amount_paid\": {\n",
    "        \"amount paid\",\"paid\",\"amt paid\",\"paid (kes)\",\"amountpaid\"\n",
    "    },\n",
    "    \"date_paid\": {\n",
    "        \"date paid\",\"paid date\",\"payment date\",\"datepaid\"\n",
    "    },\n",
    "    \"ref\": {\n",
    "        \"ref number\",\"ref\",\"reference\",\"ref no\",\"reference no\",\"mpesa ref\",\"mpesa reference\",\"receipt\",\"receipt no\"\n",
    "    },\n",
    "    \"date_due\": {\n",
    "        \"date due\",\"due date\",\"rent due date\",\"datedue\"\n",
    "    },\n",
    "    \"prepay_arrears\": {\n",
    "        \"prepayment/arrears\",\"prepayment\",\"arrears\",\"balance\",\"bal\",\"prepayment arrears\",\"carry forward\",\"cf\"\n",
    "    },\n",
    "    \"penalties\": {\n",
    "        \"penalties\",\"penalty\",\"late fee\",\"late fees\",\"fine\",\"fines\"\n",
    "    },\n",
    "}\n",
    "\n",
    "REQUIRED_KEYS = [\"month\",\"amount_due\",\"amount_paid\",\"date_paid\",\"ref\",\"date_due\",\"prepay_arrears\",\"penalties\"]\n",
    "\n",
    "# --- Helper to score header row ---\n",
    "def _score_header(row_norm):\n",
    "    \"\"\"How many required columns does this row satisfy?\"\"\"\n",
    "    hits = 0\n",
    "    for key in REQUIRED_KEYS:\n",
    "        if any(a in row_norm for a in ALIASES[key]):\n",
    "            hits += 1\n",
    "    return hits\n",
    "\n",
    "# --- Helper to map row tokens to column keys ---\n",
    "def _header_map_from_row(row):\n",
    "    \"\"\"Return (colmap) by matching normalized row tokens against aliases.\"\"\"\n",
    "    row_norm = [_norm(c) for c in row]\n",
    "    colmap = {}\n",
    "    for key, aliases in ALIASES.items():\n",
    "        for i, token in enumerate(row_norm):\n",
    "            if token in aliases:\n",
    "                colmap[key] = i\n",
    "                break\n",
    "    return colmap\n",
    "\n",
    "\n",
    "# --- Helper to detect or create a header row ---\n",
    "def _detect_or_create_header(ws):\n",
    "    \"\"\"\n",
    "    Find a header row in the first 10 rows.\n",
    "    If none reaches a threshold (>=4 matches), insert a standard header at row 1.\n",
    "    Returns (header_row_idx_0based, header_list, colmap).\n",
    "    \"\"\"\n",
    "    all_data = ws.get_all_values()\n",
    "    max_rows = len(all_data) if all_data else 1\n",
    "    probe_rows = min(max_rows, 10)\n",
    "    last_col = ws.col_count or 12\n",
    "    rn = f\"A1:{rowcol_to_a1(probe_rows, last_col)}\"\n",
    "    values = ws.get_values(rn)  # rectangular cut\n",
    "\n",
    "    best_idx, best_hits, best_map = None, -1, None\n",
    "    for idx, row in enumerate(values):\n",
    "        colmap = _header_map_from_row(row)\n",
    "        hits = len(colmap)\n",
    "        if hits > best_hits:\n",
    "            best_idx, best_hits, best_map = idx, hits, colmap\n",
    "\n",
    "    if best_hits >= 4:\n",
    "        header = ws.row_values(best_idx+1)\n",
    "        missing_keys = [k for k in REQUIRED_KEYS if k not in best_map]\n",
    "        if missing_keys:\n",
    "            standard_columns = {\n",
    "                \"month\": \"Month\",\n",
    "                \"amount_due\": \"Amount Due\",\n",
    "                \"amount_paid\": \"Amount paid\",\n",
    "                \"date_paid\": \"Date paid\",\n",
    "                \"ref\": \"REF Number\",\n",
    "                \"date_due\": \"Date due\",\n",
    "                \"prepay_arrears\": \"Prepayment/Arrears\",\n",
    "                \"penalties\": \"Penalties\"\n",
    "            }\n",
    "            for key in missing_keys:\n",
    "                header.append(standard_columns[key])\n",
    "            ws.update(values=[header], range_name=f\"{best_idx+1}:{best_idx+1}\", value_input_option=\"USER_ENTERED\")\n",
    "            best_map = _header_map_from_row(header)\n",
    "        return best_idx, header, best_map\n",
    "    # No good header found: create standard header on row 1\n",
    "    header = ['Month','Amount Due','Amount paid','Date paid','REF Number','Date due','Prepayment/Arrears','Penalties']\n",
    "    if max_rows == 0:\n",
    "        ws.update(values=[header], range_name=\"1:1\", value_input_option=\"USER_ENTERED\")\n",
    "    else:\n",
    "        ws.insert_row(header, index=1, value_input_option=\"USER_ENTERED\")\n",
    "    return 0, header, _header_map_from_row(header)\n",
    "\n",
    "\n",
    "# --- Helper to convert date string to month key ---\n",
    "def _month_key_from_date_str(date_str):\n",
    "    dt = datetime.strptime(date_str, '%d/%m/%Y %I:%M %p')\n",
    "    return dt.strftime('%B-%Y'), dt   # e.g., January-2025\n",
    "\n",
    "# --- Helper to find the month row in values ---\n",
    "def _find_month_row(values, month_col_idx, month_key):\n",
    "    for r in range(1, len(values)):  # skip header at 0\n",
    "        cell = str(values[r][month_col_idx]).strip()\n",
    "        if not cell:\n",
    "            continue\n",
    "        # accept \"Jan-2025\"/\"JAN 2025\"/\"January 2025\"\n",
    "        if cell.lower().startswith(month_key.lower()[:3]) and month_key[-4:] in cell:\n",
    "            return r\n",
    "    return None\n",
    "\n",
    "# --- Helper to convert row/col to letter(s) ---\n",
    "def _col_letter(row, col):\n",
    "    \"\"\"Return column letter(s) for a given 1-based row/col using A1 conversion.\"\"\"\n",
    "    return re.sub(r'\\d+', '', rowcol_to_a1(row, col))\n",
    "\n",
    "\n",
    "# --- Main function to update tenant month row ---\n",
    "def update_tenant_month_row(tenant_ws, payment):\n",
    "    \"\"\"\n",
    "    Realtime version:\n",
    "      - Writes ONLY: Amount paid, Date paid, REF Number\n",
    "      - Sets once-per-row formulas for:\n",
    "          Prepayment/Arrears = N(Amount paid) - N(Amount Due)\n",
    "          Penalties          = IF(DATEVALUE(LEFT(DatePaid,10)) > DATEVALUE(DateDue)+2, 3000, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- detect/insert header (uses your robust detector from the previous block) ---\n",
    "    header_row0, header, colmap = _detect_or_create_header(tenant_ws)\n",
    "    missing = [k for k in REQUIRED_KEYS if k not in colmap]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Sheet '{tenant_ws.title}' missing required columns after normalization: {missing}\")\n",
    "\n",
    "    # Reload values from header row downward\n",
    "    all_vals = tenant_ws.get_all_values()\n",
    "    vals = all_vals[header_row0:]\n",
    "    base_row_1based = header_row0 + 1\n",
    "\n",
    "    # --- find or create the month row ---\n",
    "    month_key, pay_dt = _month_key_from_date_str(payment['Date Paid'])\n",
    "    row_rel = _find_month_row(vals, colmap['month'], month_key)\n",
    "    if row_rel is None:\n",
    "        new_row = [''] * len(header)\n",
    "        new_row[colmap['month']] = month_key\n",
    "        new_row[colmap['amount_due']] = '0'\n",
    "        new_row[colmap['amount_paid']] = '0'\n",
    "        new_row[colmap['date_paid']] = ''\n",
    "        new_row[colmap['ref']] = ''\n",
    "        # Set Date due as the previous row's date due plus one month.\n",
    "        # Try to get last row's Date due (skip header row)\n",
    "        if len(vals) > 1 and vals[-1][colmap['date_due']]:\n",
    "            try:\n",
    "                last_date_due = datetime.strptime(vals[-1][colmap['date_due']], \"%d/%m/%Y\").replace(day=5)\n",
    "                new_date_due = last_date_due + relativedelta(months=1)\n",
    "            except Exception:\n",
    "            # Fallback to payment date plus one month if parsing fails\n",
    "                new_date_due = datetime.strptime(payment['Date Paid'], '%d/%m/%Y %I:%M %p') + relativedelta(months=1)\n",
    "        else:\n",
    "            new_date_due = datetime.strptime(payment['Date Paid'], '%d/%m/%Y %I:%M %p') + relativedelta(months=1)\n",
    "            new_row[colmap['date_due']] = new_date_due.strftime(\"%d/%m/%Y\")\n",
    "            \n",
    "        # prepay/arrears and penalties will be set as FORMULAS after append\n",
    "        tenant_ws.append_row(new_row, value_input_option='USER_ENTERED')\n",
    "        all_vals = tenant_ws.get_all_values()\n",
    "        vals = all_vals[header_row0:]\n",
    "        row_rel = len(vals) - 1\n",
    "\n",
    "    row_abs_1based = base_row_1based + row_rel\n",
    "    row = vals[row_rel]\n",
    "\n",
    "    # --- helpers to coerce numbers/strings ---\n",
    "    def _num(v):\n",
    "        try:\n",
    "            s = str(v).replace(',','').strip()\n",
    "            return float(s) if s else 0.0\n",
    "        except:\n",
    "            return 0.0\n",
    "    def _str(v):\n",
    "        return '' if v is None else str(v)\n",
    "\n",
    "    # current row values\n",
    "    due0   = _num(row[colmap['amount_due']])\n",
    "    paid0  = _num(row[colmap['amount_paid']])\n",
    "    ref0   = _str(row[colmap['ref']])\n",
    "\n",
    "    pay_amt = float(payment['Amount Paid'])\n",
    "\n",
    "    # (if you previously tracked arrears carryover in this cell, you can ignore that here\n",
    "    #  because the balance is now a live formula: Paid - Due)\n",
    "    paid1 = paid0 + pay_amt\n",
    "\n",
    "    # --- 1) write the three direct fields ---\n",
    "    updates = {\n",
    "        colmap['amount_paid']:  paid1,\n",
    "        colmap['date_paid']:    payment['Date Paid'],\n",
    "        colmap['ref']:          (payment['REF Number'] if not ref0 else f\"{ref0}, {payment['REF Number']}\")\n",
    "    }\n",
    "\n",
    "    # compact range write\n",
    "    touched = sorted(updates.keys())\n",
    "    c1 = touched[0] + 1\n",
    "    c2 = touched[-1] + 1\n",
    "    rng = f\"{rowcol_to_a1(row_abs_1based, c1)}:{rowcol_to_a1(row_abs_1based, c2)}\"\n",
    "    payload = [''] * (c2 - c1 + 1)\n",
    "    for cidx, val in updates.items():\n",
    "        payload[(cidx + 1 - c1)] = val\n",
    "    payload = [str(x) if x is not None else '' for x in payload]\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            tenant_ws.update(values=[payload], range_name=rng, value_input_option='USER_ENTERED')\n",
    "            break\n",
    "        except HttpError as e:\n",
    "            if getattr(e, \"resp\", None) and e.resp.status == 429:\n",
    "                time.sleep(5 * (attempt+1))\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "    # --- 2) ensure the formula cells are present (set once; theyâ€™ll recalc automatically) ---\n",
    "    col_letters = {k: _col_letter(row_abs_1based, colmap[k] + 1) for k in colmap}\n",
    "    # addresses for this row:\n",
    "    amt_paid_addr = f\"{col_letters['amount_paid']}{row_abs_1based}\"\n",
    "    amt_due_addr  = f\"{col_letters['amount_due']}{row_abs_1based}\"\n",
    "    date_paid_addr= f\"{col_letters['date_paid']}{row_abs_1based}\"\n",
    "    date_due_addr = f\"{col_letters['date_due']}{row_abs_1based}\"\n",
    "    bal_addr      = f\"{col_letters['prepay_arrears']}{row_abs_1based}\"\n",
    "    pen_addr      = f\"{col_letters['penalties']}{row_abs_1based}\"\n",
    "\n",
    "\n",
    "    # Penalties formula: if DatePaid > DateDue + 2 days, penalty = 3000\n",
    "    pen_formula = f\"=IF(DATEVALUE(LEFT({date_paid_addr},10))>DATEVALUE({date_due_addr})+2, 3000, 0)\"\n",
    "\n",
    "    # Balance formula: if first data row, =N(amt_paid)-N(amt_due); else, =N(prev_bal)+N(amt_paid)-N(amt_due)\n",
    "    if row_abs_1based == base_row_1based:\n",
    "        bal_formula = f\"=N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "    else:\n",
    "        prev_bal_addr = f\"{col_letters['prepay_arrears']}{row_abs_1based-1}\"\n",
    "        bal_formula = f\"=N({prev_bal_addr})+N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "    \n",
    "\n",
    "    # Only set if not already a formula (so we don't overwrite intentional manual values)\n",
    "    current_bal = tenant_ws.acell(bal_addr).value or \"\"\n",
    "    current_pen = tenant_ws.acell(pen_addr).value or \"\"\n",
    "    needs_bal = not str(current_bal).startswith(\"=\")\n",
    "    needs_pen = not str(current_pen).startswith(\"=\")\n",
    "\n",
    "    # Set any missing formulas in a single batch\n",
    "    body = []\n",
    "    if needs_bal:\n",
    "        body.append({'range': bal_addr, 'values': [[bal_formula]]})\n",
    "    if needs_pen:\n",
    "        body.append({'range': pen_addr, 'values': [[pen_formula]]})\n",
    "    if body:\n",
    "        tenant_ws.batch_update(body, value_input_option='USER_ENTERED')\n",
    "\n",
    "    # Return info (no computed numbers nowâ€”Sheet will reflect in realtime)\n",
    "    return {\n",
    "        'sheet': tenant_ws.title,\n",
    "        'month_row': row_abs_1based,\n",
    "        'paid_before': paid0,\n",
    "        'paid_after': paid1,\n",
    "        'ref_added': payment['REF Number'],\n",
    "        'formulas_set': {'balance': needs_bal, 'penalties': needs_pen},\n",
    "        'balance_addr': bal_addr,    \n",
    "        'penalties_addr': pen_addr       \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# ----- META SHEETS (ProcessedRefs, PaymentHistory) -----\n",
    "def ensure_meta(ws_name, header):\n",
    "    try:\n",
    "        ws = sh.worksheet(ws_name)\n",
    "    except gspread.WorksheetNotFound:\n",
    "        ws = sh.add_worksheet(ws_name, rows=2000, cols=max(10, len(header)))\n",
    "        ws.append_row(header)\n",
    "    return ws\n",
    "\n",
    "refs_ws = ensure_meta(\"ProcessedRefs\", [\"Ref\"])\n",
    "hist_ws = ensure_meta(\"PaymentHistory\", PAYMENT_COLS + ['AccountCode','TenantSheet','Month'])\n",
    "\n",
    "# Load processed refs into a set\n",
    "ref_vals = refs_ws.get_all_values()\n",
    "processed_refs = set((r[0] or '').upper() for r in ref_vals[1:]) if len(ref_vals) > 1 else set()\n",
    "\n",
    "# ----- GMAIL FETCH + PARSE -----\n",
    "print(\"ðŸ”Ž Searching Gmailâ€¦\")\n",
    "result = gmail.users().messages().list(userId=\"me\", q=GMAIL_QUERY, maxResults=200).execute()\n",
    "msg_list = result.get(\"messages\", [])\n",
    "print(f\"Found {len(msg_list)} candidate emails.\")\n",
    "\n",
    "parsed, errors = [], []\n",
    "for m in msg_list:\n",
    "    try:\n",
    "        text = get_message_text(gmail, m[\"id\"])\n",
    "        pay = parse_email(text)\n",
    "        if not pay:\n",
    "            errors.append(f\"Could not parse message id {m['id']}\")\n",
    "            continue\n",
    "        if pay['REF Number'] in processed_refs:\n",
    "            continue\n",
    "        parsed.append((m[\"id\"], pay))\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error reading message {m['id']}: {e}\")\n",
    "\n",
    "print(f\"âœ… Parsed {len(parsed)} new payments.\")\n",
    "\n",
    "# ----- APPLY: to tenant sheets + PaymentHistory + ProcessedRefs -----\n",
    "logs = []\n",
    "tenant_tally = {}\n",
    "\n",
    "# Cache worksheets to reduce calls\n",
    "worksheets = {ws.title: ws for ws in sh.worksheets()}\n",
    "\n",
    "def find_or_create_tenant_sheet(account_code: str):\n",
    "    for title, ws in worksheets.items():\n",
    "        t = title.upper()\n",
    "        if t.startswith(account_code) and 'PROCESSEDREFS' not in t and 'PAYMENTHISTORY' not in t:\n",
    "            return ws\n",
    "    title = f\"{account_code} - AutoAdded\"\n",
    "    ws = sh.add_worksheet(title, rows=1000, cols=12)\n",
    "    ws.update(values=[['Month','Amount Due','Amount paid','Date paid','REF Number','Date due','Prepayment/Arrears','Penalties']],\n",
    "              range_name='A1', value_input_option='USER_ENTERED')\n",
    "    ws.format('1:1', {'textFormat': {'bold': True}})\n",
    "    ws.freeze(rows=1)\n",
    "    worksheets[title] = ws\n",
    "    logs.append(f\"âž• Created tenant sheet: {title}\")\n",
    "    return ws\n",
    "\n",
    "for msg_id, p in parsed:\n",
    "    tenant_ws = find_or_create_tenant_sheet(p['AccountCode'])\n",
    "    info = update_tenant_month_row(tenant_ws, p)\n",
    "    # Read the live, recalculated values\n",
    "    logs.append(\n",
    "    f\"ðŸ§¾ {info['sheet']} R{info['month_row']} | \"\n",
    "    f\"Paid {info['paid_before']}â†’{info['paid_after']} | \"\n",
    "    f\"Ref {info['ref_added']} | Bal/penalties will auto-update in sheet\"\n",
    "    )\n",
    "    \n",
    "    tenant_tally[info['sheet']] = tenant_tally.get(info['sheet'], 0) + 1\n",
    "\n",
    "    # PaymentHistory\n",
    "    dt = datetime.strptime(p['Date Paid'], '%d/%m/%Y %I:%M %p')\n",
    "    mon = dt.strftime('%Y-%m')\n",
    "    hist_ws.append_row(\n",
    "        [p[k] for k in PAYMENT_COLS] + [p['AccountCode'], tenant_ws.title, mon],\n",
    "        value_input_option='USER_ENTERED'\n",
    "    )\n",
    "\n",
    "    # ProcessedRefs\n",
    "    refs_ws.append_row([p['REF Number']], value_input_option='RAW')\n",
    "    processed_refs.add(p['REF Number'])\n",
    "\n",
    "    # Mark Gmail read (optional)\n",
    "    try:\n",
    "        gmail.users().messages().modify(userId='me', id=msg_id, body={'removeLabelIds': ['UNREAD']}).execute()\n",
    "    except HttpError:\n",
    "        pass\n",
    "\n",
    "    time.sleep(2)  # throttle writes\n",
    "\n",
    "# ----- GROUPED MONTHLY SUMMARY (display) -----\n",
    "hist_vals = hist_ws.get_all_values()\n",
    "if len(hist_vals) > 1:\n",
    "    df = pd.DataFrame(hist_vals[1:], columns=hist_vals[0])\n",
    "    with pd.option_context('display.float_format', '{:,.2f}'.format):\n",
    "        df['Amount Paid'] = pd.to_numeric(df['Amount Paid'], errors='coerce').fillna(0.0)\n",
    "        grouped = df.groupby('Month', dropna=False).agg(\n",
    "            Payments=('REF Number','count'),\n",
    "            TotalAmount=('Amount Paid','sum')\n",
    "        ).reset_index().sort_values('Month')\n",
    "        display(grouped)\n",
    "else:\n",
    "    print(\"No payment history yet.\")\n",
    "\n",
    "# ----- LOGS -----\n",
    "print(\"\\n------ BOT LOG ------\")\n",
    "for line in logs:\n",
    "    print(line)\n",
    "print(\"\\nPayments per tenant sheet:\")\n",
    "for t, c in tenant_tally.items():\n",
    "    print(f\"  {t}: {c} payment(s)\")\n",
    "if errors:\n",
    "    print(\"\\nNon-fatal parse/read issues:\")\n",
    "    for e in errors:\n",
    "        print(\"  -\", e)\n",
    "print(\"\\nâœ… Prototype run complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067a70e",
   "metadata": {},
   "source": [
    "## DEPLOYMENT CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb35c02",
   "metadata": {},
   "source": [
    "* In this integration, we extend the proofâ€ofâ€concept prototype into a Streamlit app. The app retains the core functionality: â€¢ OAuth-based Google authentication to securely access Gmail, Google Sheets, and Drive. â€¢ Parsing payment notification emails with regular expressions. â€¢ Updating the relevant tenant sheets and maintaining meta data like ProcessedRefs and PaymentHistory.\n",
    "\n",
    "* Streamlit provides a user-friendly dashboard where users can trigger the payment bot and view real-time summaries and logs. This separation of the UI from the backend logic enables rapid deployment and easier scalability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "from googleapiclient.discovery import build\n",
    "import gspread\n",
    "from google.oauth2.credentials import Credentials\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CLIENT_SECRETS_FILE = 'client_secret.json'  # Download this from Google Cloud (OAuth Client ID)\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly',\n",
    "          'https://www.googleapis.com/auth/spreadsheets',\n",
    "          'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "SPREADSHEET_NAME = '2025 RENT TRACKING - Lemaiyan Heights'\n",
    "\n",
    "# --- SESSION STATE ---\n",
    "if 'credentials' not in st.session_state:\n",
    "    st.session_state.credentials = None\n",
    "\n",
    "# --- AUTHENTICATION FUNCTION ---\n",
    "def authenticate_user():\n",
    "    flow = Flow.from_client_secrets_file(\n",
    "        CLIENT_SECRETS_FILE,\n",
    "        scopes=SCOPES,\n",
    "        redirect_uri='http://localhost:8501/'\n",
    "    )\n",
    "    auth_url, _ = flow.authorization_url(prompt='consent')\n",
    "\n",
    "    st.write(f\"[Click here to authorize access]({auth_url})\")\n",
    "\n",
    "    code = st.text_input('Paste the full redirect URL after authentication here:')\n",
    "    if code:\n",
    "        # Extract the code from URL\n",
    "        parsed_code = code.split('code=')[1].split('&')[0]\n",
    "        flow.fetch_token(code=parsed_code)\n",
    "        creds = flow.credentials\n",
    "        st.session_state.credentials = creds\n",
    "        st.success('Authentication successful!')\n",
    "\n",
    "# --- EMAIL PARSING LOGIC ---\n",
    "def fetch_payment_emails(creds):\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "    results = service.users().messages().list(\n",
    "        userId='me',\n",
    "        q='from:ncbacustomer@ncbagroup.com subject:\"NCBA TRANSACTIONS STATUS UPDATE\"',\n",
    "        maxResults=10\n",
    "    ).execute()\n",
    "\n",
    "    messages = results.get('messages', [])\n",
    "    email_data = []\n",
    "\n",
    "    for msg in messages:\n",
    "        msg_content = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
    "        snippet = msg_content['snippet']\n",
    "        email_data.append(snippet)\n",
    "\n",
    "    return email_data\n",
    "\n",
    "# --- PAYMENT DATA EXTRACTION ---\n",
    "def extract_payment_info(email_body):\n",
    "    pattern = r'payment of KES ([\\d,]+.\\d{2}) for account: ([\\w#]+) has been received from (.+?) (\\d{3}\\*\\*\\*\\*\\d{3}) on (\\d{2}/\\d{2}/\\d{4} \\d{1,2}:\\d{2} [APM]{2})\\. M-Pesa Ref: ([\\w\\d]+)'\n",
    "    match = re.search(pattern, email_body)\n",
    "    if match:\n",
    "        amount = float(match.group(1).replace(',', ''))\n",
    "        account_code = match.group(2).split('#')[-1]\n",
    "        payer_name = match.group(3)\n",
    "        phone = match.group(4)\n",
    "        payment_date = match.group(5)\n",
    "        mpesa_ref = match.group(6)\n",
    "        return {\n",
    "            'Amount': amount,\n",
    "            'AccountCode': account_code,\n",
    "            'Payer': payer_name,\n",
    "            'Phone': phone,\n",
    "            'Date': payment_date,\n",
    "            'Ref': mpesa_ref\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# --- GOOGLE SHEETS UPDATE FUNCTION ---\n",
    "def update_google_sheet(creds, payment_data):\n",
    "    gc = gspread.authorize(creds)\n",
    "    sh = gc.open(SPREADSHEET_NAME)\n",
    "\n",
    "    # Check or create 'ProcessedRefs' sheet\n",
    "    try:\n",
    "        refs_ws = sh.worksheet('ProcessedRefs')\n",
    "    except gspread.exceptions.WorksheetNotFound:\n",
    "        refs_ws = sh.add_worksheet(title='ProcessedRefs', rows=\"1000\", cols=\"1\")\n",
    "        refs_ws.append_row(['Ref'])\n",
    "\n",
    "    processed_refs = refs_ws.col_values(1)\n",
    "    if payment_data['Ref'] in processed_refs:\n",
    "        st.warning(f\"Ref {payment_data['Ref']} already processed. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Find Tenant Sheet\n",
    "    tenant_ws = None\n",
    "    for ws in sh.worksheets():\n",
    "        if payment_data['AccountCode'] in ws.title and 'ProcessedRefs' not in ws.title:\n",
    "            tenant_ws = ws\n",
    "            break\n",
    "\n",
    "    if tenant_ws:\n",
    "        new_row = [\n",
    "            payment_data['Date'],\n",
    "            payment_data['Amount'],\n",
    "            payment_data['Ref'],\n",
    "            payment_data['Payer'],\n",
    "            payment_data['Phone'],\n",
    "            'MPESA Payment'\n",
    "        ]\n",
    "        tenant_ws.append_row(new_row)\n",
    "        refs_ws.append_row([payment_data['Ref']])\n",
    "        st.success(f\"Payment logged for {payment_data['AccountCode']} successfully.\")\n",
    "    else:\n",
    "        st.error(f\"No matching tenant sheet found for {payment_data['AccountCode']}\")\n",
    "\n",
    "# --- MAIN APP LOGIC ---\n",
    "st.title(\"ðŸ  Lemaiyan Heights Rent Automation Bot\")\n",
    "\n",
    "if not st.session_state.credentials:\n",
    "    st.header(\"ðŸ”‘ Authenticate with Google\")\n",
    "    authenticate_user()\n",
    "else:\n",
    "    st.success(\"You're authenticated!\")\n",
    "\n",
    "    if st.button(\"ðŸš€ Run Payment Bot\"):\n",
    "        st.info(\"Fetching latest payment emails...\")\n",
    "        emails = fetch_payment_emails(st.session_state.credentials)\n",
    "\n",
    "        if not emails:\n",
    "            st.warning(\"No new payment emails found.\")\n",
    "        else:\n",
    "            for email_body in emails:\n",
    "                payment_info = extract_payment_info(email_body)\n",
    "                if payment_info:\n",
    "                    update_google_sheet(st.session_state.credentials, payment_info)\n",
    "                else:\n",
    "                    st.warning(\"Could not parse email. Possible format mismatch.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartpath-streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
