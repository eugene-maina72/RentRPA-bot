{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23dbf1cd",
   "metadata": {},
   "source": [
    "# RENT AUTOMATION BOT (PROOF OF CONCEPT, PROTOTYPE, DEPLOYMENT)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96bfed",
   "metadata": {},
   "source": [
    "<img src= 'images\\rent bot.jpg' width='200'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578216d3",
   "metadata": {},
   "source": [
    "\n",
    "# Problem Statement and Project Objectives\n",
    "\n",
    "***\n",
    "\n",
    "## Problem Statement\n",
    "The primary challenge addressed in this notebook is the automation of rent payment tracking for Lemaiyan Heights. Traditional rent collection and record-keeping can be error-prone and time-consuming, especially when dealing with multiple payment sources and tenants. Key challenges include:\n",
    "- Manual reconciliation of payments.\n",
    "- Risk of duplicate entries due to repetitive processing of the same payment notifications.\n",
    "- Difficulty in maintaining up-to-date financial records and tenant-specific payment histories.\n",
    "\n",
    "## Project Objectives\n",
    "The notebook aims to achieve the following objectives:\n",
    "- **Automate Payment Parsing:** Use regular expressions to extract payment details from email notifications reliably.\n",
    "- **Ensure Data Integrity:** Avoid double-processing of payments by tracking unique payment references.\n",
    "- **Dynamic Sheet Management:** Automatically update or create individual tenant sheets based on the received payment details.\n",
    "- **Seamless Integration:** Connect with the Google platform (Gmail and Google Sheets) to streamline data extraction and real-time updates.\n",
    "- **User-Friendly Dashboard:** Provide a streamlined overview through a Streamlit app, allowing users to initiate the payment bot and view processing logs and summaries.\n",
    "\n",
    "This solution demonstrates a proof of concept that leverages Python, Pandas, openpyxl, gspread, and Google APIs to enhance the rent collection process, optimize administrative workflows, and reduce the possibility of human error.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d849538",
   "metadata": {},
   "source": [
    "## PROOF OF CONCEPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c84fb8",
   "metadata": {},
   "source": [
    "* Random generated dataset to simulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c261b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 200 dummy emails in data\\dummy_emails_200.txt\n",
      "Sample email:\n",
      " Dear Customer, your payment of KES 19000.00 for account: PAYLEMAIYAN #A3 has been received from Kathleen Jones 759****602 on 04/02/2025 09:06 AM. M-Pesa Ref: R80VIOA2YW\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define possible account codes (A1-A6, B1-B6, ..., G1-G6)\n",
    "accounts = [f\"{l}{n}\" for l in \"ABCDEFG\" for n in range(1, 7)]\n",
    "\n",
    "email_template = (\"Dear Customer, your payment of KES {amount} for account: PAYLEMAIYAN #{code} \"\n",
    "                  \"has been received from {name} {phone} on {date_time}. \"\n",
    "                  \"M-Pesa Ref: {mpesa_ref}\")\n",
    "def random_ref_code(length=10):\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=length))\n",
    "dummy_emails = []\n",
    "for _ in range(200):\n",
    "    amount = f\"{random.randint(5, 20) * 1000}.00\"\n",
    "    code = random.choice(accounts)\n",
    "    name = fake.name()\n",
    "    phone = f\"{random.randint(700, 799)}****{random.randint(100,999)}\"\n",
    "    date_time = fake.date_time_this_year().strftime('%d/%m/%Y %I:%M %p')\n",
    "    mpesa_ref = random_ref_code(10)\n",
    "    email_text = email_template.format(\n",
    "        amount=amount,\n",
    "        code=code,\n",
    "        name=name,\n",
    "        phone=phone,\n",
    "        date_time=date_time,\n",
    "        mpesa_ref=mpesa_ref\n",
    "    )\n",
    "    dummy_emails.append(email_text)\n",
    "\n",
    "# Save to data/dummy_emails_200.txt\n",
    "out_path = Path(\"data/dummy_emails_200.txt\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_path.write_text(\"\\n\\n\".join(dummy_emails))\n",
    "\n",
    "print(f\"Created {len(dummy_emails)} dummy emails in {out_path}\")\n",
    "print(\"Sample email:\\n\", dummy_emails[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b474a9c",
   "metadata": {},
   "source": [
    "* Logic engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa9290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 emails.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Reads MPESA email notifications from dummy_emails.txt,\n",
    "# Parses payment info, updates dummy_rent_tracker.xlsx,\n",
    "# Avoids double-logging by checking ProcessedRefs sheet.\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_DIR = Path('data')\n",
    "EMAIL_FILE = DATA_DIR / 'dummy_emails_200.txt'\n",
    "SPREADSHEET_FILE = DATA_DIR / 'dummy_rent_tracker.xlsx'\n",
    "\n",
    "# --- 1. Load Dummy Emails ---\n",
    "with open(EMAIL_FILE, 'r') as f:\n",
    "    email_texts = f.read().split('\\n\\n')\n",
    "\n",
    "print(f\"Loaded {len(email_texts)} emails.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532bc6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Customer, your payment of KES 20000.00 for account: PAYLEMAIYAN #G4 has been received from Blake Lee 719****900 on 08/05/2025 08:08 AM. M-Pesa Ref: 1NRVADULXZ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_texts[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2107ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1250 previously processed refs.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Workbook and All Sheet Names ---\n",
    "wb = load_workbook(SPREADSHEET_FILE)\n",
    "sheet_names = wb.sheetnames\n",
    "\n",
    "# --- 3. Load ProcessedRefs (deduplication) ---\n",
    "try:\n",
    "    processed_refs_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='ProcessedRefs')\n",
    "    processed_refs = set(str(ref).strip().upper() for ref in processed_refs_df['Ref'] if pd.notna(ref))\n",
    "except Exception:\n",
    "    processed_refs = set()\n",
    "    print(\"ProcessedRefs sheet is empty or missing. Will create it.\")\n",
    "\n",
    "print(f\"Found {len(processed_refs)} previously processed refs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46ab175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Regex Parser Function ---\n",
    "def extract_payment_info(email_body):\n",
    "    pattern = (\n",
    "        r'payment of KES ([\\d,]+\\.\\d{2}) '\n",
    "        r'for account: PAYLEMAIYAN\\s*#?\\s*([A-Za-z]\\d{1,2})'\n",
    "        r' has been received from (.+?) '\n",
    "        r'(.{1,13}) '\n",
    "        r'on (\\d{2}/\\d{2}/\\d{4} \\d{1,2}:\\d{2} [APM]{2})\\. '\n",
    "        r'M-Pesa Ref: ([\\w\\d]+)'\n",
    "    )\n",
    "    match = re.search(pattern, email_body, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        return {\n",
    "            'Amount': float(match.group(1).replace(',', '').strip()),\n",
    "            'AccountCode': match.group(2).strip().upper(),\n",
    "            'Payer': match.group(3).strip(),\n",
    "            'Phone': match.group(4).strip(),\n",
    "            'Date': match.group(5).strip(),\n",
    "            'Ref': match.group(6).strip().upper(),\n",
    "        }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07c2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Process Emails, Update or Create Sheets ---\n",
    "\n",
    "\n",
    "updates_log = []\n",
    "new_refs = []\n",
    "updates_per_sheet = {}\n",
    "\n",
    "# We'll use openpyxl to add new sheets if needed\n",
    "wb = load_workbook(SPREADSHEET_FILE)\n",
    "writer = pd.ExcelWriter(SPREADSHEET_FILE, engine='openpyxl', mode='a', if_sheet_exists='overlay')\n",
    "\n",
    "# Loading a Master payments file\n",
    "try:\n",
    "    payment_history_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='PaymentHistory')\n",
    "except Exception:\n",
    "    payment_history_df = pd.DataFrame(columns=[\n",
    "        'Date', 'Amount', 'Ref', 'Payer', 'Phone', 'Payment Mode', 'AccountCode', 'TenantSheet'\n",
    "    ])\n",
    "\n",
    "\n",
    "for email in email_texts:\n",
    "    payment_data = extract_payment_info(email)\n",
    "    if not payment_data:\n",
    "        updates_log.append(\"Skipped email: Could not parse payment info.\")\n",
    "        continue\n",
    "\n",
    "    ref = payment_data['Ref'].upper().strip()\n",
    "    if ref in processed_refs:\n",
    "        updates_log.append(f\"Duplicate ignored (Ref {ref})\")\n",
    "        continue\n",
    "\n",
    "    account_code = payment_data['AccountCode']\n",
    "    payer_name = payment_data['Payer'].replace(\" \", \"_\")[:15]\n",
    "    # Try to match an existing tenant sheet\n",
    "    target_sheet = None\n",
    "    for s in sheet_names:\n",
    "        # Take just the code part from the sheet name\n",
    "        sheet_token = s.split()[0].replace('-', '').upper().strip()\n",
    "        if account_code == sheet_token and 'PROCESSEDREFS' not in s.upper() and 'PAYMENTHISTORY' not in s.upper():\n",
    "            target_sheet = s\n",
    "            break\n",
    "\n",
    "    # --- 7. If no sheet found, CREATE it ---\n",
    "    if target_sheet is None:\n",
    "        target_sheet = f\"{account_code} - {payer_name if payer_name else 'AutoAdded'}\"\n",
    "        print(f\"Creating new sheet: {target_sheet} for new tenant {account_code}\")\n",
    "        new_tenant_df = pd.DataFrame(columns=[\n",
    "            'Date', 'Amount', 'Ref', 'Payer', 'Phone', 'Payment Mode'\n",
    "        ])\n",
    "        new_tenant_df.to_excel(writer, sheet_name=target_sheet, index=False)\n",
    "        updates_log.append(f\"Created new sheet: {target_sheet}\")\n",
    "        sheet_names.append(target_sheet)  # So we don't create it twice\n",
    "\n",
    "    # --- 8. Append payment to tenant sheet ---\n",
    "    try:\n",
    "        df = pd.read_excel(SPREADSHEET_FILE, sheet_name=target_sheet)\n",
    "    except Exception:\n",
    "        df = pd.DataFrame(columns=['Date', 'Amount', 'Ref', 'Payer', 'Phone', 'Payment Mode'])\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'Date': [payment_data['Date']],\n",
    "        'Amount': [payment_data['Amount']],\n",
    "        'Ref': [payment_data['Ref']],\n",
    "        'Payer': [payment_data['Payer']],\n",
    "        'Phone': [payment_data['Phone']],\n",
    "        'Payment Mode': ['MPESA Payment'],\n",
    "    })\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_excel(writer, sheet_name=target_sheet, index=False)\n",
    "    updates_log.append(f\"Logged payment for {account_code} - Ref {ref}\")\n",
    "    new_refs.append(ref)\n",
    "    updates_per_sheet.setdefault(target_sheet, 0)\n",
    "    updates_per_sheet[target_sheet] += 1\n",
    "\n",
    "     # --- 9. Add to PaymentHistory sheet ---\n",
    "    new_hist_row = new_row.copy()\n",
    "    new_hist_row['AccountCode'] = account_code\n",
    "    new_hist_row['TenantSheet'] = target_sheet\n",
    "    payment_history_df = pd.concat([payment_history_df, new_hist_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ccb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Logged payment for A3 - Ref R80VIOA2YW\n",
      "Logged payment for C4 - Ref WURDRH7ZBU\n",
      "Logged payment for D2 - Ref LTW0VCTS5S\n",
      "Logged payment for A6 - Ref WP2X99YUDD\n",
      "Logged payment for G4 - Ref MUH400LVXG\n",
      "Logged payment for A3 - Ref 3RB37S9E7O\n",
      "Logged payment for A3 - Ref LRVN72GBQD\n",
      "Logged payment for F6 - Ref FRGEE8A03G\n",
      "Logged payment for F1 - Ref SXFW54V1I9\n",
      "Logged payment for G3 - Ref IY79MGDB1U\n",
      "Logged payment for F2 - Ref 8AEOYFJRQ8\n",
      "Logged payment for C3 - Ref 2CT6AX00NG\n",
      "Logged payment for E1 - Ref JEFNXKQ14B\n",
      "Logged payment for D4 - Ref 1OKUUKCM8U\n",
      "Logged payment for C2 - Ref 6KZBWB5WB5\n",
      "Logged payment for G2 - Ref RRYATOC3YD\n",
      "Logged payment for G2 - Ref CBIHOA0YP1\n",
      "Logged payment for A1 - Ref V5W74BU5YC\n",
      "Logged payment for B2 - Ref L2YI1I2XWG\n",
      "Logged payment for E5 - Ref AKPXDAOR4G\n",
      "Logged payment for G6 - Ref X1W9MGLQ64\n",
      "Logged payment for B2 - Ref 5V2F3WF2HQ\n",
      "Logged payment for G4 - Ref 1NRVADULXZ\n",
      "Logged payment for A3 - Ref X5DK2WVQC2\n",
      "Logged payment for F1 - Ref 9EW3MP7T41\n",
      "Logged payment for F3 - Ref U6Y1HU29I6\n",
      "Logged payment for F3 - Ref EOIQWK0IDF\n",
      "Logged payment for B5 - Ref D8PCEFGFEF\n",
      "Logged payment for D4 - Ref BO0A6VW8TV\n",
      "Logged payment for B3 - Ref OTCAPO3TPN\n",
      "Logged payment for E4 - Ref BC6LU4OR26\n",
      "Logged payment for E5 - Ref 50MFFFDZ6F\n",
      "Logged payment for F6 - Ref Z6RRM5W9RH\n",
      "Logged payment for C5 - Ref JA4F23YYAW\n",
      "Logged payment for B1 - Ref W4GUZ6SNCT\n",
      "Logged payment for G3 - Ref SKNISAXO11\n",
      "Logged payment for G6 - Ref 7BXPVYN2TP\n",
      "Logged payment for E3 - Ref LZKKVBE8WI\n",
      "Logged payment for D3 - Ref 6FY5YMUUWU\n",
      "Logged payment for G4 - Ref XAZ6PW4DOC\n",
      "Logged payment for G1 - Ref 9MS7N9CVYW\n",
      "Logged payment for G3 - Ref G61M9QCEU8\n",
      "Logged payment for G2 - Ref MILL26SY02\n",
      "Logged payment for D5 - Ref M8F7VG3QEX\n",
      "Logged payment for A2 - Ref ADB90A79W9\n",
      "Logged payment for B4 - Ref O2NFGL8QR3\n",
      "Logged payment for D4 - Ref MBJ4MGGGIW\n",
      "Logged payment for C5 - Ref 2C6TDK273Y\n",
      "Logged payment for A4 - Ref LLU12WOSIH\n",
      "Logged payment for F6 - Ref EIWZLFFUZR\n",
      "Logged payment for B6 - Ref NIXA902R9Y\n",
      "Logged payment for A5 - Ref TCVXSRE1IM\n",
      "Logged payment for G1 - Ref TJC5CRFZ2M\n",
      "Logged payment for E3 - Ref UJN6I2E4F0\n",
      "Logged payment for G3 - Ref 3E0GE8KWKS\n",
      "Logged payment for F4 - Ref O24IXPQIWH\n",
      "Logged payment for C5 - Ref U0W7XXJMSW\n",
      "Logged payment for A2 - Ref GMJ2MBPVUO\n",
      "Logged payment for B1 - Ref J1455MYQKK\n",
      "Logged payment for D2 - Ref ILHTH6FW5U\n",
      "Logged payment for B1 - Ref 8L5Q5YHFH3\n",
      "Logged payment for F4 - Ref 88F23893AG\n",
      "Logged payment for D2 - Ref E8JUMDNDZU\n",
      "Logged payment for E5 - Ref NETO1VDBL2\n",
      "Logged payment for G1 - Ref E51UEHDPAY\n",
      "Logged payment for F3 - Ref V0Y8PZEQJT\n",
      "Logged payment for C1 - Ref DODA3U606Y\n",
      "Logged payment for C1 - Ref QEEPZOA346\n",
      "Logged payment for C2 - Ref TXATD1JTU8\n",
      "Logged payment for C2 - Ref 6JM8PR5IKJ\n",
      "Logged payment for D1 - Ref 6AG66Z923J\n",
      "Logged payment for B5 - Ref KI3EIYZVPA\n",
      "Logged payment for F3 - Ref 6R6XPCD8K6\n",
      "Logged payment for E4 - Ref RPVGM119T2\n",
      "Logged payment for B4 - Ref 0V05QHUDY5\n",
      "Logged payment for B1 - Ref 6XPFJSE84B\n",
      "Logged payment for A1 - Ref HYBZFXJSJ2\n",
      "Logged payment for D4 - Ref CMBBVPW8QM\n",
      "Logged payment for E5 - Ref PQDRUG7E8S\n",
      "Logged payment for G5 - Ref R4QPRUOXNC\n",
      "Logged payment for C1 - Ref TH0XKTQ64V\n",
      "Logged payment for B3 - Ref U9E0EN566G\n",
      "Logged payment for E2 - Ref Z8WLE5YSUS\n",
      "Logged payment for C5 - Ref MA9RJF77E4\n",
      "Logged payment for D6 - Ref 7SROZK4ETH\n",
      "Logged payment for D1 - Ref 399DRWMNOH\n",
      "Logged payment for F5 - Ref FM6T9JIIYX\n",
      "Logged payment for A1 - Ref 9Z559VB5AM\n",
      "Logged payment for A4 - Ref 9QKNXT7YSG\n",
      "Logged payment for F1 - Ref 55DVR91BXK\n",
      "Logged payment for E5 - Ref Z64LZ2NYS4\n",
      "Logged payment for G2 - Ref 91LIMU7EFW\n",
      "Logged payment for A4 - Ref V7YK603CRB\n",
      "Logged payment for D6 - Ref 0LX3DTX908\n",
      "Logged payment for E4 - Ref OCV44ZI91L\n",
      "Logged payment for A1 - Ref IWLQ0OMUBP\n",
      "Logged payment for A1 - Ref XDP3C0Z3OZ\n",
      "Logged payment for G1 - Ref MG8J6L0VHQ\n",
      "Logged payment for G2 - Ref NFNR8TTZDO\n",
      "Logged payment for E4 - Ref LTNZOT403X\n",
      "Logged payment for D3 - Ref 9QVIUXS7K9\n",
      "Logged payment for E6 - Ref Y7SRWCR8MB\n",
      "Logged payment for B4 - Ref FO7SSVLQYH\n",
      "Logged payment for G4 - Ref HXROI4YN80\n",
      "Logged payment for D6 - Ref 4UZAHI0RPP\n",
      "Logged payment for A2 - Ref SXKRQ4JG81\n",
      "Logged payment for D3 - Ref V26KBACQTB\n",
      "Logged payment for F5 - Ref 88RNU45QMV\n",
      "Logged payment for E4 - Ref QNU6KBDPYW\n",
      "Logged payment for G4 - Ref 6Q1CSKDAOH\n",
      "Logged payment for F4 - Ref ADZ76PIN0H\n",
      "Logged payment for E2 - Ref O8YRYVQW2W\n",
      "Logged payment for B1 - Ref EWE3S9R9T5\n",
      "Logged payment for A6 - Ref C2ME2KE0YY\n",
      "Logged payment for G1 - Ref 035BF3PQ45\n",
      "Logged payment for E5 - Ref IZ0R4E0E5D\n",
      "Logged payment for B3 - Ref 2C1MM86HRY\n",
      "Logged payment for A1 - Ref HPV4F6JZ80\n",
      "Logged payment for G1 - Ref G4989910W9\n",
      "Logged payment for E4 - Ref BEVRXPEC4C\n",
      "Logged payment for A3 - Ref 1KZMSC7GSG\n",
      "Logged payment for A5 - Ref J5K9L7OIEJ\n",
      "Logged payment for F2 - Ref OHOX78BMFN\n",
      "Logged payment for F3 - Ref E902IA06KX\n",
      "Logged payment for F4 - Ref JSYVVCX02O\n",
      "Logged payment for C2 - Ref STTYEVZR1V\n",
      "Logged payment for E2 - Ref SD9ZCFJMWK\n",
      "Logged payment for F3 - Ref HH1LH1T7PN\n",
      "Logged payment for A4 - Ref PG07QVSNS4\n",
      "Logged payment for F4 - Ref JA75S3VHG8\n",
      "Logged payment for E4 - Ref FIMVDWZ8OJ\n",
      "Logged payment for C6 - Ref OGWBLL5GUZ\n",
      "Logged payment for G5 - Ref CRKC9M9X9A\n",
      "Logged payment for F6 - Ref EMJMOV1TEL\n",
      "Logged payment for B4 - Ref G4HSP3KSIJ\n",
      "Logged payment for D1 - Ref 1H3BDLYTD1\n",
      "Logged payment for E5 - Ref IA05ES95RT\n",
      "Logged payment for B3 - Ref ADTJ8NK2NG\n",
      "Logged payment for D5 - Ref OYNRASA21M\n",
      "Logged payment for B2 - Ref 62J3UCGRWV\n",
      "Logged payment for F6 - Ref 3U4I6KN5XZ\n",
      "Logged payment for E2 - Ref KA0YXO42E2\n",
      "Logged payment for G3 - Ref GB0BSN2HH5\n",
      "Logged payment for G3 - Ref KK7PE340WZ\n",
      "Logged payment for C2 - Ref 1GTIT9XJY2\n",
      "Logged payment for B3 - Ref KQEOJYVBMQ\n",
      "Logged payment for B5 - Ref KB94IJBXZK\n",
      "Logged payment for A5 - Ref 5JK60K55HS\n",
      "Logged payment for B6 - Ref DG918O7407\n",
      "Logged payment for C1 - Ref AHQNKG9AD8\n",
      "Logged payment for G1 - Ref SDGU9GFT0R\n",
      "Logged payment for E2 - Ref OG6FMPROPV\n",
      "Logged payment for C5 - Ref Q3PB3PDPFC\n",
      "Logged payment for A1 - Ref GK4K8G08RN\n",
      "Logged payment for A5 - Ref HWX40ML0K7\n",
      "Logged payment for E1 - Ref R37VV0G7O9\n",
      "Logged payment for E5 - Ref 2JY9AO1GLB\n",
      "Logged payment for B3 - Ref KXK6NEAA6M\n",
      "Logged payment for F2 - Ref 3MDDPKFT53\n",
      "Logged payment for D2 - Ref G9RPDCD3N1\n",
      "Logged payment for A2 - Ref BPUFHZA5HO\n",
      "Logged payment for F2 - Ref 2OPZUBUX2E\n",
      "Logged payment for B1 - Ref V2GIYL65GK\n",
      "Logged payment for E6 - Ref KLX88O9S62\n",
      "Logged payment for F4 - Ref S66R8EGDRA\n",
      "Logged payment for F1 - Ref OJ2Z132NL3\n",
      "Logged payment for G3 - Ref ZF6MZRW314\n",
      "Logged payment for C2 - Ref HMEHQFOOVG\n",
      "Logged payment for D3 - Ref RQF5XJ2LOB\n",
      "Logged payment for C4 - Ref 6VYNLIK1HX\n",
      "Logged payment for B1 - Ref UILNUFXUEI\n",
      "Logged payment for A2 - Ref BOTTO7RSOV\n",
      "Logged payment for D3 - Ref CZZVT0V7EZ\n",
      "Logged payment for G2 - Ref TOQ82H9JR7\n",
      "Logged payment for B1 - Ref RJQIVJD4H4\n",
      "Logged payment for F5 - Ref EK03OR0JLQ\n",
      "Logged payment for D5 - Ref 8M9FQHDIU3\n",
      "Logged payment for G2 - Ref A1C0ABYU9J\n",
      "Logged payment for F3 - Ref BU7ECPCAUN\n",
      "Logged payment for E6 - Ref F24450UED8\n",
      "Logged payment for A2 - Ref OXM24L831N\n",
      "Logged payment for A5 - Ref 8OEPM2TG9N\n",
      "Logged payment for F3 - Ref 2QQMQOKFYJ\n",
      "Logged payment for B3 - Ref G5YDX6EH62\n",
      "Logged payment for B1 - Ref IQB86IM1HU\n",
      "Logged payment for D3 - Ref XOINEXDG1V\n",
      "Logged payment for D1 - Ref K5YALC8IW3\n",
      "Logged payment for A4 - Ref 9MB4QK3GEF\n",
      "Logged payment for E1 - Ref ML06IIE20U\n",
      "Logged payment for G3 - Ref BARWRWRENU\n",
      "Logged payment for B6 - Ref URI0WN9C84\n",
      "Logged payment for B3 - Ref FYHA8MEW2T\n",
      "Logged payment for G5 - Ref LINBDBMKBZ\n",
      "Logged payment for E1 - Ref 3RUJ6PXXQ4\n",
      "Logged payment for E1 - Ref 32YCAK78H3\n",
      "Logged payment for C2 - Ref KKPK8RA85P\n",
      "Logged payment for A3 - Ref GPB448BPQW\n",
      "Logged payment for F5 - Ref KTKJIBKXG6\n",
      "Logged payment for C6 - Ref 91KZ5E53AY\n",
      "Logged payment for E4 - Ref T0GFRWFQR6\n",
      "ProcessedRefs updated with 200 new refs.\n",
      "\n",
      "Updates per tenant sheet:\n",
      "A3 - Bradley_Turner: 6 payments appended\n",
      "C4 - Bobby_Alvarez: 2 payments appended\n",
      "D2 - Robert_Brown: 4 payments appended\n",
      "A6 - Paul_Moreno: 2 payments appended\n",
      "G4 - Jason_Reyes: 5 payments appended\n",
      "F6 - AutoAdded: 5 payments appended\n",
      "F1 - Deanna_Perkins: 4 payments appended\n",
      "G3 - Caleb_Casey: 8 payments appended\n",
      "F2 - Jonathan: 4 payments appended\n",
      "C3 - AutoAdded: 1 payments appended\n",
      "E1 - Jason: 5 payments appended\n",
      "D4 - AutoAdded: 4 payments appended\n",
      "C2 - Valerie_Frost: 7 payments appended\n",
      "G2 - Jessica_Tran: 7 payments appended\n",
      "A1 - AutoAdded: 7 payments appended\n",
      "B2 - AutoAdded: 3 payments appended\n",
      "E5 - AutoAdded: 8 payments appended\n",
      "G6 - Nicholas: 2 payments appended\n",
      "F3 - Sophia_Garcia: 8 payments appended\n",
      "B5 - Andrew_Johnson: 3 payments appended\n",
      "B3 - William: 8 payments appended\n",
      "E4 - John_Shannon: 8 payments appended\n",
      "C5 - Susan_Cook: 5 payments appended\n",
      "B1 - Jackie_Miller: 9 payments appended\n",
      "E3 - Todd_Harris: 2 payments appended\n",
      "D3 - Andrew_Hubbard: 6 payments appended\n",
      "G1 - AutoAdded: 7 payments appended\n",
      "D5 - Adam: 3 payments appended\n",
      "A2 - Lisa_Andrews: 6 payments appended\n",
      "B4 - Lauren_Lee: 4 payments appended\n",
      "A4 - Dawn_Mason: 5 payments appended\n",
      "B6 - Eric_Pruitt: 3 payments appended\n",
      "A5 - Misty_Kim: 5 payments appended\n",
      "F4 - Michael: 6 payments appended\n",
      "C1 - Grace_Huffman: 4 payments appended\n",
      "D1 - Michael_Thomas: 4 payments appended\n",
      "G5 - Roger_Mejia: 3 payments appended\n",
      "E2 - Jeremiah_Smith: 5 payments appended\n",
      "D6 - Mr._Robert_Elli: 3 payments appended\n",
      "F5 - Heidi_Rivera: 4 payments appended\n",
      "E6 - Karla_Myers: 3 payments appended\n",
      "C6 - Ryan_White: 2 payments appended\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Save PaymentHistory sheet\n",
    "payment_history_df.to_excel(writer, sheet_name='PaymentHistory', index=False)\n",
    "\n",
    "# --- 11. Update ProcessedRefs sheet\n",
    "try:\n",
    "    refs_df = pd.read_excel(SPREADSHEET_FILE, sheet_name='ProcessedRefs')\n",
    "except Exception:\n",
    "    refs_df = pd.DataFrame({'Ref': []})\n",
    "if new_refs:\n",
    "    new_refs_df = pd.DataFrame({'Ref': new_refs})\n",
    "    updated_refs = pd.concat([refs_df, new_refs_df], ignore_index=True)\n",
    "    updated_refs.to_excel(writer, sheet_name='ProcessedRefs', index=False)\n",
    "    updates_log.append(f\"ProcessedRefs updated with {len(new_refs)} new refs.\")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"\\n--- Processing Summary ---\")\n",
    "for log in updates_log:\n",
    "    print(log)\n",
    "print(\"\\nUpdates per tenant sheet:\")\n",
    "for k, v in updates_per_sheet.items():\n",
    "    print(f\"{k}: {v} payments appended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecf57d",
   "metadata": {},
   "source": [
    "## PROTOTYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f050d",
   "metadata": {},
   "source": [
    "* Intergrating the proof of concept to the Google Platform\n",
    "* First is to create a dummy account on gmail and populate it with dummy emails as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458db27",
   "metadata": {},
   "source": [
    "### DUMMY EMAIL GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eda4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependencies for sending email notifications\n",
    "import base64, random, string, time, datetime\n",
    "from faker import Faker\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from email.mime.text import MIMEText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359afaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899105285450-50tdk35cnnrrich3nlr0d80kdp2qeovr.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A53635%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify&state=Dt8GnubiuGBZcnEm2f3Exs4ILuX5AJ&access_type=offline\n",
      "✅ 40 dummy messages delivered to dmmccntdev@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# ---------- SEND 200 TEST EMAILS INTO SANDBOX GMAIL ----------\n",
    "\n",
    "fake = Faker()\n",
    "SCOPES = SCOPES = [\n",
    "    'https://www.googleapis.com/auth/gmail.send',     # to inject test mail\n",
    "    'https://www.googleapis.com/auth/gmail.readonly',\n",
    "    'https://www.googleapis.com/auth/gmail.modify' # to call getProfile\n",
    "]\n",
    "flow   = InstalledAppFlow.from_client_secrets_file('bot_secret.json', SCOPES)\n",
    "creds  = flow.run_local_server(port=0)\n",
    "gmail  = build('gmail', 'v1', credentials=creds)\n",
    "user_email = gmail.users().getProfile(userId='me').execute()['emailAddress']\n",
    "\n",
    "accounts = [f\"{l}{n}\" for l in \"ABCDEFG\" for n in range(1,7)]\n",
    "def rand_ref(): return ''.join(random.choices(string.ascii_uppercase+string.digits, k=10))\n",
    "\n",
    "def make_msg(text):\n",
    "    m = MIMEText(text)\n",
    "    m['From'] = 'NCB <ncbcustomer@ncbgroup.com>'\n",
    "    m['To']   = user_email\n",
    "    m['Subject'] = 'NCBA TRANSACTIONS STATUS UPDATE'\n",
    "    return {'raw': base64.urlsafe_b64encode(m.as_bytes()).decode()}\n",
    "\n",
    "for _ in range(40):\n",
    "    code  = random.choice(accounts)\n",
    "    code_fragment = f\"#{code.lower()}\" if random.random()>.4 else code   # hash optional\n",
    "    amt   = f\"{random.randint(5,20)*1000:,}.00\"\n",
    "    name  = fake.name().title()\n",
    "    phone = f\"0{random.randint(100,999)}***{random.randint(100,999)}\"\n",
    "    dt    = fake.date_time_this_year().strftime('%d/%m/%Y %I:%M %p')\n",
    "    ref   = rand_ref()\n",
    "    body  = (f\"Your M-Pesa payment of KES {amt} for account: PAYLEMAIYAN {code_fragment} \"\n",
    "             f\"has been received from {name} {phone} on {dt}. M-Pesa Ref: {ref}. NCBA, Go for it.\")\n",
    "    gmail.users().messages().send(userId='me', body=make_msg(body)).execute()\n",
    "    time.sleep(0.3) # Adjusted sleep time to avoid rate limits\n",
    "\n",
    "print(\"✅ 40 dummy messages delivered to\", user_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243da59",
   "metadata": {},
   "source": [
    "### GOOGLE SHEET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc98e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD GSPREAD LIBRARIES FOR GOOGLE SHEETS ----------\n",
    "import pandas as pd, gspread, openpyxl\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efa219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap complete – Google Sheet mirrors the Excel file.\n"
     ]
    }
   ],
   "source": [
    "# ---------- ONE‑TIME MIGRATION EXCEL → GOOGLE SHEETS ----------\n",
    "\n",
    "\n",
    "SRC_EXCEL = 'data/2025 RENT TRACKING - Lemaiyan Heights.xlsx'  # original data file\n",
    "DEST_SHEET = 'RENT TRACKING-Lemaiyan Heights' # New file in google sheets\n",
    "\n",
    "creds = Credentials.from_service_account_file('bot_service.json',\n",
    "    scopes=['https://www.googleapis.com/auth/spreadsheets',\n",
    "            'https://www.googleapis.com/auth/drive'])\n",
    "gc = gspread.authorize(creds)\n",
    "sh = gc.open(DEST_SHEET)\n",
    "\n",
    "wb = openpyxl.load_workbook(SRC_EXCEL, data_only=True)\n",
    "for ws in wb.worksheets:\n",
    "    title = ws.title[:99]  # Sheets title limit\n",
    "    if title in [s.title for s in sh.worksheets()]:\n",
    "        sheet = sh.worksheet(title)\n",
    "    else:\n",
    "        sheet = sh.add_worksheet(title, rows=2000, cols=10)\n",
    "\n",
    "    data = [[str(cell) if cell is not None else '' for cell in row] for row in ws.iter_rows(values_only=True)]\n",
    "    \n",
    "#   Update the sheets to populate\n",
    "    sheet.update(values=data, range_name='A1', value_input_option='USER_ENTERED')\n",
    "    time.sleep(2)  # Wait 2 seconds per write\n",
    "\n",
    "    # freeze first 7 rows and bold headers\n",
    "    sheet.format('1:7', {'textFormat': {'bold': True}})\n",
    "    sheet.freeze(rows=1)\n",
    "\n",
    "print(\"Bootstrap complete – Google Sheet mirrors the Excel file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec35b08",
   "metadata": {},
   "source": [
    "### BOT-SERVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ece92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899105285450-50tdk35cnnrrich3nlr0d80kdp2qeovr.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A64549%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.modify+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send&state=RLSPJlljDsFVNMjhzgOmSIa4rLFqNV&access_type=offline\n",
      "🔎 Searching Gmail…\n",
      "Found 200 candidate emails.\n",
      "✅ Parsed 0 new payments.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Payments",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TotalAmount",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2d878edb-0973-4f76-ab37-627d588ff524",
       "rows": [
        [
         "0",
         "2025-01",
         "51",
         "682000"
        ],
        [
         "1",
         "2025-02",
         "42",
         "559000"
        ],
        [
         "2",
         "2025-03",
         "71",
         "853000"
        ],
        [
         "3",
         "2025-04",
         "68",
         "845000"
        ],
        [
         "4",
         "2025-05",
         "45",
         "545000"
        ],
        [
         "5",
         "2025-06",
         "54",
         "712000"
        ],
        [
         "6",
         "2025-07",
         "56",
         "690000"
        ],
        [
         "7",
         "2025-08",
         "28",
         "318000"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Payments</th>\n",
       "      <th>TotalAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01</td>\n",
       "      <td>51</td>\n",
       "      <td>682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02</td>\n",
       "      <td>42</td>\n",
       "      <td>559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03</td>\n",
       "      <td>71</td>\n",
       "      <td>853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04</td>\n",
       "      <td>68</td>\n",
       "      <td>845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05</td>\n",
       "      <td>45</td>\n",
       "      <td>545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>54</td>\n",
       "      <td>712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>56</td>\n",
       "      <td>690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-08</td>\n",
       "      <td>28</td>\n",
       "      <td>318000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  Payments  TotalAmount\n",
       "0  2025-01        51       682000\n",
       "1  2025-02        42       559000\n",
       "2  2025-03        71       853000\n",
       "3  2025-04        68       845000\n",
       "4  2025-05        45       545000\n",
       "5  2025-06        54       712000\n",
       "6  2025-07        56       690000\n",
       "7  2025-08        28       318000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ BOT LOG ------\n",
      "\n",
      "Payments per tenant sheet:\n",
      "\n",
      "✅ Prototype run complete.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "#  RENT RPA — PROTOTYPE\n",
    "#  Gmail -> Google Sheets\n",
    "# ================================\n",
    "\n",
    "import re, base64, time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.text import MIMEText\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Google APIs ---\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.oauth2.service_account import Credentials\n",
    "import gspread\n",
    "from gspread.utils import rowcol_to_a1\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CLIENT_SECRET = 'bot_secret.json'        # Gmail OAuth Desktop credentials\n",
    "SERVICE_KEY   = 'bot_service.json'      # Sheets service account (shared on the target Sheet)\n",
    "SHEET_NAME    = 'RENT TRACKING-Lemaiyan Heights'  # exact Google Sheet NAME\n",
    "GMAIL_QUERY   = 'PAYLEMAIYAN subject:\"NCBA TRANSACTIONS STATUS UPDATE\" newer_than:365d'  # tweak as needed\n",
    "\n",
    "# This prototype uses a unified event schema for consistency:\n",
    "PAYMENT_COLS  = ['Date Paid','Amount Paid','REF Number','Payer','Phone','Payment Mode']\n",
    "MAX_PHONE_LEN = 13\n",
    "REF_LEN       = 10\n",
    "\n",
    "\n",
    "# ----- AUTH -----\n",
    "gmail_flow = InstalledAppFlow.from_client_secrets_file(\n",
    "    CLIENT_SECRET,\n",
    "    scopes=[\n",
    "        'https://www.googleapis.com/auth/gmail.modify',  # read + mark read\n",
    "        'https://www.googleapis.com/auth/gmail.readonly',\n",
    "        'https://www.googleapis.com/auth/gmail.send'\n",
    "    ]\n",
    ")\n",
    "gmail_creds = gmail_flow.run_local_server(port=0)\n",
    "gmail = build('gmail', 'v1', credentials=gmail_creds)\n",
    "\n",
    "sheets_creds = Credentials.from_service_account_file(\n",
    "    SERVICE_KEY,\n",
    "    scopes=['https://www.googleapis.com/auth/spreadsheets',\n",
    "            'https://www.googleapis.com/auth/drive'])\n",
    "gc = gspread.authorize(sheets_creds)\n",
    "sh = gc.open(SHEET_NAME)\n",
    "\n",
    "# ----- PARSER (flexible account code; 10-char ref) -----\n",
    "PATTERN = re.compile(\n",
    "    rf'payment of KES ([\\d,]+\\.\\d{{2}}) '\n",
    "    rf'for account: PAYLEMAIYAN\\s*#?\\s*([A-Za-z]\\d{{1,2}})'\n",
    "    rf' has been received from (.+?) '\n",
    "    rf'(.{{1,{MAX_PHONE_LEN}}}) '\n",
    "    rf'on (\\d{{2}}/\\d{{2}}/\\d{{4}} \\d{{1,2}}:\\d{{2}} [APM]{{2}})\\. '\n",
    "    rf'M-Pesa Ref: ([A-Z0-9]{{{REF_LEN}}})',\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "def parse_email(text: str):\n",
    "    m = PATTERN.search(text or \"\")\n",
    "    if not m:\n",
    "        return None\n",
    "    amt, code, payer, phone, dt, ref = m.groups()\n",
    "    return {\n",
    "        'Date Paid':   dt.strip(),                      # dd/mm/YYYY hh:mm AM/PM\n",
    "        'Amount Paid': float(amt.replace(',', '')),\n",
    "        'REF Number':  ref.upper(),\n",
    "        'Payer':       payer.strip(),\n",
    "        'Phone':       phone.strip(),\n",
    "        'Payment Mode':'MPESA Payment',\n",
    "        'AccountCode': code.upper(),                    # used for routing to the tenant sheet\n",
    "    }\n",
    "\n",
    "# ----- GMAIL: get message text (best-effort) -----\n",
    "def get_message_text(service, msg_id):\n",
    "    msg = service.users().messages().get(userId=\"me\", id=msg_id, format=\"full\").execute()\n",
    "    payload = msg.get(\"payload\", {})\n",
    "    body_texts = []\n",
    "\n",
    "    def walk(part):\n",
    "        mime = part.get(\"mimeType\", \"\")\n",
    "        data = part.get(\"body\", {}).get(\"data\")\n",
    "        parts = part.get(\"parts\", [])\n",
    "        if mime == \"text/plain\" and data:\n",
    "            body_texts.append(base64.urlsafe_b64decode(data).decode(\"utf-8\", errors=\"ignore\"))\n",
    "        for p in parts:\n",
    "            walk(p)\n",
    "\n",
    "    walk(payload)\n",
    "    if body_texts:\n",
    "        return \"\\n\".join(body_texts)\n",
    "    return msg.get(\"snippet\", \"\")\n",
    "\n",
    "# Normalizer: lower, trim, collapse spaces, strip punctuation/currency/nbsp\n",
    "_PUNCT = re.compile(r\"[^\\w\\s/]+\", re.UNICODE)\n",
    "def _norm(s):\n",
    "    if s is None: return \"\"\n",
    "    s = str(s).replace(\"\\xa0\", \" \")  # nbsp -> space\n",
    "    s = s.strip().lower()\n",
    "    s = _PUNCT.sub(\"\", s)            # remove punctuation like ( ), :, KES, etc.\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "# Broad alias sets (normalized)\n",
    "ALIASES = {\n",
    "    \"month\": {\n",
    "        \"month\",\"month/period\",\"period\",\"rent month\",\"billing month\"\n",
    "    },\n",
    "    \"amount_due\": {\n",
    "        \"amount due\",\"rent due\",\"due\",\"amountdue\",\"monthly rent\",\"rent\",\"amount due kes\",\"rent (kes)\"\n",
    "    },\n",
    "    \"amount_paid\": {\n",
    "        \"amount paid\",\"paid\",\"amt paid\",\"paid (kes)\",\"amountpaid\"\n",
    "    },\n",
    "    \"date_paid\": {\n",
    "        \"date paid\",\"paid date\",\"payment date\",\"datepaid\"\n",
    "    },\n",
    "    \"ref\": {\n",
    "        \"ref number\",\"ref\",\"reference\",\"ref no\",\"reference no\",\"mpesa ref\",\"mpesa reference\",\"receipt\",\"receipt no\"\n",
    "    },\n",
    "    \"date_due\": {\n",
    "        \"date due\",\"due date\",\"rent due date\",\"datedue\"\n",
    "    },\n",
    "    \"prepay_arrears\": {\n",
    "        \"prepayment/arrears\",\"prepayment\",\"arrears\",\"balance\",\"bal\",\"prepayment arrears\",\"carry forward\",\"cf\"\n",
    "    },\n",
    "    \"penalties\": {\n",
    "        \"penalties\",\"penalty\",\"late fee\",\"late fees\",\"fine\",\"fines\"\n",
    "    },\n",
    "}\n",
    "\n",
    "REQUIRED_KEYS = [\"month\",\"amount_due\",\"amount_paid\",\"date_paid\",\"ref\",\"date_due\",\"prepay_arrears\",\"penalties\"]\n",
    "\n",
    "# --- Helper to score header row ---\n",
    "def _score_header(row_norm):\n",
    "    \"\"\"How many required columns does this row satisfy?\"\"\"\n",
    "    hits = 0\n",
    "    for key in REQUIRED_KEYS:\n",
    "        if any(a in row_norm for a in ALIASES[key]):\n",
    "            hits += 1\n",
    "    return hits\n",
    "\n",
    "# --- Helper to map row tokens to column keys ---\n",
    "def _header_map_from_row(row):\n",
    "    \"\"\"Return (colmap) by matching normalized row tokens against aliases.\"\"\"\n",
    "    row_norm = [_norm(c) for c in row]\n",
    "    colmap = {}\n",
    "    for key, aliases in ALIASES.items():\n",
    "        for i, token in enumerate(row_norm):\n",
    "            if token in aliases:\n",
    "                colmap[key] = i\n",
    "                break\n",
    "    return colmap\n",
    "\n",
    "\n",
    "# --- Helper to detect or create a header row ---\n",
    "def _detect_or_create_header(ws):\n",
    "    \"\"\"\n",
    "    Find a header row in the first 10 rows.\n",
    "    If none reaches a threshold (>=4 matches), insert a standard header at row 1.\n",
    "    Returns (header_row_idx_0based, header_list, colmap).\n",
    "    \"\"\"\n",
    "    all_data = ws.get_all_values()\n",
    "    max_rows = len(all_data) if all_data else 1\n",
    "    probe_rows = min(max_rows, 10)\n",
    "    last_col = ws.col_count or 12\n",
    "    rn = f\"A1:{rowcol_to_a1(probe_rows, last_col)}\"\n",
    "    values = ws.get_values(rn)  # rectangular cut\n",
    "\n",
    "    best_idx, best_hits, best_map = None, -1, None\n",
    "    for idx, row in enumerate(values):\n",
    "        colmap = _header_map_from_row(row)\n",
    "        hits = len(colmap)\n",
    "        if hits > best_hits:\n",
    "            best_idx, best_hits, best_map = idx, hits, colmap\n",
    "\n",
    "    if best_hits >= 4:\n",
    "        header = ws.row_values(best_idx+1)\n",
    "        missing_keys = [k for k in REQUIRED_KEYS if k not in best_map]\n",
    "        if missing_keys:\n",
    "            standard_columns = {\n",
    "                \"month\": \"Month\",\n",
    "                \"amount_due\": \"Amount Due\",\n",
    "                \"amount_paid\": \"Amount paid\",\n",
    "                \"date_paid\": \"Date paid\",\n",
    "                \"ref\": \"REF Number\",\n",
    "                \"date_due\": \"Date due\",\n",
    "                \"prepay_arrears\": \"Prepayment/Arrears\",\n",
    "                \"penalties\": \"Penalties\"\n",
    "            }\n",
    "            for key in missing_keys:\n",
    "                header.append(standard_columns[key])\n",
    "            ws.update(values=[header], range_name=f\"{best_idx+1}:{best_idx+1}\", value_input_option=\"USER_ENTERED\")\n",
    "            best_map = _header_map_from_row(header)\n",
    "        return best_idx, header, best_map\n",
    "    # No good header found: create standard header on row 1\n",
    "    header = ['Month','Amount Due','Amount paid','Date paid','REF Number','Date due','Prepayment/Arrears','Penalties']\n",
    "    if max_rows == 0:\n",
    "        ws.update(values=[header], range_name=\"1:1\", value_input_option=\"USER_ENTERED\")\n",
    "    else:\n",
    "        ws.insert_row(header, index=1, value_input_option=\"USER_ENTERED\")\n",
    "    return 0, header, _header_map_from_row(header)\n",
    "\n",
    "\n",
    "# --- Helper to convert date string to month key ---\n",
    "def _month_key_from_date_str(date_str):\n",
    "    dt = datetime.strptime(date_str, '%d/%m/%Y %I:%M %p')\n",
    "    return dt.strftime('%B-%Y'), dt   # e.g., January-2025\n",
    "\n",
    "# --- Helper to find the month row in values ---\n",
    "def _find_month_row(values, month_col_idx, month_key):\n",
    "    for r in range(1, len(values)):  # skip header at 0\n",
    "        cell = str(values[r][month_col_idx]).strip()\n",
    "        if not cell:\n",
    "            continue\n",
    "        # accept \"Jan-2025\"/\"JAN 2025\"/\"January 2025\"\n",
    "        if cell.lower().startswith(month_key.lower()[:3]) and month_key[-4:] in cell:\n",
    "            return r\n",
    "    return None\n",
    "\n",
    "# --- Helper to convert row/col to letter(s) ---\n",
    "def _col_letter(row, col):\n",
    "    \"\"\"Return column letter(s) for a given 1-based row/col using A1 conversion.\"\"\"\n",
    "    return re.sub(r'\\d+', '', rowcol_to_a1(row, col))\n",
    "\n",
    "\n",
    "# --- Main function to update tenant month row ---\n",
    "def update_tenant_month_row(tenant_ws, payment):\n",
    "    \"\"\"\n",
    "    Realtime version:\n",
    "      - Writes ONLY: Amount paid, Date paid, REF Number\n",
    "      - Sets once-per-row formulas for:\n",
    "          Prepayment/Arrears = N(Amount paid) - N(Amount Due)\n",
    "          Penalties          = IF(DATEVALUE(LEFT(DatePaid,10)) > DATEVALUE(DateDue)+2, 3000, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- detect/insert header (uses your robust detector from the previous block) ---\n",
    "    header_row0, header, colmap = _detect_or_create_header(tenant_ws)\n",
    "    missing = [k for k in REQUIRED_KEYS if k not in colmap]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Sheet '{tenant_ws.title}' missing required columns after normalization: {missing}\")\n",
    "\n",
    "    # Reload values from header row downward\n",
    "    all_vals = tenant_ws.get_all_values()\n",
    "    vals = all_vals[header_row0:]\n",
    "    base_row_1based = header_row0 + 1\n",
    "\n",
    "    # --- find or create the month row ---\n",
    "    month_key, pay_dt = _month_key_from_date_str(payment['Date Paid'])\n",
    "    row_rel = _find_month_row(vals, colmap['month'], month_key)\n",
    "    if row_rel is None:\n",
    "        new_row = [''] * len(header)\n",
    "        new_row[colmap['month']] = month_key\n",
    "        new_row[colmap['amount_due']] = '0'\n",
    "        new_row[colmap['amount_paid']] = '0'\n",
    "        new_row[colmap['date_paid']] = ''\n",
    "        new_row[colmap['ref']] = ''\n",
    "        # Set Date due as the previous row's date due plus one month.\n",
    "        # Try to get last row's Date due (skip header row)\n",
    "        if len(vals) > 1 and vals[-1][colmap['date_due']]:\n",
    "            try:\n",
    "                last_date_due = datetime.strptime(vals[-1][colmap['date_due']], \"%d/%m/%Y\").replace(day=5)\n",
    "                new_date_due = last_date_due + relativedelta(months=1)\n",
    "            except Exception:\n",
    "            # Fallback to payment date plus one month if parsing fails\n",
    "                new_date_due = datetime.strptime(payment['Date Paid'], '%d/%m/%Y %I:%M %p') + relativedelta(months=1)\n",
    "        else:\n",
    "            new_date_due = datetime.strptime(payment['Date Paid'], '%d/%m/%Y %I:%M %p') + relativedelta(months=1)\n",
    "            new_row[colmap['date_due']] = new_date_due.strftime(\"%d/%m/%Y\")\n",
    "            \n",
    "        # prepay/arrears and penalties will be set as FORMULAS after append\n",
    "        tenant_ws.append_row(new_row, value_input_option='USER_ENTERED')\n",
    "        all_vals = tenant_ws.get_all_values()\n",
    "        vals = all_vals[header_row0:]\n",
    "        row_rel = len(vals) - 1\n",
    "\n",
    "    row_abs_1based = base_row_1based + row_rel\n",
    "    row = vals[row_rel]\n",
    "\n",
    "    # --- helpers to coerce numbers/strings ---\n",
    "    def _num(v):\n",
    "        try:\n",
    "            s = str(v).replace(',','').strip()\n",
    "            return float(s) if s else 0.0\n",
    "        except:\n",
    "            return 0.0\n",
    "    def _str(v):\n",
    "        return '' if v is None else str(v)\n",
    "\n",
    "    # current row values\n",
    "    due0   = _num(row[colmap['amount_due']])\n",
    "    paid0  = _num(row[colmap['amount_paid']])\n",
    "    ref0   = _str(row[colmap['ref']])\n",
    "\n",
    "    pay_amt = float(payment['Amount Paid'])\n",
    "\n",
    "    # (if you previously tracked arrears carryover in this cell, you can ignore that here\n",
    "    #  because the balance is now a live formula: Paid - Due)\n",
    "    paid1 = paid0 + pay_amt\n",
    "\n",
    "    # --- 1) write the three direct fields ---\n",
    "    updates = {\n",
    "        colmap['amount_paid']:  paid1,\n",
    "        colmap['date_paid']:    payment['Date Paid'],\n",
    "        colmap['ref']:          (payment['REF Number'] if not ref0 else f\"{ref0}, {payment['REF Number']}\")\n",
    "    }\n",
    "\n",
    "    # compact range write\n",
    "    touched = sorted(updates.keys())\n",
    "    c1 = touched[0] + 1\n",
    "    c2 = touched[-1] + 1\n",
    "    rng = f\"{rowcol_to_a1(row_abs_1based, c1)}:{rowcol_to_a1(row_abs_1based, c2)}\"\n",
    "    payload = [''] * (c2 - c1 + 1)\n",
    "    for cidx, val in updates.items():\n",
    "        payload[(cidx + 1 - c1)] = val\n",
    "    payload = [str(x) if x is not None else '' for x in payload]\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            tenant_ws.update(values=[payload], range_name=rng, value_input_option='USER_ENTERED')\n",
    "            break\n",
    "        except HttpError as e:\n",
    "            if getattr(e, \"resp\", None) and e.resp.status == 429:\n",
    "                time.sleep(5 * (attempt+1))\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "    # --- 2) ensure the formula cells are present (set once; they’ll recalc automatically) ---\n",
    "    col_letters = {k: _col_letter(row_abs_1based, colmap[k] + 1) for k in colmap}\n",
    "    # addresses for this row:\n",
    "    amt_paid_addr = f\"{col_letters['amount_paid']}{row_abs_1based}\"\n",
    "    amt_due_addr  = f\"{col_letters['amount_due']}{row_abs_1based}\"\n",
    "    date_paid_addr= f\"{col_letters['date_paid']}{row_abs_1based}\"\n",
    "    date_due_addr = f\"{col_letters['date_due']}{row_abs_1based}\"\n",
    "    bal_addr      = f\"{col_letters['prepay_arrears']}{row_abs_1based}\"\n",
    "    pen_addr      = f\"{col_letters['penalties']}{row_abs_1based}\"\n",
    "\n",
    "\n",
    "    # Penalties formula: if DatePaid > DateDue + 2 days, penalty = 3000\n",
    "    pen_formula = f\"=IF(DATEVALUE(LEFT({date_paid_addr},10))>DATEVALUE({date_due_addr})+2, 3000, 0)\"\n",
    "\n",
    "    # Balance formula: if first data row, =N(amt_paid)-N(amt_due); else, =N(prev_bal)+N(amt_paid)-N(amt_due)\n",
    "    if row_abs_1based == base_row_1based:\n",
    "        bal_formula = f\"=N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "    else:\n",
    "        prev_bal_addr = f\"{col_letters['prepay_arrears']}{row_abs_1based-1}\"\n",
    "        bal_formula = f\"=N({prev_bal_addr})+N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "    \n",
    "\n",
    "    # Only set if not already a formula (so we don't overwrite intentional manual values)\n",
    "    current_bal = tenant_ws.acell(bal_addr).value or \"\"\n",
    "    current_pen = tenant_ws.acell(pen_addr).value or \"\"\n",
    "    needs_bal = not str(current_bal).startswith(\"=\")\n",
    "    needs_pen = not str(current_pen).startswith(\"=\")\n",
    "\n",
    "    # Set any missing formulas in a single batch\n",
    "    body = []\n",
    "    if needs_bal:\n",
    "        body.append({'range': bal_addr, 'values': [[bal_formula]]})\n",
    "    if needs_pen:\n",
    "        body.append({'range': pen_addr, 'values': [[pen_formula]]})\n",
    "    if body:\n",
    "        tenant_ws.batch_update(body, value_input_option='USER_ENTERED')\n",
    "\n",
    "    # Return info (no computed numbers now—Sheet will reflect in realtime)\n",
    "    return {\n",
    "        'sheet': tenant_ws.title,\n",
    "        'month_row': row_abs_1based,\n",
    "        'paid_before': paid0,\n",
    "        'paid_after': paid1,\n",
    "        'ref_added': payment['REF Number'],\n",
    "        'formulas_set': {'balance': needs_bal, 'penalties': needs_pen},\n",
    "        'balance_addr': bal_addr,    \n",
    "        'penalties_addr': pen_addr       \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# ----- META SHEETS (ProcessedRefs, PaymentHistory) -----\n",
    "def ensure_meta(ws_name, header):\n",
    "    try:\n",
    "        ws = sh.worksheet(ws_name)\n",
    "    except gspread.WorksheetNotFound:\n",
    "        ws = sh.add_worksheet(ws_name, rows=2000, cols=max(10, len(header)))\n",
    "        ws.append_row(header)\n",
    "    return ws\n",
    "\n",
    "refs_ws = ensure_meta(\"ProcessedRefs\", [\"Ref\"])\n",
    "hist_ws = ensure_meta(\"PaymentHistory\", PAYMENT_COLS + ['AccountCode','TenantSheet','Month'])\n",
    "\n",
    "# Load processed refs into a set\n",
    "ref_vals = refs_ws.get_all_values()\n",
    "processed_refs = set((r[0] or '').upper() for r in ref_vals[1:]) if len(ref_vals) > 1 else set()\n",
    "\n",
    "# ----- GMAIL FETCH + PARSE -----\n",
    "print(\"🔎 Searching Gmail…\")\n",
    "result = gmail.users().messages().list(userId=\"me\", q=GMAIL_QUERY, maxResults=200).execute()\n",
    "msg_list = result.get(\"messages\", [])\n",
    "print(f\"Found {len(msg_list)} candidate emails.\")\n",
    "\n",
    "parsed, errors = [], []\n",
    "for m in msg_list:\n",
    "    try:\n",
    "        text = get_message_text(gmail, m[\"id\"])\n",
    "        pay = parse_email(text)\n",
    "        if not pay:\n",
    "            errors.append(f\"Could not parse message id {m['id']}\")\n",
    "            continue\n",
    "        if pay['REF Number'] in processed_refs:\n",
    "            continue\n",
    "        parsed.append((m[\"id\"], pay))\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error reading message {m['id']}: {e}\")\n",
    "\n",
    "print(f\"✅ Parsed {len(parsed)} new payments.\")\n",
    "\n",
    "# ----- APPLY: to tenant sheets + PaymentHistory + ProcessedRefs -----\n",
    "logs = []\n",
    "tenant_tally = {}\n",
    "\n",
    "# Cache worksheets to reduce calls\n",
    "worksheets = {ws.title: ws for ws in sh.worksheets()}\n",
    "\n",
    "def find_or_create_tenant_sheet(account_code: str):\n",
    "    for title, ws in worksheets.items():\n",
    "        t = title.upper()\n",
    "        if t.startswith(account_code) and 'PROCESSEDREFS' not in t and 'PAYMENTHISTORY' not in t:\n",
    "            return ws\n",
    "    title = f\"{account_code} - AutoAdded\"\n",
    "    ws = sh.add_worksheet(title, rows=1000, cols=12)\n",
    "    ws.update(values=[['Month','Amount Due','Amount paid','Date paid','REF Number','Date due','Prepayment/Arrears','Penalties']],\n",
    "              range_name='A1', value_input_option='USER_ENTERED')\n",
    "    ws.format('1:1', {'textFormat': {'bold': True}})\n",
    "    ws.freeze(rows=1)\n",
    "    worksheets[title] = ws\n",
    "    logs.append(f\"➕ Created tenant sheet: {title}\")\n",
    "    return ws\n",
    "\n",
    "for msg_id, p in parsed:\n",
    "    tenant_ws = find_or_create_tenant_sheet(p['AccountCode'])\n",
    "    info = update_tenant_month_row(tenant_ws, p)\n",
    "    # Read the live, recalculated values\n",
    "    logs.append(\n",
    "    f\"🧾 {info['sheet']} R{info['month_row']} | \"\n",
    "    f\"Paid {info['paid_before']}→{info['paid_after']} | \"\n",
    "    f\"Ref {info['ref_added']} | Bal/penalties will auto-update in sheet\"\n",
    "    )\n",
    "    \n",
    "    tenant_tally[info['sheet']] = tenant_tally.get(info['sheet'], 0) + 1\n",
    "\n",
    "    # PaymentHistory\n",
    "    dt = datetime.strptime(p['Date Paid'], '%d/%m/%Y %I:%M %p')\n",
    "    mon = dt.strftime('%Y-%m')\n",
    "    hist_ws.append_row(\n",
    "        [p[k] for k in PAYMENT_COLS] + [p['AccountCode'], tenant_ws.title, mon],\n",
    "        value_input_option='USER_ENTERED'\n",
    "    )\n",
    "\n",
    "    # ProcessedRefs\n",
    "    refs_ws.append_row([p['REF Number']], value_input_option='RAW')\n",
    "    processed_refs.add(p['REF Number'])\n",
    "\n",
    "    # Mark Gmail read (optional)\n",
    "    try:\n",
    "        gmail.users().messages().modify(userId='me', id=msg_id, body={'removeLabelIds': ['UNREAD']}).execute()\n",
    "    except HttpError:\n",
    "        pass\n",
    "\n",
    "    time.sleep(2)  # throttle writes\n",
    "\n",
    "# ----- GROUPED MONTHLY SUMMARY (display) -----\n",
    "hist_vals = hist_ws.get_all_values()\n",
    "if len(hist_vals) > 1:\n",
    "    df = pd.DataFrame(hist_vals[1:], columns=hist_vals[0])\n",
    "    with pd.option_context('display.float_format', '{:,.2f}'.format):\n",
    "        df['Amount Paid'] = pd.to_numeric(df['Amount Paid'], errors='coerce').fillna(0.0)\n",
    "        grouped = df.groupby('Month', dropna=False).agg(\n",
    "            Payments=('REF Number','count'),\n",
    "            TotalAmount=('Amount Paid','sum')\n",
    "        ).reset_index().sort_values('Month')\n",
    "        display(grouped)\n",
    "else:\n",
    "    print(\"No payment history yet.\")\n",
    "\n",
    "# ----- LOGS -----\n",
    "print(\"\\n------ BOT LOG ------\")\n",
    "for line in logs:\n",
    "    print(line)\n",
    "print(\"\\nPayments per tenant sheet:\")\n",
    "for t, c in tenant_tally.items():\n",
    "    print(f\"  {t}: {c} payment(s)\")\n",
    "if errors:\n",
    "    print(\"\\nNon-fatal parse/read issues:\")\n",
    "    for e in errors:\n",
    "        print(\"  -\", e)\n",
    "print(\"\\n✅ Prototype run complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067a70e",
   "metadata": {},
   "source": [
    "## DEPLOYMENT CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb35c02",
   "metadata": {},
   "source": [
    "* In this integration, we extend the proof‐of‐concept prototype into a Streamlit app. The app retains the core functionality: • OAuth-based Google authentication to securely access Gmail, Google Sheets, and Drive. • Parsing payment notification emails with regular expressions. • Updating the relevant tenant sheets and maintaining meta data like ProcessedRefs and PaymentHistory.\n",
    "\n",
    "* Streamlit provides a user-friendly dashboard where users can trigger the payment bot and view real-time summaries and logs. This separation of the UI from the backend logic enables rapid deployment and easier scalability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abd5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bot_logic (backend)\n",
    "\n",
    "\"\"\"\n",
    "Core sheet-update logic for Rent RPA.\n",
    "\n",
    "WHY these choices:\n",
    "- Header-aware & additive: avoids breaking existing tabs.\n",
    "- Robust parser: tolerates case, '#' omission, varied date formats.\n",
    "- Business rules baked into formulas: easy to audit in-sheet.\n",
    "- Minimal API calls with backoff: protects against quota spikes.\n",
    "- MonthKey + sorting: keeps months ordered even with mixed month strings.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time\n",
    "from gspread.utils import rowcol_to_a1\n",
    "\n",
    "# Match workbook schema (first 6 columns used by PaymentHistory)\n",
    "PAYMENT_COLS = ['Date Paid', 'Amount Paid', 'REF Number', 'Payer', 'Phone', 'Comments']\n",
    "\n",
    "# --- NCBA email parser (tolerant to case, '#', date formats) -----------------\n",
    "\n",
    "DATE_PAT = (\n",
    "    r'(?:'\n",
    "    r'\\d{2}/\\d{2}/\\d{4}\\s+\\d{1,2}:\\d{2}\\s+[APMapm]{2}'\n",
    "    r'|'\n",
    "    r'\\d{4}[-/]\\d{2}[-/]\\d{2}[ T]\\d{1,2}:\\d{2}(?:\\s?[APMapm]{2})?'\n",
    "    r'|'\n",
    "    r'\\d{2}[-/]\\d{2}[-/]\\d{4}\\s+\\d{1,2}:\\d{2}(?:\\s?[APMapm]{2})?'\n",
    "    r')'\n",
    ")\n",
    "\n",
    "# WHY: Explicit groups for amount, account code, payer, phone, date, ref.\n",
    "PATTERN = re.compile(\n",
    "    rf'payment of KES ([\\d,]+\\.\\d{{2}})\\s*'\n",
    "    rf'for account:\\s*PAYLEMAIYAN\\s*#?\\s*([A-Za-z]\\d{{1,2}})\\s*'\n",
    "    rf'has been received from\\s+(.+?)\\s+(.{{1,13}})\\s+'\n",
    "    rf'on\\s+({DATE_PAT})\\.?\\s+'\n",
    "    rf'M-?Pesa Ref:\\s*([A-Za-z0-9\\-\\s]{{6,32}})',\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "def _normalize_ref(ref_raw: str, min_len: int = 8, max_len: int = 16) -> str | None:\n",
    "    core = re.sub(r'[^A-Za-z0-9]', '', (ref_raw or '')).upper()\n",
    "    return core if min_len <= len(core) <= max_len else None  # WHY: reject obviously bad refs\n",
    "\n",
    "def _normalize_payer(name: str) -> str:\n",
    "    n = (name or \"\").strip()\n",
    "    return \" \".join(part.capitalize() for part in re.split(r\"\\s+\", n) if part)  # WHY: tidy casing\n",
    "\n",
    "def _normalize_date_ddmmyyyy(dt_str: str) -> str:\n",
    "    dt_str = (dt_str or \"\").strip()\n",
    "    fmts = [\n",
    "        \"%d/%m/%Y %I:%M %p\", \"%d/%m/%Y %H:%M\",\n",
    "        \"%d-%m-%Y %I:%M %p\", \"%d-%m-%Y %H:%M\",\n",
    "        \"%Y-%m-%d %H:%M\", \"%Y/%m/%d %H:%M\",\n",
    "        \"%Y-%m-%d %I:%M %p\", \"%Y/%m/%d %I:%M %p\",\n",
    "        \"%d/%m/%Y\", \"%d-%m-%Y\", \"%Y-%m-%d\", \"%Y/%m/%d\",\n",
    "    ]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            dt = datetime.strptime(dt_str, f)\n",
    "            return dt.strftime(\"%d/%m/%Y\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return dt_str  # WHY: keep original if parsing fails; written as text\n",
    "\n",
    "def parse_email(text: str) -> Optional[Dict]:\n",
    "    m = PATTERN.search(text or \"\")\n",
    "    if not m:\n",
    "        return None\n",
    "    amt, code, payer, phone, dt_str, ref_raw = m.groups()\n",
    "    ref = _normalize_ref(ref_raw)\n",
    "    if not ref:\n",
    "        return None  # WHY: REF is our idempotency key\n",
    "    return {\n",
    "        'Date Paid':   _normalize_date_ddmmyyyy(dt_str),\n",
    "        'Amount Paid': float((amt or \"0\").replace(',', '')) if amt else 0.0,\n",
    "        'REF Number':  ref,\n",
    "        'Payer':       _normalize_payer(payer),\n",
    "        'Phone':       (phone or \"\").strip(),\n",
    "        'AccountCode': (code or \"\").upper(),       # WHY: route to sheet by code\n",
    "        'Comments':    \"\",                         # WHY: keep schema stable; never overwrite user comments\n",
    "    }\n",
    "\n",
    "# --- Canonical headers & helpers --------------------------------------------\n",
    "\n",
    "ALIASES = {\n",
    "    \"month\": {\"month\",\"month/period\",\"period\",\"rent month\",\"billing month\"},\n",
    "    \"amount_due\": {\"amount due\",\"rent due\",\"due\",\"monthly rent\",\"rent\",\"amount due kes\",\"rent kes\"},\n",
    "    \"amount_paid\": {\"amount paid\",\"paid\",\"amt paid\",\"paid kes\",\"amountpaid\"},\n",
    "    \"date_paid\": {\"date paid\",\"paid date\",\"payment date\",\"datepaid\",\"date of payment\"},\n",
    "    \"ref\": {\"ref number\",\"ref\",\"reference\",\"ref no\",\"reference no\",\"mpesa ref\",\"mpesa reference\",\"receipt\",\"receipt no\"},\n",
    "    \"date_due\": {\"date due\",\"due date\",\"rent due date\",\"datedue\"},\n",
    "    \"prepay_arrears\": {\"prepayment/arrears\",\"prepayment\",\"arrears\",\"balance\",\"bal\",\"prepayment arrears\",\"carry forward\",\"cf\"},\n",
    "    \"penalties\": {\"penalties\",\"penalty\",\"late fee\",\"late fees\",\"fine\",\"fines\"},\n",
    "    \"comments\": {\"comments\",\"comment\",\"remarks\",\"notes\",\"note\"},\n",
    "}\n",
    "REQUIRED_KEYS = [\"month\",\"amount_due\",\"amount_paid\",\"date_paid\",\"ref\",\"date_due\",\"prepay_arrears\",\"penalties\",\"comments\"]\n",
    "CANONICAL_NAME = {\n",
    "    \"month\": \"Month\",\n",
    "    \"amount_due\": \"Amount Due\",\n",
    "    \"amount_paid\": \"Amount Paid\",\n",
    "    \"date_paid\": \"Date Paid\",\n",
    "    \"ref\": \"REF Number\",\n",
    "    \"date_due\": \"Date Due\",\n",
    "    \"prepay_arrears\": \"Prepayment/Arrears\",\n",
    "    \"penalties\": \"Penalties\",\n",
    "    \"comments\": \"Comments\",\n",
    "}\n",
    "CANONICAL_SET = set(CANONICAL_NAME.values())\n",
    "\n",
    "def _norm_header(s: str) -> str:\n",
    "    s = str(s or \"\").replace(\"\\xa0\", \" \").strip().lower()\n",
    "    s = re.sub(r\"[^\\w\\s/]+\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def _alias_key_for(normalized_header: str) -> Optional[str]:\n",
    "    for key, aliases in ALIASES.items():\n",
    "        if normalized_header in aliases:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def _header_colmap(header: List[str]) -> Dict[str, int]:\n",
    "    # WHY: build mapping across canonical/alias names; first win per key\n",
    "    colmap: Dict[str, int] = {}\n",
    "    seen = set()\n",
    "    for idx, name in enumerate(header):\n",
    "        name_str = str(name or \"\")\n",
    "        norm = _norm_header(name_str)\n",
    "        if name_str in CANONICAL_SET:\n",
    "            key = next(k for k, v in CANONICAL_NAME.items() if v == name_str)\n",
    "        else:\n",
    "            key = _alias_key_for(norm)\n",
    "        if key and key not in seen:\n",
    "            colmap[key] = idx\n",
    "            seen.add(key)\n",
    "    return colmap\n",
    "\n",
    "# --- Utilities: backoff, grid safety, header detection, month helpers --------\n",
    "\n",
    "def _with_backoff(fn, *args, **kwargs):\n",
    "    delay = 1.0\n",
    "    for _ in range(6):\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            status = getattr(getattr(e, \"resp\", None), \"status\", None)\n",
    "            if status == 429 or \"quota\" in str(e).lower() or \"rate limit\" in str(e).lower():\n",
    "                time.sleep(delay); delay *= 2; continue  # WHY: survive transient quota errors\n",
    "            raise\n",
    "\n",
    "def _with_backoff_factory(fn_factory, *, max_tries=6):\n",
    "    delay = 1.0\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            return fn_factory()\n",
    "        except Exception as e:\n",
    "            status = getattr(getattr(e, \"resp\", None), \"status\", None)\n",
    "            if status == 429 or \"quota\" in str(e).lower() or \"rate limit\" in str(e).lower():\n",
    "                time.sleep(delay); delay *= 2; continue\n",
    "            raise\n",
    "\n",
    "def _strip_ws_prefix(a1: str) -> str:\n",
    "    s = str(a1 or \"\")\n",
    "    # WHY: gspread returns \"'Sheet'!A1\" sometimes; batch_update expects bare A1\n",
    "    while True:\n",
    "        m = re.match(r\"^'[^']+'!(.+)$\", s)\n",
    "        if not m: break\n",
    "        s = m.group(1)\n",
    "    return s\n",
    "\n",
    "def _ensure_grid_size(ws, need_rows: Optional[int] = None, need_cols: Optional[int] = None):\n",
    "    try:\n",
    "        cur_rows = ws.row_count\n",
    "        cur_cols = ws.col_count\n",
    "        if need_rows is not None and need_rows > cur_rows:\n",
    "            _with_backoff(ws.add_rows, need_rows - cur_rows)\n",
    "        if need_cols is not None and need_cols > cur_cols:\n",
    "            _with_backoff(ws.add_cols, need_cols - cur_cols)\n",
    "    except Exception:\n",
    "        pass  # WHY: some mocks/older APIs lack row_count/col_count\n",
    "\n",
    "def _detect_header_row(all_vals, scan_rows: int = 30) -> int:\n",
    "    # WHY: headers often sit at row 7; detect by scoring canonical/alias hits\n",
    "    def score(row):\n",
    "        s = 0\n",
    "        for cell in row:\n",
    "            if not cell: continue\n",
    "            txt = str(cell).strip()\n",
    "            if txt in CANONICAL_SET or _alias_key_for(_norm_header(txt)):\n",
    "                s += 1\n",
    "        return s\n",
    "    best_i, best_score = 0, 0\n",
    "    limit = min(len(all_vals), max(1, scan_rows))\n",
    "    for i in range(limit):\n",
    "        sc = score(all_vals[i])\n",
    "        if sc > best_score:\n",
    "            best_i, best_score = i, sc\n",
    "    return best_i if best_score >= 3 else 0\n",
    "\n",
    "def _parse_month_cell(s: str) -> Optional[Tuple[int,int]]:\n",
    "    if not s: return None\n",
    "    s = str(s).strip()\n",
    "    m = re.match(r\"^([A-Za-z]{3,9})[- ](\\d{4})$\", s)\n",
    "    if m:\n",
    "        name, year = m.group(1), int(m.group(2))\n",
    "        for fmt in (\"%b\", \"%B\"):\n",
    "            try:\n",
    "                dt = datetime.strptime(f\"01 {name} {year}\", f\"%d {fmt} %Y\")\n",
    "                return (dt.year, dt.month)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    m = re.match(r\"^(\\d{4})[-/](\\d{1,2})$\", s)\n",
    "    if m: return (int(m.group(1)), int(m.group(2)))\n",
    "    m = re.match(r\"^(\\d{1,2})[-/](\\d{4})$\", s)\n",
    "    if m: return (int(m.group(2)), int(m.group(1)))\n",
    "    return None\n",
    "\n",
    "def _choose_month_display(existing_samples: List[str], dt: datetime) -> str:\n",
    "    # WHY: preserve sheet style (e.g., \"Sep-2025\" vs \"2025-09\")\n",
    "    for v in existing_samples:\n",
    "        t = (v or \"\").strip()\n",
    "        if not t: continue\n",
    "        if re.fullmatch(r\"\\d{4}[-/]\\d{2}\", t):\n",
    "            return f\"{dt.year}-{dt.month:02d}\"\n",
    "        if re.fullmatch(r\"[A-Za-z]{3,9}[- ]\\d{4}\", t):\n",
    "            return dt.strftime(\"%b-%Y\")\n",
    "        if re.fullmatch(r\"\\d{2}[-/]\\d{4}\", t):\n",
    "            return f\"{dt.month:02d}-{dt.year}\"\n",
    "    return dt.strftime(\"%b-%Y\")\n",
    "\n",
    "def _ensure_monthkey_and_fill(ws, header_row0: int, header: list[str], colmap: dict):\n",
    "    # WHY: stable sorting regardless of \"Month\" display format\n",
    "    norm = [h.strip().lower() for h in header]\n",
    "    if \"monthkey\" not in norm:\n",
    "        header.append(\"MonthKey\")\n",
    "        ws.update(f\"{header_row0+1}:{header_row0+1}\", [header], value_input_option=\"USER_ENTERED\")\n",
    "        colmap.clear(); colmap.update(_header_colmap(header))\n",
    "    mk_idx = colmap.get(\"monthkey\", len(header)-1)\n",
    "    mon_idx = colmap[\"month\"]\n",
    "\n",
    "    vals = ws.get_all_values()\n",
    "    data = vals[header_row0+1:]\n",
    "    updates = []\n",
    "    for i, row in enumerate(data, start=header_row0+2):\n",
    "        mon_txt = row[mon_idx] if len(row) > mon_idx else \"\"\n",
    "        ym = _parse_month_cell(mon_txt)\n",
    "        if not ym: continue\n",
    "        y, m = ym\n",
    "        a1 = rowcol_to_a1(i, mk_idx+1)\n",
    "        updates.append({\"range\": a1, \"values\": [[f\"{y:04d}-{m:02d}\"]]})\n",
    "    if updates:\n",
    "        ws.batch_update(updates, value_input_option=\"USER_ENTERED\")\n",
    "\n",
    "def _sort_by_monthkey(ws, header_row0: int, header: list[str], colmap: dict):\n",
    "    try:\n",
    "        mk_idx = [h.strip().lower() for h in header].index(\"monthkey\")\n",
    "    except ValueError:\n",
    "        return\n",
    "    ws.sort((mk_idx+1, 'asc'))  # WHY: sheets-native sort\n",
    "\n",
    "# --- Conditional formatting: arrears/penalties highlights --------------------\n",
    "\n",
    "def _ensure_conditional_formatting(ws, header_row0: int, colmap: Dict[str,int], cache: Dict, debug: Optional[List[str]] = None):\n",
    "    if cache.get(\"cf_applied\"): return\n",
    "    try:\n",
    "        sheet_id = ws.id\n",
    "    except Exception:\n",
    "        return\n",
    "    start_row = header_row0 + 1\n",
    "    requests = [\n",
    "        {   # WHY: highlight negative balances (arrears)\n",
    "            \"addConditionalFormatRule\": {\n",
    "                \"rule\": {\n",
    "                    \"ranges\": [{\n",
    "                        \"sheetId\": sheet_id,\n",
    "                        \"startRowIndex\": start_row,\n",
    "                        \"startColumnIndex\": colmap[\"prepay_arrears\"],\n",
    "                        \"endColumnIndex\": colmap[\"prepay_arrears\"] + 1\n",
    "                    }],\n",
    "                    \"booleanRule\": {\n",
    "                        \"condition\": {\"type\": \"NUMBER_LESS\", \"values\": [{\"userEnteredValue\": \"0\"}]},\n",
    "                        \"format\": {\"backgroundColor\": {\"red\": 1.0, \"green\": 0.84, \"blue\": 0.84}}\n",
    "                    }\n",
    "                },\n",
    "                \"index\": 0\n",
    "            }\n",
    "        },\n",
    "        {   # WHY: highlight any penalties\n",
    "            \"addConditionalFormatRule\": {\n",
    "                \"rule\": {\n",
    "                    \"ranges\": [{\n",
    "                        \"sheetId\": sheet_id,\n",
    "                        \"startRowIndex\": start_row,\n",
    "                        \"startColumnIndex\": colmap[\"penalties\"],\n",
    "                        \"endColumnIndex\": colmap[\"penalties\"] + 1\n",
    "                    }],\n",
    "                    \"booleanRule\": {\n",
    "                        \"condition\": {\"type\": \"NUMBER_GREATER\", \"values\": [{\"userEnteredValue\": \"0\"}]},\n",
    "                        \"format\": {\"backgroundColor\": {\"red\": 1.0, \"green\": 1.0, \"blue\": 0.6}}\n",
    "                    }\n",
    "                },\n",
    "                \"index\": 1\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "    try:\n",
    "        ws.spreadsheet.batch_update({\"requests\": requests})\n",
    "        cache[\"cf_applied\"] = True\n",
    "        if debug is not None: debug.append(\"Applied conditional formatting.\")\n",
    "    except Exception as e:\n",
    "        if debug is not None: debug.append(f\"CF skipped: {e}\")\n",
    "\n",
    "# --- Per-sheet cache (reduce API chatter within one run) ---------------------\n",
    "\n",
    "_sheet_cache: Dict[str, Dict] = {}\n",
    "def clear_cache(): _sheet_cache.clear()\n",
    "\n",
    "# --- Main: update a tenant tab for a given payment ---------------------------\n",
    "\n",
    "def update_tenant_month_row(ws, payment: Dict, debug: Optional[List[str]] = None) -> Dict:\n",
    "    title = ws.title\n",
    "    if debug is not None:\n",
    "        debug.append(f\"[{title}] Start REF={payment.get('REF Number')} Amt={payment.get('Amount Paid')} DatePaid={payment.get('Date Paid')}\")\n",
    "\n",
    "    if title not in _sheet_cache:\n",
    "        all_vals = _with_backoff(ws.get_all_values)\n",
    "        header_row0 = _detect_header_row(all_vals)\n",
    "        header = list(all_vals[header_row0]) if len(all_vals) > header_row0 else []\n",
    "        rows   = [list(r) for r in all_vals[header_row0+1:]] if len(all_vals) > header_row0+1 else []\n",
    "        colmap = _header_colmap(header)\n",
    "\n",
    "        added_any = False\n",
    "        for key in REQUIRED_KEYS:\n",
    "            if key not in colmap:\n",
    "                header.append(CANONICAL_NAME[key])\n",
    "                for r in rows: r.append(\"None\" if key == \"comments\" else \"\")\n",
    "                added_any = True\n",
    "\n",
    "        _ensure_grid_size(ws, need_rows=header_row0+1, need_cols=len(header))\n",
    "        _with_backoff(ws.update, f\"{header_row0+1}:{header_row0+1}\", [header], value_input_option='USER_ENTERED')\n",
    "\n",
    "        cache = {\"header_row0\": header_row0, \"header\": header, \"rows\": rows, \"colmap\": _header_colmap(header), \"cf_applied\": False}\n",
    "        _sheet_cache[title] = cache\n",
    "        if debug is not None:\n",
    "            debug.append(f\"[{title}] Header row {header_row0+1}, added_missing={added_any}\")\n",
    "    else:\n",
    "        cache = _sheet_cache[title]\n",
    "\n",
    "    header_row0, header, rows, colmap = cache[\"header_row0\"], cache[\"header\"], cache[\"rows\"], cache[\"colmap\"]\n",
    "\n",
    "    dt_paid = datetime.strptime(payment['Date Paid'], '%d/%m/%Y')\n",
    "    target_y, target_m = dt_paid.year, dt_paid.month\n",
    "    existing_month_samples = [r[colmap['month']] for r in rows if len(r) > colmap['month'] and r[colmap['month']]]\n",
    "    month_display = _choose_month_display(existing_month_samples, dt_paid)\n",
    "\n",
    "    row_abs = None; row_idx = None\n",
    "    for idx_in_rows, r in enumerate(rows, start=1):\n",
    "        if len(r) <= colmap['month']: continue\n",
    "        ym = _parse_month_cell(r[colmap['month']])\n",
    "        if ym and ym == (target_y, target_m):\n",
    "            row_idx = idx_in_rows - 1\n",
    "            row_abs = header_row0 + 1 + idx_in_rows\n",
    "            break\n",
    "\n",
    "    if row_abs is None:\n",
    "        last_due = \"0\"\n",
    "        for r in reversed(rows):\n",
    "            if len(r) > colmap['amount_due'] and str(r[colmap['amount_due']]).strip():\n",
    "                last_due = r[colmap['amount_due']]\n",
    "                break\n",
    "        new_row = [\"\"] * len(header)\n",
    "        new_row[colmap['month']]      = month_display\n",
    "        new_row[colmap['amount_due']] = last_due\n",
    "        if \"comments\" in colmap: new_row[colmap['comments']] = \"None\"\n",
    "        rows.append(new_row)\n",
    "        row_idx = len(rows) - 1\n",
    "        row_abs = header_row0 + 1 + (row_idx + 1)\n",
    "        _ensure_grid_size(ws, need_rows=row_abs, need_cols=len(header))\n",
    "        _with_backoff(ws.update, f\"{row_abs}:{row_abs}\", [new_row], value_input_option='USER_ENTERED')\n",
    "        if debug is not None:\n",
    "            debug.append(f\"[{title}] Created month row R{row_abs}; carry Amount Due={last_due}\")\n",
    "\n",
    "    row_vals = rows[row_idx]\n",
    "    while len(row_vals) < len(header): row_vals.append(\"\")\n",
    "\n",
    "    def _num(v):\n",
    "        try: return float(str(v).replace(\",\", \"\").strip() or 0)\n",
    "        except Exception: return 0.0\n",
    "\n",
    "    paid_before = _num(row_vals[colmap['amount_paid']])\n",
    "    paid_after  = paid_before + float(payment['Amount Paid'])\n",
    "    prev_ref    = row_vals[colmap['ref']] or \"\"\n",
    "    ref_new     = payment['REF Number'] if not prev_ref else f\"{prev_ref}, {payment['REF Number']}\"\n",
    "    due_str     = datetime(target_y, target_m, 5).strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    row_vals[colmap['month']]       = month_display\n",
    "    row_vals[colmap['amount_paid']] = str(paid_after)\n",
    "    row_vals[colmap['date_paid']]   = payment['Date Paid']\n",
    "    row_vals[colmap['ref']]         = ref_new\n",
    "    row_vals[colmap['date_due']]    = due_str\n",
    "\n",
    "    amt_paid_addr  = rowcol_to_a1(row_abs, colmap['amount_paid']+1)\n",
    "    amt_due_addr   = rowcol_to_a1(row_abs, colmap['amount_due']+1)\n",
    "    date_paid_addr = rowcol_to_a1(row_abs, colmap['date_paid']+1)\n",
    "    date_due_addr  = rowcol_to_a1(row_abs, colmap['date_due']+1)\n",
    "    pen_addr       = rowcol_to_a1(row_abs, colmap['penalties']+1)\n",
    "    bal_addr       = rowcol_to_a1(row_abs, colmap['prepay_arrears']+1)\n",
    "    prev_bal_addr  = rowcol_to_a1(row_abs-1, colmap['prepay_arrears']+1)\n",
    "\n",
    "    # WHY: normalize text dates so comparisons work even if stored as text\n",
    "    dpaid_expr  = f\"IF(ISTEXT({date_paid_addr}), DATEVALUE({date_paid_addr}), {date_paid_addr})\"\n",
    "    ddue_expr   = f\"IF(ISTEXT({date_due_addr}),  DATEVALUE({date_due_addr}),  {date_due_addr})\"\n",
    "    prev_bal_safe = f\"IFERROR({prev_bal_addr},0)\"\n",
    "    net_after = f\"({prev_bal_safe} + N({amt_paid_addr}) - N({amt_due_addr}))\"\n",
    "\n",
    "    # BUSINESS RULE: Penalty if paid > due + 2 days AND net balance negative\n",
    "    pen_formula = (\n",
    "        f\"=IF(AND(LEN({date_paid_addr})>0, LEN({date_due_addr})>0, \"\n",
    "        f\"{net_after} < 0, \"\n",
    "        f\"{dpaid_expr} > {ddue_expr} + 2), 3000, 0)\"\n",
    "    )\n",
    "\n",
    "    # Rolling balance (first data row vs subsequent)\n",
    "    if row_abs == header_row0 + 2:\n",
    "        bal_formula = f\"=N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "    else:\n",
    "        bal_formula = f\"=N({prev_bal_addr})+N({amt_paid_addr})-N({amt_due_addr})-N({pen_addr})\"\n",
    "\n",
    "    _target_cols = [\n",
    "        colmap['month']+1, colmap['amount_paid']+1, colmap['date_paid']+1,\n",
    "        colmap['ref']+1, colmap['date_due']+1, colmap['penalties']+1, colmap['prepay_arrears']+1\n",
    "    ]\n",
    "    _ensure_grid_size(ws, need_rows=row_abs, need_cols=max(_target_cols))\n",
    "\n",
    "    updates = [\n",
    "        {\"range\": _strip_ws_prefix(rowcol_to_a1(row_abs, colmap['month']+1)),          \"values\": [[month_display]]},\n",
    "        {\"range\": _strip_ws_prefix(rowcol_to_a1(row_abs, colmap['amount_paid']+1)),    \"values\": [[paid_after]]},\n",
    "        {\"range\": _strip_ws_prefix(rowcol_to_a1(row_abs, colmap['date_paid']+1)),      \"values\": [[payment['Date Paid']]]},\n",
    "        {\"range\": _strip_ws_prefix(rowcol_to_a1(row_abs, colmap['ref']+1)),            \"values\": [[ref_new]]},\n",
    "        {\"range\": _strip_ws_prefix(rowcol_to_a1(row_abs, colmap['date_due']+1)),       \"values\": [[due_str]]},\n",
    "        {\"range\": _strip_ws_prefix(rowcol_to_a1(row_abs, colmap['penalties']+1)),      \"values\": [[pen_formula]]},\n",
    "        {\"range\": _strip_ws_prefix(rowcol_to_a1(row_abs, colmap['prepay_arrears']+1)), \"values\": [[bal_formula]]},\n",
    "    ]\n",
    "    _with_backoff_factory(lambda: ws.batch_update(deepcopy(updates), value_input_option='USER_ENTERED'))\n",
    "\n",
    "    if debug is not None:\n",
    "        debug.append(f\"[{title}] R{row_abs}: paid {paid_before}→{paid_after}, due={due_str}\")\n",
    "\n",
    "    _ensure_conditional_formatting(ws, header_row0, colmap, cache, debug)\n",
    "    _ensure_monthkey_and_fill(ws, header_row0, header, colmap)\n",
    "    _sort_by_monthkey(ws, header_row0, header, colmap)\n",
    "\n",
    "    return {\n",
    "        \"sheet\": ws.title,\n",
    "        \"row\": row_abs,\n",
    "        \"month\": month_display,\n",
    "        \"paid_before\": paid_before,\n",
    "        \"paid_after\": paid_after,\n",
    "        \"date_due\": due_str,\n",
    "        \"month_row\": row_abs,\n",
    "        \"ref_added\": payment.get(\"REF Number\"),\n",
    "        \"formulas_set\": {\"balance\": True, \"penalties\": True},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c00fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The front-end\n",
    "\n",
    "\"\"\"\n",
    "streamlit_app.py — RentRPA Streamlit UI\n",
    "\n",
    "What this app does\n",
    "------------------\n",
    "- Authenticates to Google via OAuth (Gmail + Sheets scopes).\n",
    "- Searches Gmail for payment alerts, parses them, and de-duplicates by REF.\n",
    "- For each parsed payment, finds the matching tenant tab and updates the correct month row\n",
    "  using `bot_logic.update_tenant_month_row` (which is header-row aware and non-destructive).\n",
    "- Writes a clean PaymentHistory and ProcessedRefs to help with metrics and avoiding duplicates.\n",
    "- Shows portfolio metrics (income this month, total prepayments/arrears, penalty frequency).\n",
    "- Optional weekly automation (opt-in checkbox) runs Mondays 09:00 EAT *while the app is open*.\n",
    "\n",
    "Key UX / Safety details\n",
    "-----------------------\n",
    "- The app never renames user headers or deletes columns/rows. It adds missing canonical columns to the far right.\n",
    "- It assumes Date Due is always the 5th of the month, and computes Penalties + Prepayment/Arrears accordingly.\n",
    "- The Comments column is never overwritten; new rows get \"None\" for Comments so a human can fill it in later.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Streamlit UI to ingest NCBA emails → Google Sheets.\n",
    "\n",
    "WHY these choices:\n",
    "- Safe OAuth flow & checker: avoids hard-crash when secrets missing.\n",
    "- Robust Gmail parsing with throttling & dedupe by REF.\n",
    "- History writes align with workbook header; tolerant to missing fields.\n",
    "- Optional tenant tab auto-create with canonical headers.\n",
    "- Portfolio metrics computed from PaymentHistory + per-tenant balances.\n",
    "\"\"\"\n",
    "\n",
    "import json, time, base64, re\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "import gspread\n",
    "from gspread.exceptions import APIError\n",
    "\n",
    "# Extra: capture common OAuth errors to show helpful guidance\n",
    "try:\n",
    "    from oauthlib.oauth2.rfc6749.errors import (\n",
    "        InvalidGrantError, MismatchingStateError, InvalidClientError, InvalidRequestError,\n",
    "    )\n",
    "except Exception:  # pragma: no cover\n",
    "    InvalidGrantError = MismatchingStateError = InvalidClientError = InvalidRequestError = Exception\n",
    "\n",
    "from bot_logic import (\n",
    "    parse_email,\n",
    "    update_tenant_month_row,\n",
    "    PAYMENT_COLS,\n",
    "    clear_cache\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 0) PAGE CHROME + TOP HELP\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "st.set_page_config(page_title=\"Rent RPA (Gmail → Sheets)\", page_icon=\"🏠\", layout=\"wide\")\n",
    "st.title(\"🏠 Rent RPA — Gmail → Google Sheets\")\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "<div style=\"padding:10px;border:1px solid #ddd;border-radius:8px;background:#f7f5f4;margin-bottom:8px\">\n",
    "<b>Rules:</b> Date due = <b>5th</b>. <b>Penalty</b> = 3000 KES if paid <i>after</i> due + 2 days and balance is negative.<br>\n",
    "<b>Safety:</b> We append missing headers; never overwrite <b>Comments</b>.\n",
    "</div>\n",
    "\"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "st.caption(\"Tokens live only in your session memory. No server-side persistence.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1) OAUTH CONFIG — lenient and debug-friendly\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/gmail.modify\",\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/gmail.send\",\n",
    "    \"https://www.googleapis.com/auth/gmail.readonly\",\n",
    "]\n",
    "\n",
    "ENV            = st.secrets.get(\"ENV\", \"local\")\n",
    "GOOGLE_OAUTH   = st.secrets.get(\"google_oauth\", {})\n",
    "CLIENT_ID      = GOOGLE_OAUTH.get(\"client_id\")\n",
    "CLIENT_SECRET  = GOOGLE_OAUTH.get(\"client_secret\")\n",
    "REDIRECT_LOCAL = GOOGLE_OAUTH.get(\"redirect_uri_local\")\n",
    "REDIRECT_PROD  = GOOGLE_OAUTH.get(\"redirect_uri_prod\")\n",
    "REDIRECT_URI   = REDIRECT_PROD if ENV == \"prod\" else REDIRECT_LOCAL\n",
    "\n",
    "def build_flow(state: str | None = None) -> Flow:\n",
    "    \"\"\"Create an OAuth 2.0 Flow; `state` is persisted across the auth dance.\n",
    "    Why: Google checks `state` to prevent CSRF — mismatches raise InvalidGrant.\n",
    "    \"\"\"\n",
    "    client_config = {\n",
    "        \"web\": {\n",
    "            \"client_id\": CLIENT_ID or \"\",\n",
    "            \"project_id\": \"rent-rpa\",\n",
    "            \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "            \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "            \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "            \"client_secret\": CLIENT_SECRET or \"\",\n",
    "            \"redirect_uris\": [REDIRECT_URI or \"\"],\n",
    "        }\n",
    "    }\n",
    "    return Flow.from_client_config(client_config, scopes=SCOPES, redirect_uri=REDIRECT_URI or \"\", state=state)\n",
    "\n",
    "def get_creds():\n",
    "    if \"creds_json\" in st.session_state:\n",
    "        return Credentials.from_authorized_user_info(json.loads(st.session_state[\"creds_json\"]), SCOPES)\n",
    "    return None\n",
    "\n",
    "def store_creds(creds: Credentials):\n",
    "    st.session_state[\"creds_json\"] = creds.to_json()\n",
    "\n",
    "def oauth_setup_checker():\n",
    "    issues, tips = [], []\n",
    "    if not CLIENT_ID or not CLIENT_SECRET:\n",
    "        issues.append(\"Missing CLIENT_ID or CLIENT_SECRET in st.secrets['google_oauth'].\")\n",
    "    if not REDIRECT_URI:\n",
    "        issues.append(\"Missing REDIRECT_URI (set redirect_uri_local / redirect_uri_prod).\")\n",
    "    else:\n",
    "        if not REDIRECT_URI.startswith((\"http://\", \"https://\")):\n",
    "            issues.append(\"REDIRECT_URI must start with http:// or https://\")\n",
    "        if \"localhost\" in REDIRECT_URI and not REDIRECT_URI.startswith(\"http://\"):\n",
    "            tips.append(\"For localhost, use http:// and include the exact port (e.g., http://localhost:8501/)\")\n",
    "        if not REDIRECT_URI.endswith(\"/\"):\n",
    "            tips.append(\"Ensure trailing slash matches GCP OAuth settings.\")\n",
    "    with st.expander(\"🔧 OAuth Setup Checker\", expanded=False):\n",
    "        st.code({\"ENV\": ENV, \"CLIENT_ID_suffix\": (CLIENT_ID or \"\")[-12:], \"REDIRECT_URI\": REDIRECT_URI, \"SCOPES\": SCOPES}, language=\"json\")\n",
    "        if issues: st.error(\"\\n\".join(f\"• {i}\" for i in issues))\n",
    "        if tips:   st.info(\"\\n\".join(f\"• {t}\" for t in tips))\n",
    "    return not issues\n",
    "\n",
    "# Try refresh\n",
    "creds = get_creds()\n",
    "if creds and not creds.valid and creds.refresh_token:\n",
    "    try:\n",
    "        creds.refresh(Request()); store_creds(creds)\n",
    "    except Exception:\n",
    "        # Why: refresh_token can be revoked or expired; force re-auth cleanly.\n",
    "        creds = None\n",
    "\n",
    "# OAuth callback\n",
    "params = st.query_params\n",
    "if \"code\" in params and \"state\" in params and \"creds_json\" not in st.session_state:\n",
    "    returned_state = params.get(\"state\")\n",
    "    saved_state = st.session_state.get(\"oauth_state\")\n",
    "\n",
    "    # Guard: if the state doesn't match, stop to avoid CSRF & invalid_grant\n",
    "    if saved_state and returned_state != saved_state:\n",
    "        st.error(\"OAuth state mismatch. Please retry.\"); st.stop()\n",
    "    flow = build_flow(state=saved_state)\n",
    "    try:\n",
    "        flow.fetch_token(code=params[\"code\"])\n",
    "    except (MismatchingStateError, InvalidRequestError):\n",
    "        st.error(\"OAuth parameters invalid. Retry sign-in.\"); st.stop()\n",
    "    except (InvalidClientError, InvalidGrantError) as e:  # pragma: no cover\n",
    "        st.error(\"Google rejected the OAuth exchange. Check redirect URI and retry.\")\n",
    "        st.stop()\n",
    "    creds = flow.credentials\n",
    "    store_creds(creds)\n",
    "    st.query_params.clear()\n",
    "    st.success(\"Signed in.\")\n",
    "    st.rerun()\n",
    "\n",
    "# Auth gate\n",
    "if not creds or not creds.valid:\n",
    "    oauth_setup_checker()\n",
    "    flow = build_flow()\n",
    "    auth_url, state = flow.authorization_url(\n",
    "        access_type=\"offline\",\n",
    "        include_granted_scopes=True,  # WHY: actual boolean (not string)\n",
    "        prompt=\"consent\",\n",
    "    )\n",
    "    # Persist state so the callback can verify it and rebuild Flow\n",
    "    st.session_state[\"oauth_state\"] = state\n",
    "    st.link_button(\"🔐 Sign in with Google\", auth_url, use_container_width=True)\n",
    "    st.stop()\n",
    "\n",
    "# --- Inputs -----------------------------------------------------------------\n",
    "\n",
    "sheet_url = st.text_input(\"Google Sheet URL\", placeholder=\"https://docs.google.com/spreadsheets/d/xxxxxxxxxxxxxxxxxxxx/edit#gid=0\")\n",
    "gmail_query = st.text_input(\n",
    "    \"Gmail search query\",\n",
    "    value='PAYLEMAIYAN subject:\"NCBA TRANSACTIONS STATUS UPDATE\" newer_than:365d',\n",
    "    help=\"Use Gmail operators (is:unread, after:, before:) to narrow results.\"\n",
    ")\n",
    "\n",
    "c1, c2, c3, c4, c5, c6 = st.columns([1,1,1,1,1,1])\n",
    "with c1: mark_read = st.checkbox(\"Mark processed as Read\", value=True)\n",
    "with c2: throttle_ms = st.number_input(\"Throttle (ms) between writes\", min_value=0, value=200, step=50)\n",
    "with c3: max_results = st.number_input(\"Max messages to scan\", min_value=10, max_value=1000, value=200, step=10)\n",
    "with c4: weekly_auto = st.checkbox(\"Enable weekly automation\", value=False)\n",
    "with c5: verbose_debug = st.checkbox(\"Verbose debug\", value=True)\n",
    "with c6: create_if_missing = st.checkbox(\"Auto-create tenant tabs\", value=True)\n",
    "run_now = st.button(\"▶️ Run Bot Now\", type=\"primary\", use_container_width=True)\n",
    "\n",
    "# --- Helpers ----------------------------------------------------------------\n",
    "\n",
    "def extract_sheet_id(url: str) -> str:\n",
    "    try: return url.split(\"/d/\")[1].split(\"/\")[0]\n",
    "    except Exception: return \"\"\n",
    "\n",
    "def _decode_base64url(data: str) -> str:\n",
    "    \"\"\"Decode base64url Gmail parts safely (padding fixed).\"\"\"\n",
    "    padding = '=' * (-len(data) % 4)\n",
    "    return base64.urlsafe_b64decode(data + padding).decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def _strip_html(html: str) -> str:\n",
    "    \"\"\"Basic HTML to text for simple emails that don't include text/plain parts.\"\"\"\n",
    "    text = re.sub(r\"<br\\s*/?>\", \"\\n\", html, flags=re.I)\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def get_message_text(service, msg_id):\n",
    "    \"\"\"\n",
    "    Fetch a Gmail message by id and return best-effort text.\n",
    "    - Prefers text/plain parts\n",
    "    - Falls back to stripped HTML\n",
    "    - Finally, uses snippet if nothing else\n",
    "    \"\"\"\n",
    "    msg = service.users().messages().get(userId=\"me\", id=msg_id, format=\"full\").execute()\n",
    "    payload = msg.get(\"payload\", {})\n",
    "    body_texts = []\n",
    "    def walk(part):\n",
    "        mime = part.get(\"mimeType\", \"\")\n",
    "        data = part.get(\"body\", {}).get(\"data\")\n",
    "        parts = part.get(\"parts\", [])\n",
    "        if mime == \"text/plain\" and data:\n",
    "            body_texts.append(_decode_base64url(data))\n",
    "        elif mime == \"text/html\" and data and not body_texts:\n",
    "            body_texts.append(_strip_html(_decode_base64url(data)))\n",
    "        for p in parts or []: walk(p)\n",
    "    walk(payload or {})\n",
    "    return \"\\n\".join(body_texts) if body_texts else msg.get(\"snippet\", \"\")\n",
    "\n",
    "def with_backoff(fn, *args, **kwargs):\n",
    "    \"\"\"Backoff wrapper for Sheets operations (append_rows, update, etc.).\"\"\"\n",
    "    delay = 1.0\n",
    "    for _ in range(6):\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except APIError as e:\n",
    "            if hasattr(e, \"response\") and getattr(e.response, \"status_code\", None) == 429:\n",
    "                time.sleep(delay); delay *= 2; continue\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            if \"Rate Limit Exceeded\" in str(e) or \"quota\" in str(e).lower():\n",
    "                time.sleep(delay); delay *= 2; continue\n",
    "            raise\n",
    "\n",
    "def should_auto_run():\n",
    "    \"\"\"\n",
    "    Weekly automation gate:\n",
    "    - Fires Mondays 09:00 EAT (UTC+3) when the app is open.\n",
    "    - Only once per week (tracked in session).\n",
    "    \"\"\"\n",
    "    if not weekly_auto: return False\n",
    "    now_utc = datetime.utcnow()\n",
    "    eat = now_utc + timedelta(hours=3)\n",
    "    in_window = (eat.weekday() == 0 and eat.hour == 9)\n",
    "    last = st.session_state.get(\"last_auto_run_at\")\n",
    "    if in_window and (last is None or (now_utc - last) > timedelta(days=6)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# --- Main run ---------------------------------------------------------------\n",
    "\n",
    "auto_trigger = should_auto_run()\n",
    "if auto_trigger:\n",
    "    st.info(\"🤖 Weekly automation window detected — running.\")\n",
    "run_now = run_now or auto_trigger\n",
    "\n",
    "if run_now:\n",
    "    # Reset bot_logic cache at the start of each run to avoid stale header/col counts\n",
    "    clear_cache()\n",
    "\n",
    "    # Validate inputs\n",
    "    if not sheet_url:\n",
    "        st.error(\"Please paste your Google Sheet URL.\"); st.stop()\n",
    "    sheet_id = extract_sheet_id(sheet_url)\n",
    "    if not sheet_id:\n",
    "        st.error(\"That doesn't look like a valid Google Sheet URL.\"); st.stop()\n",
    "\n",
    "    # Build clients\n",
    "    gmail = build(\"gmail\", \"v1\", credentials=creds)\n",
    "    gs = gspread.authorize(creds)\n",
    "\n",
    "    # Open spreadsheet\n",
    "    try:\n",
    "        sh = gs.open_by_key(sheet_id)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Could not open the Google Sheet. Ensure edit access.\\n\\n{e}\")\n",
    "        st.stop()\n",
    "\n",
    "    def ensure_meta(ws_name, header):\n",
    "        try:\n",
    "            ws = sh.worksheet(ws_name)\n",
    "        except gspread.WorksheetNotFound:\n",
    "            ws = sh.add_worksheet(title=ws_name, rows=2000, cols=max(10, len(header)))\n",
    "            with_backoff(ws.update, \"1:1\", [header], value_input_option=\"USER_ENTERED\")\n",
    "        return ws\n",
    "\n",
    "    # Headers aligned to workbook\n",
    "    refs_ws = ensure_meta(\"ProcessedRefs\", [\"Refs\"])  # WHY: matches workbook\n",
    "    hist_ws = ensure_meta(\"PaymentHistory\", PAYMENT_COLS + ['AccountCode','TenantSheet','Month'])\n",
    "\n",
    "    # Load processed refs to avoid duplicates\n",
    "    ref_vals = with_backoff(refs_ws.get_all_values)\n",
    "    processed_refs = set((r[0] or '').upper() for r in ref_vals[1:]) if len(ref_vals) > 1 else set()\n",
    "\n",
    "    # Gmail search\n",
    "    st.write(\"🔎 Searching Gmail…\")\n",
    "    result = gmail.users().messages().list(userId=\"me\", q=gmail_query, maxResults=int(max_results)).execute()\n",
    "    messages = result.get(\"messages\", [])\n",
    "    st.write(f\"Found {len(messages)} candidate emails.\")\n",
    "\n",
    "    # Parse & filter new payments\n",
    "    parsed, errors = [], []\n",
    "    for m in messages:\n",
    "        try:\n",
    "            text = get_message_text(gmail, m[\"id\"])\n",
    "            if \"PAYLEMAIYAN\" not in (text or \"\").upper():\n",
    "                continue\n",
    "            pay = parse_email(text)\n",
    "            if not pay:\n",
    "                errors.append(f\"Could not parse message id {m['id']}\")\n",
    "                continue\n",
    "            ref_norm = (pay.get('REF Number','') or '').upper()\n",
    "            if ref_norm in processed_refs:\n",
    "                continue  # WHY: idempotent writes by REF\n",
    "            parsed.append((m[\"id\"], pay))\n",
    "        except Exception as e:\n",
    "            errors.append(f\"Error reading message {m['id']}: {e}\")\n",
    "\n",
    "    st.success(f\"Parsed {len(parsed)} new payments.\")\n",
    "\n",
    "    # Find/create tenant worksheet by AccountCode (prefix match)\n",
    "    worksheets = {ws.title: ws for ws in sh.worksheets()}\n",
    "\n",
    "    def find_or_create_tenant_sheet(account_code: str):\n",
    "        acct = (account_code or '').strip().upper()\n",
    "        for title, ws in worksheets.items():\n",
    "            t = title.strip().upper()\n",
    "            if t.startswith(acct) and title not in (\"ProcessedRefs\",\"PaymentHistory\"):\n",
    "                return ws\n",
    "        if not create_if_missing:\n",
    "            raise RuntimeError(f\"No tenant sheet found for AccountCode {account_code}\")\n",
    "        # Create with header on row 7 (matches your schema)\n",
    "        title = f\"{account_code} - AutoAdded\"\n",
    "        ws = sh.add_worksheet(title=title, rows=2000, cols=20)\n",
    "        # Canonical header (row 7) — WHY: matches logic aliasing and keeps uniform\n",
    "        hdr = ['Month','Date Due','Amount Due','Amount Paid','Date Paid','REF Number','Comments','Prepayment/Arrears','Penalties']\n",
    "        with_backoff(ws.update, \"7:7\", [hdr], value_input_option=\"USER_ENTERED\")\n",
    "        try: ws.freeze(rows=7)\n",
    "        except Exception: pass\n",
    "        worksheets[title] = ws\n",
    "        st.info(f\"➕ Created tenant sheet: {title}\")\n",
    "        return ws\n",
    "\n",
    "    # Process payments\n",
    "    hist_rows, ref_rows, logs = [], [], []\n",
    "    debug_accum = [] if verbose_debug else None\n",
    "\n",
    "    for idx, (msg_id, p) in enumerate(parsed, start=1):\n",
    "        ws = find_or_create_tenant_sheet(p[\"AccountCode\"])\n",
    "        info = update_tenant_month_row(ws, p, debug_accum)\n",
    "\n",
    "        logs.append(f\"🧾 {info.get('sheet')} R{info.get('row')} | {info.get('month')} | Paid {info.get('paid_before')}→{info.get('paid_after')} | Ref {p.get('REF Number')}\")\n",
    "\n",
    "        # Append to history using aligned schema; preserve extras at end\n",
    "        hist_rows.append([p.get(k, \"\") for k in PAYMENT_COLS] + [\n",
    "            p.get('AccountCode',''), ws.title, datetime.strptime(p[\"Date Paid\"], \"%d/%m/%Y\").strftime(\"%Y-%m\")\n",
    "        ])\n",
    "\n",
    "        ref_val = (p.get(\"REF Number\",\"\") or \"\").upper()\n",
    "        ref_rows.append([ref_val])\n",
    "        processed_refs.add(ref_val)\n",
    "\n",
    "        # Optionally mark Gmail as read\n",
    "        if mark_read:\n",
    "            try:\n",
    "                gmail.users().messages().modify(userId=\"me\", id=msg_id, body={\"removeLabelIds\": [\"UNREAD\"]}).execute()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if throttle_ms > 0: time.sleep(throttle_ms / 1000.0)\n",
    "\n",
    "        # Flush in batches\n",
    "        if len(hist_rows) >= 100 or idx == len(parsed):\n",
    "            with_backoff(hist_ws.append_rows, hist_rows, value_input_option=\"USER_ENTERED\"); hist_rows.clear()\n",
    "            with_backoff(refs_ws.append_rows, ref_rows, value_input_option=\"RAW\"); ref_rows.clear()\n",
    "\n",
    "    # Run results\n",
    "    st.success(\"Ingestion complete.\")\n",
    "    st.subheader(\"Run Log\")\n",
    "    if logs: st.code(\"\\n\".join(logs), language=\"text\")\n",
    "    if errors:\n",
    "        st.subheader(\"Non-fatal Parse/Read Errors\"); st.code(\"\\n\".join(errors), language=\"text\")\n",
    "    if debug_accum:\n",
    "        st.subheader(\"Verbose Debug (bot_logic)\"); st.code(\"\\n\".join(debug_accum), language=\"text\")\n",
    "\n",
    "    # --- Metrics -------------------------------------------------------------\n",
    "    st.subheader(\"📊 Portfolio Metrics\")\n",
    "\n",
    "    # PaymentHistory aggregates\n",
    "    hist_vals = with_backoff(hist_ws.get_all_values)\n",
    "    income_this_month = 0.0\n",
    "    if len(hist_vals) > 1:\n",
    "        df_hist = pd.DataFrame(hist_vals[1:], columns=hist_vals[0])\n",
    "        for col in (\"Amount Paid\",):\n",
    "            df_hist[col] = pd.to_numeric(df_hist[col], errors=\"coerce\").fillna(0.0)\n",
    "        this_month = datetime.now().strftime(\"%Y-%m\")\n",
    "        income_this_month = float(df_hist.loc[df_hist[\"Month\"] == this_month, \"Amount Paid\"].sum())\n",
    "        grouped = df_hist.groupby(\"Month\", dropna=False).agg(Payments=(\"REF Number\",\"count\"), TotalAmount=(\"Amount Paid\",\"sum\")).reset_index().sort_values(\"Month\")\n",
    "        st.markdown(\"**Payment History — by Month**\")\n",
    "        st.dataframe(grouped, use_container_width=True)\n",
    "\n",
    "    # Per-tenant balances & penalties (scan each tenant tab)\n",
    "\n",
    "    total_prepay = 0.0\n",
    "    total_arrears = 0.0\n",
    "    penalty_freq = {}\n",
    "\n",
    "    def parse_float(x):\n",
    "        try: return float(str(x).replace(\",\", \"\").strip())\n",
    "        except Exception: return 0.0\n",
    "\n",
    "    def detect_header_row(all_vals, scan_rows: int = 30) -> int:\n",
    "        # Lightweight in-app variant\n",
    "        def score(row):\n",
    "            s = 0\n",
    "            for cell in row:\n",
    "                t = str(cell or \"\").strip().lower()\n",
    "                if t in {\"month\",\"amount due\",\"amount paid\",\"date paid\",\"ref number\",\"date due\",\"prepayment/arrears\",\"penalties\",\"comments\"}:\n",
    "                    s += 1\n",
    "            return s\n",
    "        best_i, best_score = 0, 0\n",
    "        limit = min(len(all_vals), max(1, scan_rows))\n",
    "        for i in range(limit):\n",
    "            sc = score(all_vals[i])\n",
    "            if sc > best_score: best_i, best_score = i, sc\n",
    "        return best_i if best_score >= 3 else 0\n",
    "\n",
    "    for ws in sh.worksheets():\n",
    "        name = ws.title.upper()\n",
    "        if name in (\"PAYMENTHISTORY\", \"PROCESSEDREFS\"):\n",
    "            continue\n",
    "        try:\n",
    "            vals = with_backoff(ws.get_all_values)\n",
    "            if not vals: continue\n",
    "            header_row0 = detect_header_row(vals)\n",
    "            header = [c.strip() for c in vals[header_row0]]\n",
    "            rows = vals[header_row0+1:]\n",
    "            if not rows: continue\n",
    "\n",
    "            def idx(colname):\n",
    "                try: return header.index(colname)\n",
    "                except ValueError: return -1\n",
    "\n",
    "            i_bal = idx(\"Prepayment/Arrears\")\n",
    "            i_pen = idx(\"Penalties\")\n",
    "            i_mon = idx(\"Month\")\n",
    "\n",
    "            # Latest balance = last populated Month row (or last row if Month empty)\n",
    "            latest_row = None\n",
    "            for r in reversed(rows):\n",
    "                if i_mon != -1 and len(r) > i_mon and str(r[i_mon]).strip():\n",
    "                    latest_row = r; break\n",
    "            if latest_row is None and rows:\n",
    "                latest_row = rows[-1]\n",
    "\n",
    "            if latest_row and i_bal != -1 and len(latest_row) > i_bal:\n",
    "                bal = parse_float(latest_row[i_bal])\n",
    "                if bal > 0: total_prepay += bal\n",
    "                elif bal < 0: total_arrears += abs(bal)\n",
    "\n",
    "            if i_pen != -1:\n",
    "                cnt = 0\n",
    "                for r in rows:\n",
    "                    if len(r) > i_pen and parse_float(r[i_pen]) > 0:\n",
    "                        cnt += 1\n",
    "                acct = ws.title.split(\" - \")[0].strip().upper()\n",
    "                penalty_freq[acct] = penalty_freq.get(acct, 0) + cnt\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    c1, c2, c3 = st.columns(3)\n",
    "    c1.metric(\"Income (this month)\", f\"{income_this_month:,.0f} KES\")\n",
    "    c2.metric(\"Total Prepayments\", f\"{total_prepay:,.0f} KES\")\n",
    "    c3.metric(\"Total Arrears\", f\"{total_arrears:,.0f} KES\")\n",
    "\n",
    "    if penalty_freq:\n",
    "        df_pen = pd.DataFrame(\n",
    "            [{\"AccountCode\": k, \"Penalty Rows\": v} for k, v in penalty_freq.items()]\n",
    "        ).sort_values(\"Penalty Rows\", ascending=False)\n",
    "        st.markdown(\"**Penalty frequency by AccountCode** (rows with penalties > 0):\")\n",
    "        st.dataframe(df_pen, use_container_width=True)\n",
    "\n",
    "    if auto_trigger:\n",
    "        st.session_state[\"last_auto_run_at\"] = datetime.utcnow()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5) FOOTER\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "st.divider()\n",
    "st.caption(\n",
    "    \"Rent-RPA © {year}. Tips: keep Gmail queries narrow; use Google Sheets (not Excel uploads); \"\n",
    "    \"Made by [Eugene Maina](https://github.com/eugene-maina72).\"\n",
    "    .format(year=datetime.now().year)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6711f",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Workflow Summary\n",
    "\n",
    "- **Project Overview:**  \n",
    "    Developed a rent automation bot for Lemaiyan Heights that processes payment notifications and tracks rent payment histories.\n",
    "\n",
    "- **Dummy Data Generation:**  \n",
    "    - Created a dummy dataset of email notifications to simulate incoming rent payment emails.  \n",
    "    - Utilized Faker for generating realistic customer names, phone numbers, dates, and payment amounts.\n",
    "\n",
    "- **Payment Parsing & Data Extraction:**  \n",
    "    - Developed regex-based functions to extract payment details (amount, account code, payer, phone, date, and reference) from email texts.\n",
    "    - Handled variable formatting and ensured proper deduplication using a set of processed payment references.\n",
    "\n",
    "- **Excel Workbook Management:**  \n",
    "    - Implemented logic to update an Excel workbook (`dummy_rent_tracker.xlsx`) with the parsed payment data.\n",
    "    - Managed multiple sheets: tenant-specific sheets, a master payment history, and a deduplication sheet (\"ProcessedRefs\").\n",
    "    - Used Pandas and openpyxl to read, update, and create sheets dynamically when a tenant’s sheet was not found.\n",
    "\n",
    "- **Integration with Google Services:**  \n",
    "    - Extended the proof-of-concept to interact with Gmail and Google Sheets:\n",
    "        - Sent dummy emails into a Gmail sandbox for testing.\n",
    "        - Migrated data from Excel to Google Sheets.\n",
    "        - Automated the process to fetch emails, parse their content, and update the corresponding tenant sheets on Google Sheets in real time.\n",
    "    - Employed OAuth for secure access to Gmail and Google Sheets.\n",
    "\n",
    "- **Deployment and Prototyping:**  \n",
    "    - The final implementation was adapted for a deployment scenario, integrating with both Gmail and Google Sheets, and ensuring quota-safe operations.\n",
    "    - Streamlit was mentioned as a potential UI dashboard for triggering the payment bot and viewing realtime logs and summaries.\n",
    "\n",
    "This notebook documents the end-to-end automation of rent payment processing, from dummy email generation to real-time Google Sheets updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d42f76",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusions\n",
    "- The rent automation bot successfully simulates the processing of payment emails, extracting key information using regex.\n",
    "- Data is reliably logged into an Excel workbook with dedicated sheets for tenant details, payment history, and deduplication (ProcessedRefs).\n",
    "- Integration with Google services (Sheets and Gmail) demonstrates that the core functionality can be extended to a cloud-based, real-time workflow.\n",
    "- The use of Faker and dummy email generation confirms that the system can handle various data scenarios and potential edge cases.\n",
    "\n",
    "## Next Steps\n",
    "- Expand automated tests and CI:\n",
    "    - Unit tests for the email parser, date/amount normalization, and sheet-update functions.\n",
    "    - Integration tests that run against a sandbox Gmail + test Google Sheet.\n",
    "    - Linting and pre-commit checks.\n",
    "\n",
    "- Harden parsing and validation:\n",
    "    - Accept more date formats and optional/missing fields (phone, payer).\n",
    "    - Add strict validation and clear error messages for malformed refs or amounts.\n",
    "    - Add synthetic edge-case tests (truncated bodies, extra punctuation).\n",
    "\n",
    "- Reliability & quotas:\n",
    "    - Centralize exponential backoff/retry strategy for Gmail/Sheets calls.\n",
    "    - Batch writes where possible and add rate-limit monitoring.\n",
    "    - Add idempotency guards beyond REF (timestamps, message-id).\n",
    "\n",
    "- Security & config:\n",
    "    - Move secrets to secure storage (Vault / environment / Streamlit secrets).\n",
    "    - Document required IAM scopes and least-privilege roles for service accounts.\n",
    "    - Rotate keys and provide instructions for safe local dev.\n",
    "\n",
    "- Observability & alerts:\n",
    "    - Structured logging (JSON), run-level summary logs and error reports.\n",
    "    - Export metrics (processed count, duplicates, parse failures) to a monitoring dashboard and alert on spikes.\n",
    "\n",
    "- Deployment & scheduling:\n",
    "    - Provide a reproducible deployment (Docker image or Cloud Function / Cloud Run).\n",
    "    - Add scheduled runner (Cloud Scheduler / cron) that triggers idempotent runs.\n",
    "    - Optionally expose a webhook or Pub/Sub ingestion for near-real-time processing.\n",
    "\n",
    "- UX & operational improvements:\n",
    "    - Add Streamlit UI controls for dry-run, replay window, and manual retry of failed parses.\n",
    "    - Improve runbook with common troubleshooting steps and rollback plan.\n",
    "    - Add tenant management UI to rename/move sheets safely.\n",
    "\n",
    "- Data governance:\n",
    "    - Mask or hash PII (phone numbers) in logs and histories.\n",
    "    - Define retention policy for PaymentHistory and ProcessedRefs.\n",
    "    - Provide a migration plan to consolidate historical Excel data into Google Sheets preserving audit trail.\n",
    "\n",
    "- Documentation:\n",
    "    - README with architecture diagram, setup steps, OAuth instructions, and testing guide.\n",
    "    - Contributing guide and API surface docs for bot_logic functions.\n",
    "\n",
    "- Roadmap items:\n",
    "    - Add reconciliation with bank statements for end-to-end verification.\n",
    "    - Enable multi-property support and role-based access for property managers.\n",
    "    - Add automated monthly financial reports and export to accounting systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0cb1ce",
   "metadata": {},
   "source": [
    "## 👨‍💻 Author\n",
    "\n",
    "Eugene Maina\n",
    "Data Scientist | RPA Developer\n",
    "\n",
    "* [LinkedIn](https://www.linkedin.com/in/eugene-maina-4a8b9a128/) | [GitHub](https://github.com/eugene-maina72) | [Email](mailto:eugenemaina72@gmail.com)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartpath-streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
